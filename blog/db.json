{"meta":{"version":1,"warehouse":"3.0.2"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"source/LICENSE","path":"LICENSE","modified":1,"renderable":0},{"_id":"source/img/avatar/mona_lisa.ico","path":"img/avatar/mona_lisa.ico","modified":1,"renderable":0},{"_id":"source/img/avatar/mona_lisa.jpg","path":"img/avatar/mona_lisa.jpg","modified":1,"renderable":0},{"_id":"source/img/icon/lecture.png","path":"img/icon/lecture.png","modified":1,"renderable":0},{"_id":"source/img/signature/ay-white-2.png","path":"img/signature/ay-white-2.png","modified":1,"renderable":0},{"_id":"source/img/signature/ay-white.png","path":"img/signature/ay-white.png","modified":1,"renderable":0},{"_id":"themes/livemylife/source/css/beantech.min.css","path":"css/beantech.min.css","modified":1,"renderable":1},{"_id":"themes/livemylife/source/css/archive.styl","path":"css/archive.styl","modified":1,"renderable":1},{"_id":"themes/livemylife/source/css/catalog.styl","path":"css/catalog.styl","modified":1,"renderable":1},{"_id":"themes/livemylife/source/css/gitalk.css","path":"css/gitalk.css","modified":1,"renderable":1},{"_id":"themes/livemylife/source/css/highlight.styl","path":"css/highlight.styl","modified":1,"renderable":1},{"_id":"themes/livemylife/source/css/beantech.css","path":"css/beantech.css","modified":1,"renderable":1},{"_id":"themes/livemylife/source/css/highlight_normal.css","path":"css/highlight_normal.css","modified":1,"renderable":1},{"_id":"themes/livemylife/source/css/hux-blog.min.css","path":"css/hux-blog.min.css","modified":1,"renderable":1},{"_id":"themes/livemylife/source/css/livemylife.css","path":"css/livemylife.css","modified":1,"renderable":1},{"_id":"themes/livemylife/source/css/scroll.css","path":"css/scroll.css","modified":1,"renderable":1},{"_id":"themes/livemylife/source/css/signature.styl","path":"css/signature.styl","modified":1,"renderable":1},{"_id":"themes/livemylife/source/css/search.css","path":"css/search.css","modified":1,"renderable":1},{"_id":"themes/livemylife/source/css/themecolor.css","path":"css/themecolor.css","modified":1,"renderable":1},{"_id":"themes/livemylife/source/css/rocket.styl","path":"css/rocket.styl","modified":1,"renderable":1},{"_id":"themes/livemylife/source/css/top.css","path":"css/top.css","modified":1,"renderable":1},{"_id":"themes/livemylife/source/css/viewer.min.css","path":"css/viewer.min.css","modified":1,"renderable":1},{"_id":"themes/livemylife/source/css/wave.css","path":"css/wave.css","modified":1,"renderable":1},{"_id":"themes/livemylife/source/css/widget.styl","path":"css/widget.styl","modified":1,"renderable":1},{"_id":"themes/livemylife/source/fonts/glyphicons-halflings-regular.eot","path":"fonts/glyphicons-halflings-regular.eot","modified":1,"renderable":1},{"_id":"themes/livemylife/source/fonts/glyphicons-halflings-regular.woff","path":"fonts/glyphicons-halflings-regular.woff","modified":1,"renderable":1},{"_id":"themes/livemylife/source/fonts/glyphicons-halflings-regular.ttf","path":"fonts/glyphicons-halflings-regular.ttf","modified":1,"renderable":1},{"_id":"themes/livemylife/source/js/bootstrap.min.js","path":"js/bootstrap.min.js","modified":1,"renderable":1},{"_id":"themes/livemylife/source/fonts/glyphicons-halflings-regular.woff2","path":"fonts/glyphicons-halflings-regular.woff2","modified":1,"renderable":1},{"_id":"themes/livemylife/source/js/catalog.js","path":"js/catalog.js","modified":1,"renderable":1},{"_id":"themes/livemylife/source/js/busuanzi.pure.mini.js","path":"js/busuanzi.pure.mini.js","modified":1,"renderable":1},{"_id":"themes/livemylife/source/js/hux-blog.min.js","path":"js/hux-blog.min.js","modified":1,"renderable":1},{"_id":"themes/livemylife/source/js/hux-blog.js","path":"js/hux-blog.js","modified":1,"renderable":1},{"_id":"themes/livemylife/source/js/scroll.js","path":"js/scroll.js","modified":1,"renderable":1},{"_id":"themes/livemylife/source/js/themecolor.js","path":"js/themecolor.js","modified":1,"renderable":1},{"_id":"themes/livemylife/source/js/jquery.nav.js","path":"js/jquery.nav.js","modified":1,"renderable":1},{"_id":"themes/livemylife/source/js/ziploader.js","path":"js/ziploader.js","modified":1,"renderable":1},{"_id":"themes/livemylife/source/js/totop.js","path":"js/totop.js","modified":1,"renderable":1},{"_id":"themes/livemylife/source/js/jquery.tagcloud.js","path":"js/jquery.tagcloud.js","modified":1,"renderable":1},{"_id":"themes/livemylife/source/css/bootstrap.min.css","path":"css/bootstrap.min.css","modified":1,"renderable":1},{"_id":"themes/livemylife/source/fonts/glyphicons-halflings-regular.svg","path":"fonts/glyphicons-halflings-regular.svg","modified":1,"renderable":1},{"_id":"themes/livemylife/source/js/bootstrap.js","path":"js/bootstrap.js","modified":1,"renderable":1},{"_id":"themes/livemylife/source/js/jquery.min.js","path":"js/jquery.min.js","modified":1,"renderable":1},{"_id":"themes/livemylife/source/css/bootstrap.css","path":"css/bootstrap.css","modified":1,"renderable":1},{"_id":"themes/livemylife/source/css/images/beside_up.png","path":"css/images/beside_up.png","modified":1,"renderable":1},{"_id":"themes/livemylife/source/css/images/beside_up2.png","path":"css/images/beside_up2.png","modified":1,"renderable":1},{"_id":"themes/livemylife/source/css/images/beside_up_white.png","path":"css/images/beside_up_white.png","modified":1,"renderable":1},{"_id":"themes/livemylife/source/css/images/beside_up_white2.png","path":"css/images/beside_up_white2.png","modified":1,"renderable":1},{"_id":"themes/livemylife/source/js/viewer/viewer.min.js","path":"js/viewer/viewer.min.js","modified":1,"renderable":1},{"_id":"themes/livemylife/source/js/viewer/pic-viewer.js","path":"js/viewer/pic-viewer.js","modified":1,"renderable":1},{"_id":"themes/livemylife/source/js/jquery.js","path":"js/jquery.js","modified":1,"renderable":1},{"_id":"themes/livemylife/source/js/comment/gitalk.js","path":"js/comment/gitalk.js","modified":1,"renderable":1},{"_id":"source/img/header_img/la.jpg","path":"img/header_img/la.jpg","modified":1,"renderable":0},{"_id":"source/img/header_img/coast.jpg","path":"img/header_img/coast.jpg","modified":1,"renderable":0},{"_id":"source/img/header_img/big_bear_lake.jpg","path":"img/header_img/big_bear_lake.jpg","modified":1,"renderable":0},{"_id":"source/img/header_img/404_bg.jpg","path":"img/header_img/404_bg.jpg","modified":1,"renderable":0},{"_id":"source/img/header_img/sumset.jpg","path":"img/header_img/sumset.jpg","modified":1,"renderable":0},{"_id":"source/img/header_img/snow.jpg","path":"img/header_img/snow.jpg","modified":1,"renderable":0}],"Cache":[{"_id":"source/404.md","hash":"04daf093e5db316f9b204b62412d646727318f7c","modified":1610607212617},{"_id":"source/CNAME","hash":"7b594a7c935c9222219cc5308d747e7e21c1b667","modified":1610649668934},{"_id":"source/_readme.txt","hash":"bddab7042d69720ee508338cfcde9d2b1ae901bf","modified":1610590760877},{"_id":"themes/livemylife/_config.yml","hash":"cc81f0292e6d73b86b6722dafaf507cbb331d5d8","modified":1610590761334},{"_id":"themes/livemylife/LICENSE","hash":"c48eaae47a703282e0ffe7b91d69366452046214","modified":1610590761334},{"_id":"source/LICENSE","hash":"b314c7ebb7d599944981908b7f3ed33a30e78f3a","modified":1610590760850},{"_id":"source/_posts/AIA-ch1-Q-A.md","hash":"a1cc5e798bd6a54b8e3a7efdd6791e2ce39c313a","modified":1612293225287},{"_id":"source/_posts/AIA-ch2-Q-A.md","hash":"35a71dc23bd2212506615e2d4d5e86ecb54ae6d9","modified":1612743352989},{"_id":"source/_posts/AIA-ch4-Q-A.md","hash":"fcc4019627b2f60da3a254ec7ba886b430468488","modified":1613708110029},{"_id":"source/_posts/AIA-ch3-Q-A.md","hash":"1cdb30691c3b4c5f54c5828f10f66d67480721ec","modified":1613455482896},{"_id":"source/categories/index.md","hash":"3daa8785056aa8c972ee0b6bd8630da9a9fad14f","modified":1611468449950},{"_id":"source/about/index.md","hash":"fa7adb7e4270cd5b833a7a2fa4e8ec86fa48a430","modified":1611468419780},{"_id":"themes/livemylife/languages_to_be_added/de.yml","hash":"02a98ba2b93e30a00ae7979fbe90b767a27290f0","modified":1610590761334},{"_id":"themes/livemylife/languages_to_be_added/en.yml","hash":"3cd0873b310cbf2fe022ee18d55a6113b347ea09","modified":1610590761335},{"_id":"themes/livemylife/languages_to_be_added/default.yml","hash":"3cd0873b310cbf2fe022ee18d55a6113b347ea09","modified":1610590761335},{"_id":"themes/livemylife/languages_to_be_added/es.yml","hash":"fb089145368422ac47da9eb00fed05b15c904aa2","modified":1610590761335},{"_id":"themes/livemylife/languages_to_be_added/no.yml","hash":"5ce3a1043ff85cecf83f3b5b0cdad2df44fa0192","modified":1610590761335},{"_id":"themes/livemylife/languages_to_be_added/ru.yml","hash":"2cfaf93704ea4ac3f374c69bab89ca31916faa33","modified":1610590761336},{"_id":"themes/livemylife/languages_to_be_added/pl.yml","hash":"6dc5d1b2aa75ae4c527089a770f43bafb91d80f4","modified":1610590761336},{"_id":"themes/livemylife/languages_to_be_added/zh-CN.yml","hash":"6d712d9eb6ba12213dcd76b532cd86e9da83cfa3","modified":1610590761336},{"_id":"themes/livemylife/layout/404.ejs","hash":"a70ca6364458eb6ffd8b1a527005a2d4cd8d6e4c","modified":1612244135440},{"_id":"themes/livemylife/languages_to_be_added/zh-TW.yml","hash":"45c84384a05fdb7e32a3e2d498ea180be7dccfa9","modified":1610590761336},{"_id":"themes/livemylife/layout/about.ejs","hash":"27b5aa49173e8b6430b987f7238eed5ac3ae7a91","modified":1610590761342},{"_id":"themes/livemylife/layout/archive.ejs","hash":"c783482f96be209dbfb78edb10f8ed721411e1b9","modified":1610590761342},{"_id":"themes/livemylife/layout/categories.ejs","hash":"531e24e43acb79cfab313e4dc284fab98714e335","modified":1610590761342},{"_id":"themes/livemylife/layout/index.ejs","hash":"32507af954bacbaa6257bb4a5b9fdd6f995d212f","modified":1611441443115},{"_id":"themes/livemylife/layout/keynote.ejs","hash":"2c92a060d8bbd256cc7367aec7e29e515bd00869","modified":1610590761343},{"_id":"themes/livemylife/layout/layout.ejs","hash":"7c176ef1cc8921b402ef351b9c500627f99a19bc","modified":1611795862030},{"_id":"themes/livemylife/layout/page.ejs","hash":"73ebc2a229add288e6b45b367f345c6eb558025d","modified":1610590761344},{"_id":"themes/livemylife/layout/post.ejs","hash":"d07e54285fb9d5f4af508d2eed91e45cd7f7853e","modified":1612243581646},{"_id":"themes/livemylife/layout/tags.ejs","hash":"ad71cc7761bdb63dcc03c648960f6485dcc323c3","modified":1610590761344},{"_id":"source/_posts/AIA-ch1-Q-A/lecture.png","hash":"2df60358a9b17e702e4fc0728e38a067cd327a0f","modified":1611466086761},{"_id":"source/_posts/AIA-ch1-Q-A/fn_gn.png","hash":"f6b1ae0be19723be39d055b4ffdc65a3de516807","modified":1611340418617},{"_id":"source/_posts/AIA-ch1-Q-A/ans_5.png","hash":"aba9f9b28d63f7d2009c56bb102819537281d0da","modified":1611551142616},{"_id":"source/_posts/AIA-ch2-Q-A/lecture.png","hash":"2df60358a9b17e702e4fc0728e38a067cd327a0f","modified":1611466086761},{"_id":"source/_posts/AIA-ch3-Q-A/BT.png","hash":"a332af1ffea545d8c697f8877af25a5bcfba571a","modified":1613454440462},{"_id":"source/_posts/AIA-ch3-Q-A/heap_table.png","hash":"b73c1d9847760bc6c9838c927e61fafe97eb6c35","modified":1612747609977},{"_id":"source/_posts/AIA-ch4-Q-A/lecture.png","hash":"2df60358a9b17e702e4fc0728e38a067cd327a0f","modified":1611466086761},{"_id":"source/_posts/AIA-ch3-Q-A/lecture.png","hash":"2df60358a9b17e702e4fc0728e38a067cd327a0f","modified":1611466086761},{"_id":"source/_posts/AIA-ch4-Q-A/r10.png","hash":"9c7d738c977f736e61273631eefa53e66d66cf8a","modified":1613713745265},{"_id":"source/_posts/AIA-ch4-Q-A/r12.png","hash":"50b73e5899a29cc0d791c5c630f37b55ad3b6ede","modified":1613713766316},{"_id":"source/_posts/AIA-ch4-Q-A/r2.png","hash":"8b14fff1455518337c58e7819a18a8775aa43c36","modified":1613695483544},{"_id":"source/img/avatar/mona_lisa.ico","hash":"e50aff0c7c92a9e14c125c2d0113734122464631","modified":1610653303559},{"_id":"source/img/avatar/mona_lisa.jpg","hash":"5e72c3d1e1c574600547887228de5661ac41f370","modified":1551247083384},{"_id":"source/img/icon/lecture.png","hash":"2df60358a9b17e702e4fc0728e38a067cd327a0f","modified":1611466086761},{"_id":"source/img/signature/ay-white-2.png","hash":"c5761fb500a13a2554894d23583d41608176acf9","modified":1610655921819},{"_id":"source/img/signature/ay-white.png","hash":"5bd0f949ba4c89eb08bf505aa614e406ac0026bb","modified":1610655948459},{"_id":"themes/livemylife/layout/_partial/ad.ejs","hash":"dfb0a02056608ae9b9857359b98b22550c283563","modified":1612245362664},{"_id":"themes/livemylife/layout/_partial/anchorjs.ejs","hash":"073df9003dc40e09af1c27438860c22d0bc8fe60","modified":1610590761337},{"_id":"themes/livemylife/layout/_partial/catalog.ejs","hash":"a765433a33b3613f4664de2da48d0c58f68f8cd6","modified":1610590761337},{"_id":"themes/livemylife/layout/_partial/comment.ejs","hash":"5238690d6020c059f3326e6787a7a7f388cda5d8","modified":1610590761338},{"_id":"themes/livemylife/layout/_partial/footer.ejs","hash":"692876a456ea40e9d10265fc3d009e2beb3dd192","modified":1610654173409},{"_id":"themes/livemylife/layout/_partial/head.ejs","hash":"e66ff129dd8842a71e025a4cace3127b4fb1c97a","modified":1610590761338},{"_id":"themes/livemylife/layout/_partial/gitter.ejs","hash":"34c97132f17f3c31aabe6dfbc908f0650213e847","modified":1610590761338},{"_id":"themes/livemylife/layout/_partial/header.ejs","hash":"db0234b44beea5fa61bc3e9663b0c56b3801e733","modified":1610658256013},{"_id":"themes/livemylife/layout/_partial/nav.ejs","hash":"84bb8a149495fa8708178c2309da37f57e66361e","modified":1611794533325},{"_id":"themes/livemylife/layout/_partial/pagination.ejs","hash":"cd61e4dbbf6020ad094c8e66ec06e8c38ebcd122","modified":1610590761339},{"_id":"themes/livemylife/layout/_partial/sidebar.ejs","hash":"bc7834dd769eeac94a76ffd9cfbb13a622861b62","modified":1610590761340},{"_id":"themes/livemylife/layout/_partial/search.ejs","hash":"edd2552c9226b8e0d31c134c87815444c5be1e1d","modified":1610657848959},{"_id":"themes/livemylife/layout/_partial/socialshare.ejs","hash":"c85d91b7985492a909907d7517292b79d1dec668","modified":1611443249599},{"_id":"themes/livemylife/layout/_partial/themecolor.ejs","hash":"fd4c8f2b3f2955bb867105991d45134798915526","modified":1610590761340},{"_id":"themes/livemylife/layout/_widget/archive.ejs","hash":"dc31e6cfde1b789d8550d7bfcac5d0eeae3ac6ab","modified":1610590761340},{"_id":"themes/livemylife/layout/_widget/category.ejs","hash":"1dc1187e7a04ee4be85bf302ea2618c1dbf6a570","modified":1610590761341},{"_id":"themes/livemylife/layout/_widget/friends-blog.ejs","hash":"069c8f53ae6710f4891af4cc3ed481e172357f80","modified":1610590761341},{"_id":"themes/livemylife/layout/_widget/featured-tags.ejs","hash":"a313e546c29243cfd59aa2dde0b4f99287613d31","modified":1610590761341},{"_id":"themes/livemylife/layout/_widget/recent-posts.ejs","hash":"34d9adc0926099cbd83c3da5c69e43740e56583b","modified":1610590761341},{"_id":"themes/livemylife/layout/_widget/visitor.ejs","hash":"1127ebcadc26a8b0db25c63110fd6d1123e6dd83","modified":1610590761342},{"_id":"themes/livemylife/layout/_widget/short-about.ejs","hash":"7d667e0bdfa79b1efb908c03b9ee175781345bc1","modified":1610654368882},{"_id":"themes/livemylife/source/css/beantech.min.css","hash":"fd6fc55396aca0fc85c0bfe1d037051bcce38598","modified":1613500489787},{"_id":"themes/livemylife/source/css/archive.styl","hash":"bcb216ef65804c97b1a5dbe5f519fc171a13aaf1","modified":1610590761345},{"_id":"themes/livemylife/source/css/catalog.styl","hash":"822aca17c885109452cc75a9aa384d9f3c07ea81","modified":1610590761349},{"_id":"themes/livemylife/source/css/gitalk.css","hash":"646a634ac252896d9e9f4d322d782e69c66d65ae","modified":1610590761350},{"_id":"themes/livemylife/source/css/highlight.styl","hash":"831f8195f3577ba5bea374f2e24b90054d445055","modified":1610590761350},{"_id":"themes/livemylife/source/css/beantech.css","hash":"bce245c3c8de02a7fda56d2c3dfc4ac529fcfbba","modified":1610590761346},{"_id":"themes/livemylife/source/css/highlight_normal.css","hash":"9885d5fb98646ca325ac790cfba6dc8a7be75fae","modified":1610590761350},{"_id":"themes/livemylife/source/css/hux-blog.min.css","hash":"1baef04de262aeb7023d835429b49a805ac4ab40","modified":1610590761351},{"_id":"themes/livemylife/source/css/livemylife.css","hash":"08e549c0aad0ff94a9fae8eb91900b03bd428eee","modified":1610590761352},{"_id":"themes/livemylife/source/css/scroll.css","hash":"ef16ea9eeb589e9334a0f071afb5f0cdaa34d69c","modified":1610590761353},{"_id":"themes/livemylife/source/css/signature.styl","hash":"ca77c660bac04862f8c72f8e02fa9bdd86401c01","modified":1610657532714},{"_id":"themes/livemylife/source/css/search.css","hash":"fea98c6afa4f0be1deedb7cb13a9cd6b3ab6e42c","modified":1610590761353},{"_id":"themes/livemylife/source/css/themecolor.css","hash":"57d910ec1707fd492cfcea7ebbb496cebe2078eb","modified":1611466014851},{"_id":"themes/livemylife/source/css/rocket.styl","hash":"5e3b4336496e01488bbb8f0bc444b9b24560482b","modified":1610590761353},{"_id":"themes/livemylife/source/css/top.css","hash":"7fe7d9d4434fe2bb7178e0f43977b3869b5c0fdf","modified":1610590761354},{"_id":"themes/livemylife/source/css/viewer.min.css","hash":"bb52e4168e5b740d04bcabe3833f42e98f8037da","modified":1610590761354},{"_id":"themes/livemylife/source/css/wave.css","hash":"fb939f76dc9a48d3a7e7384f64943dac710ad452","modified":1610590761354},{"_id":"themes/livemylife/source/css/widget.styl","hash":"f996466e299c68274145ba5afaca9b6d1dd83114","modified":1610590761355},{"_id":"themes/livemylife/source/fonts/glyphicons-halflings-regular.eot","hash":"86b6f62b7853e67d3e635f6512a5a5efc58ea3c3","modified":1610590761355},{"_id":"themes/livemylife/source/fonts/glyphicons-halflings-regular.woff","hash":"278e49a86e634da6f2a02f3b47dd9d2a8f26210f","modified":1610590761357},{"_id":"themes/livemylife/source/fonts/glyphicons-halflings-regular.ttf","hash":"44bc1850f570972267b169ae18f1cb06b611ffa2","modified":1610590761357},{"_id":"themes/livemylife/source/js/bootstrap.min.js","hash":"313da686ebbe387064f2d1899c64ea562b81eb40","modified":1610590761359},{"_id":"themes/livemylife/source/fonts/glyphicons-halflings-regular.woff2","hash":"ca35b697d99cae4d1b60f2d60fcd37771987eb07","modified":1610590761357},{"_id":"themes/livemylife/source/js/catalog.js","hash":"4e34f47053ece8c1a4ab4a8441760a3d33ea9fb8","modified":1610590761359},{"_id":"themes/livemylife/source/js/busuanzi.pure.mini.js","hash":"6e41f31100ae7eb3a6f23f2c168f6dd56e7f7a9a","modified":1610590761359},{"_id":"themes/livemylife/source/js/hux-blog.min.js","hash":"ee99af17a1a69ac8d85a695fed0349ba202789ae","modified":1610590761365},{"_id":"themes/livemylife/source/js/hux-blog.js","hash":"3d3c93e42a9990b2a2e6df5a08e9816f9a221e0f","modified":1610590761365},{"_id":"themes/livemylife/source/js/scroll.js","hash":"182250b3bee27de24099863f0973bb7971405464","modified":1610590761371},{"_id":"themes/livemylife/source/js/themecolor.js","hash":"af8f6d9b97f6511d55ce2266987a3540770f1f54","modified":1610590761371},{"_id":"themes/livemylife/source/js/jquery.nav.js","hash":"bc6383fa2aa8f437978cf044a3b6f10a65114398","modified":1610590761371},{"_id":"themes/livemylife/source/js/ziploader.js","hash":"f61a11e60be24cf0c64019ca4dc4dc49c325ed71","modified":1610590761373},{"_id":"themes/livemylife/source/js/totop.js","hash":"f796b09b4f6177c3674a8c1542a8c92e8590cb5c","modified":1610590761371},{"_id":"themes/livemylife/source/js/jquery.tagcloud.js","hash":"448017ff32f75f444ed7985d10a21b3ad92ab100","modified":1610590761371},{"_id":"source/_posts/AIA-ch1-Q-A/v_e_f_2.png","hash":"b773c3d82d422fe0ca7d76b2d1848d04dd7204d7","modified":1612293271040},{"_id":"source/_posts/AIA-ch3-Q-A/e2.png","hash":"09ef3e4fc9efc6c971ebeff268040b71ad7ad7df","modified":1612933774638},{"_id":"source/_posts/AIA-ch3-Q-A/e4.png","hash":"63b0b8e36a0a699a2a41d9248ab9176dd6baae67","modified":1612933284360},{"_id":"source/_posts/AIA-ch3-Q-A/e8.png","hash":"7b505c2366d5e7e91aefaca0968ba490f4732a78","modified":1612933817950},{"_id":"source/_posts/AIA-ch4-Q-A/Kruskal.png","hash":"a0668f2af80bab8411ea5ba89f2409aec60298e8","modified":1613692533522},{"_id":"source/_posts/AIA-ch4-Q-A/Prim.png","hash":"868a48290a8bd9002ca8073b9a132d4a046d9928","modified":1613692890426},{"_id":"source/_posts/AIA-ch4-Q-A/dij1.png","hash":"d647124fbb8c5f9f6dedc49b4093222d43ca3cb0","modified":1613713632854},{"_id":"source/_posts/AIA-ch4-Q-A/r5.png","hash":"0319de01288f8e91431ff4c85d533081e5c6c9e4","modified":1613713730397},{"_id":"themes/livemylife/source/css/bootstrap.min.css","hash":"e585e43f118677dd04111b2d5c12fd375eb8dc96","modified":1611796381724},{"_id":"themes/livemylife/source/fonts/glyphicons-halflings-regular.svg","hash":"4dcf0ab896f5417047f881de91bad10dcbda48c6","modified":1610590761356},{"_id":"themes/livemylife/source/js/bootstrap.js","hash":"5d69034fb6eded2e5961ea54dd47129a88cd5182","modified":1610590761358},{"_id":"themes/livemylife/source/js/jquery.min.js","hash":"17a740d68a1c330876c198b6a4d9319f379f3af2","modified":1610590761370},{"_id":"source/_posts/AIA-ch1-Q-A/ans_6.png","hash":"ae4b46c7a29be817c3a714ed9e82e96e6ba4cf2b","modified":1611551016903},{"_id":"source/_posts/AIA-ch1-Q-A/cruves.png","hash":"5d7d95fe2928fe72d1189470fb4aff1388a4a028","modified":1611339305966},{"_id":"source/_posts/AIA-ch1-Q-A/ans_7.png","hash":"f46094ccc0fa1dc18fa6a1202626871122758cbb","modified":1611551113536},{"_id":"source/_posts/AIA-ch4-Q-A/e7.png","hash":"1346138e7018b4a8a6035812438b504b4276168f","modified":1613713676039},{"_id":"themes/livemylife/source/css/bootstrap.css","hash":"d1a24afac31222d70b4e001e0361ef045aa42043","modified":1610590761348},{"_id":"themes/livemylife/source/css/images/beside_up.png","hash":"183d87f1a99e93fc663ec798fa8c94cb87c83bcb","modified":1610590761351},{"_id":"themes/livemylife/source/css/images/beside_up2.png","hash":"ef066ba2e93a4738df45ae05020726e066c4dd1f","modified":1610590761351},{"_id":"themes/livemylife/source/css/images/beside_up_white.png","hash":"49c5922a8de63dcf9468fbcffc70d2ec36b1b527","modified":1610590761352},{"_id":"themes/livemylife/source/css/images/beside_up_white2.png","hash":"52e9d5715def1d3d09ab076d5eb3d22916d8f7d7","modified":1610590761352},{"_id":"themes/livemylife/source/js/viewer/viewer.min.js","hash":"b09fff2aa41305e8975b9ef80514eb937ffa6866","modified":1610590761372},{"_id":"themes/livemylife/source/js/viewer/pic-viewer.js","hash":"3955cbca226b562f8dec96dc459ce22363affdde","modified":1610590761372},{"_id":"source/_posts/AIA-ch2-Q-A/s_c_graph.png","hash":"3ad7d2bb106746c5d099e0f74182f69250d5f62b","modified":1612292331900},{"_id":"source/_posts/AIA-ch2-Q-A/dequeue.png","hash":"4b1233a4125572dd9afecf3517382e702196cb18","modified":1612296754240},{"_id":"source/_posts/AIA-ch2-Q-A/binary_counter.png","hash":"2ae99260651869b510d0360ea94fe09fce2cef68","modified":1612662329036},{"_id":"source/_posts/AIA-ch4-Q-A/e5.png","hash":"ae1b2042ca6d53fd64fb41c962a11ec066bef263","modified":1613499617583},{"_id":"themes/livemylife/source/js/jquery.js","hash":"4bb763dc96da604aed08ac024a1a3f5de73eea39","modified":1610590761369},{"_id":"themes/livemylife/source/js/comment/gitalk.js","hash":"9e326313656b821751f486e31be8418e1578668a","modified":1610590761364},{"_id":"source/_posts/AIA-ch3-Q-A/heap.gif","hash":"366a3658ef590051972557e6152f458842e2f24e","modified":1612767841456},{"_id":"source/img/header_img/la.jpg","hash":"a43e322e76cac84e3b92995503ae08c8641b9611","modified":1611468716773},{"_id":"source/img/header_img/coast.jpg","hash":"d770c4659027f3d4fe479afb6909ed6968f56d68","modified":1610590761241},{"_id":"source/img/header_img/big_bear_lake.jpg","hash":"f009c33343e5a6dc8835a184fbc9e37a19d8ee7c","modified":1611468650865},{"_id":"source/img/header_img/404_bg.jpg","hash":"9a899c297a352c1664d0b7ec44d5fbc0c8c048fd","modified":1610590760926},{"_id":"source/img/header_img/sumset.jpg","hash":"c572aa5a4ed446f43c898c3864bf8b144844ef35","modified":1610590761203},{"_id":"source/img/header_img/snow.jpg","hash":"0cf9fb6a4fdad42dcc936dc9e90cfd3e5b7b8cef","modified":1610590761324},{"_id":"public/baidusitemap.xml","hash":"ebceaa7dfca2cfb41252a0db001926be41aebafa","modified":1613713792191},{"_id":"public/sitemap.xml","hash":"f844b8bbaf240c13b6279c70585661ae6ab404d7","modified":1613713792191},{"_id":"public/searchVersion.json","hash":"ed682f9e2e232bf5552ab0116f363ef330bc6cb8","modified":1613713792191},{"_id":"public/404.html","hash":"43e7e71b25af6628553ac02f46fea560ac147c5b","modified":1613713792191},{"_id":"public/categories/index.html","hash":"440485dab1605193961c135f074d97218d14e70e","modified":1613713792191},{"_id":"public/2021/02/15/AIA-ch4-Q-A/index.html","hash":"caf9d48dfaef67bc101a47aadaf5b3b33cfbffc2","modified":1613713792191},{"_id":"public/2021/02/06/AIA-ch3-Q-A/index.html","hash":"ccb0e0a9d61915902a730396f7c910750a8ae23b","modified":1613713792191},{"_id":"public/2021/01/24/AIA-ch2-Q-A/index.html","hash":"ff4c3d09f0f47611ff5ce54175cf795791c2e2d0","modified":1613713792191},{"_id":"public/2021/01/21/AIA-ch1-Q-A/index.html","hash":"ebadd991f63daf6f23f1630acc4a11643ee483d9","modified":1613713792191},{"_id":"public/about/index.html","hash":"7a63c4be78138c2b57b1b310034edc544ad5011c","modified":1613713792191},{"_id":"public/archives/index.html","hash":"0a79bab24045e8c84bea3323cf3fee31feab4a19","modified":1613713792191},{"_id":"public/archives/2021/index.html","hash":"233f4dff5b125489a291e0ba805599cd1b4b7bbb","modified":1613713792191},{"_id":"public/archives/2021/01/index.html","hash":"42a76178db66429fd04b82f70af00be30ff80223","modified":1613713792191},{"_id":"public/archives/2021/02/index.html","hash":"e4e5d0273d16410382fc2e855dc19f7eb142b745","modified":1613713792191},{"_id":"public/index.html","hash":"69bd1099d71e35096df261de6c900641fea6f3df","modified":1613713792191},{"_id":"public/categories/CSCI-570/index.html","hash":"3f582275a4117ad5881c8af14f64ce4f108496af","modified":1613713792191},{"_id":"public/tags/Review/index.html","hash":"502788149284d88fe94cc0a48e322290647caead","modified":1613713792191},{"_id":"public/tags/Graph/index.html","hash":"1babd2e18ae67b7aa097aed0cc47b94a07fe42c2","modified":1613713792191},{"_id":"public/tags/Q-A/index.html","hash":"28593ad390bc324823ff98948bf12c881fb29a03","modified":1613713792191},{"_id":"public/tags/Amortized-Analysis/index.html","hash":"91479118545b39f6d20886e67f3f224090db3530","modified":1613713792191},{"_id":"public/tags/Greedy-Algorithm/index.html","hash":"4782ff3751e1db33434e27d954ef6b568d0e253d","modified":1613713792191},{"_id":"public/tags/Heap/index.html","hash":"20bf80aed2c1d9f476a456e285fb8497aff21571","modified":1613713792191},{"_id":"public/CNAME","hash":"7b594a7c935c9222219cc5308d747e7e21c1b667","modified":1613713792191},{"_id":"public/LICENSE","hash":"b314c7ebb7d599944981908b7f3ed33a30e78f3a","modified":1613713792191},{"_id":"public/img/avatar/mona_lisa.ico","hash":"e50aff0c7c92a9e14c125c2d0113734122464631","modified":1613713792191},{"_id":"public/img/avatar/mona_lisa.jpg","hash":"5e72c3d1e1c574600547887228de5661ac41f370","modified":1613713792191},{"_id":"public/img/icon/lecture.png","hash":"2df60358a9b17e702e4fc0728e38a067cd327a0f","modified":1613713792191},{"_id":"public/img/signature/ay-white.png","hash":"5bd0f949ba4c89eb08bf505aa614e406ac0026bb","modified":1613713792191},{"_id":"public/img/signature/ay-white-2.png","hash":"c5761fb500a13a2554894d23583d41608176acf9","modified":1613713792191},{"_id":"public/fonts/glyphicons-halflings-regular.eot","hash":"86b6f62b7853e67d3e635f6512a5a5efc58ea3c3","modified":1613713792191},{"_id":"public/fonts/glyphicons-halflings-regular.woff","hash":"278e49a86e634da6f2a02f3b47dd9d2a8f26210f","modified":1613713792191},{"_id":"public/fonts/glyphicons-halflings-regular.ttf","hash":"44bc1850f570972267b169ae18f1cb06b611ffa2","modified":1613713792191},{"_id":"public/fonts/glyphicons-halflings-regular.woff2","hash":"ca35b697d99cae4d1b60f2d60fcd37771987eb07","modified":1613713792191},{"_id":"public/css/images/beside_up.png","hash":"183d87f1a99e93fc663ec798fa8c94cb87c83bcb","modified":1613713792191},{"_id":"public/css/images/beside_up2.png","hash":"ef066ba2e93a4738df45ae05020726e066c4dd1f","modified":1613713792191},{"_id":"public/css/images/beside_up_white.png","hash":"49c5922a8de63dcf9468fbcffc70d2ec36b1b527","modified":1613713792191},{"_id":"public/css/images/beside_up_white2.png","hash":"52e9d5715def1d3d09ab076d5eb3d22916d8f7d7","modified":1613713792191},{"_id":"public/2021/01/24/AIA-ch2-Q-A/lecture.png","hash":"2df60358a9b17e702e4fc0728e38a067cd327a0f","modified":1613713792191},{"_id":"public/2021/01/21/AIA-ch1-Q-A/ans_5.png","hash":"aba9f9b28d63f7d2009c56bb102819537281d0da","modified":1613713792191},{"_id":"public/2021/01/21/AIA-ch1-Q-A/fn_gn.png","hash":"f6b1ae0be19723be39d055b4ffdc65a3de516807","modified":1613713792191},{"_id":"public/2021/01/21/AIA-ch1-Q-A/lecture.png","hash":"2df60358a9b17e702e4fc0728e38a067cd327a0f","modified":1613713792191},{"_id":"public/2021/02/15/AIA-ch4-Q-A/lecture.png","hash":"2df60358a9b17e702e4fc0728e38a067cd327a0f","modified":1613713792191},{"_id":"public/2021/02/15/AIA-ch4-Q-A/r10.png","hash":"9c7d738c977f736e61273631eefa53e66d66cf8a","modified":1613713792191},{"_id":"public/2021/02/15/AIA-ch4-Q-A/r12.png","hash":"50b73e5899a29cc0d791c5c630f37b55ad3b6ede","modified":1613713792191},{"_id":"public/2021/02/15/AIA-ch4-Q-A/r2.png","hash":"8b14fff1455518337c58e7819a18a8775aa43c36","modified":1613713792191},{"_id":"public/2021/02/06/AIA-ch3-Q-A/BT.png","hash":"a332af1ffea545d8c697f8877af25a5bcfba571a","modified":1613713792191},{"_id":"public/2021/02/06/AIA-ch3-Q-A/e4.png","hash":"63b0b8e36a0a699a2a41d9248ab9176dd6baae67","modified":1613713792191},{"_id":"public/2021/02/06/AIA-ch3-Q-A/heap_table.png","hash":"b73c1d9847760bc6c9838c927e61fafe97eb6c35","modified":1613713792191},{"_id":"public/2021/02/06/AIA-ch3-Q-A/lecture.png","hash":"2df60358a9b17e702e4fc0728e38a067cd327a0f","modified":1613713792191},{"_id":"public/fonts/glyphicons-halflings-regular.svg","hash":"4dcf0ab896f5417047f881de91bad10dcbda48c6","modified":1613713792191},{"_id":"public/2021/02/15/AIA-ch4-Q-A/Kruskal.png","hash":"a0668f2af80bab8411ea5ba89f2409aec60298e8","modified":1613713792191},{"_id":"public/2021/01/21/AIA-ch1-Q-A/v_e_f_2.png","hash":"b773c3d82d422fe0ca7d76b2d1848d04dd7204d7","modified":1613713792191},{"_id":"public/2021/02/15/AIA-ch4-Q-A/Prim.png","hash":"868a48290a8bd9002ca8073b9a132d4a046d9928","modified":1613713792191},{"_id":"public/2021/02/15/AIA-ch4-Q-A/dij1.png","hash":"d647124fbb8c5f9f6dedc49b4093222d43ca3cb0","modified":1613713792191},{"_id":"public/2021/02/15/AIA-ch4-Q-A/r5.png","hash":"0319de01288f8e91431ff4c85d533081e5c6c9e4","modified":1613713792191},{"_id":"public/2021/02/06/AIA-ch3-Q-A/e2.png","hash":"09ef3e4fc9efc6c971ebeff268040b71ad7ad7df","modified":1613713792191},{"_id":"public/2021/02/06/AIA-ch3-Q-A/e8.png","hash":"7b505c2366d5e7e91aefaca0968ba490f4732a78","modified":1613713792191},{"_id":"public/css/archive.css","hash":"8db895ebaeff19ac145c961abcfd5d4a8d67a8ea","modified":1613713792191},{"_id":"public/css/catalog.css","hash":"2062bf4e5b219654e0d4bf470f5eef1be213da95","modified":1613713792191},{"_id":"public/css/highlight.css","hash":"03d1f0a648e9bdf7b1f57d217313cbac5d0c7eb1","modified":1613713792191},{"_id":"public/css/highlight_normal.css","hash":"6a40a9a0f268fb17d9002cb49a16946444ef5f34","modified":1613713792191},{"_id":"public/css/livemylife.css","hash":"dbf2b89627f55e7f8ef12730e822319859f25767","modified":1613713792191},{"_id":"public/css/signature.css","hash":"47d91f966a30d393aee44cec9bdba0a26e53dd35","modified":1613713792191},{"_id":"public/css/scroll.css","hash":"ba16b97532dd6aaec66a82f3c33cc989d361fa7a","modified":1613713792191},{"_id":"public/css/rocket.css","hash":"ec8abdba1cdd362d03fd8ffe182213aa4cbd449c","modified":1613713792191},{"_id":"public/css/search.css","hash":"a941f2f3d05d43e0a1517ae6923e848638b9ff7c","modified":1613713792191},{"_id":"public/css/wave.css","hash":"041f3b4a78e2840ba17679cea05fb14bb646722f","modified":1613713792191},{"_id":"public/css/viewer.min.css","hash":"0e045aa3df1be7d138caa701ec3aa623ccc7a52d","modified":1613713792191},{"_id":"public/css/top.css","hash":"0303375fbe2ca942cd3d86f31d12fef9bf5785af","modified":1613713792191},{"_id":"public/css/widget.css","hash":"da95ad3f1938f24d20f1fa77d7a38f0c392b5ec8","modified":1613713792191},{"_id":"public/js/catalog.js","hash":"059f3f31492e5b1a9dddf422a48c32969d247415","modified":1613713792191},{"_id":"public/js/busuanzi.pure.mini.js","hash":"6e41f31100ae7eb3a6f23f2c168f6dd56e7f7a9a","modified":1613713792191},{"_id":"public/js/hux-blog.min.js","hash":"1563e7f70550ac6b30803d6f449719b853200e35","modified":1613713792191},{"_id":"public/js/scroll.js","hash":"265a4c4fc33b5b44b620db64ff31d2bc05d233e9","modified":1613713792191},{"_id":"public/js/hux-blog.js","hash":"4b4d3c557405d04c3087d36c13e2834fe05c0f73","modified":1613713792191},{"_id":"public/js/jquery.nav.js","hash":"ef2160a456176a4d09cc0b95d52b27dfbbadf2d8","modified":1613713792191},{"_id":"public/js/totop.js","hash":"c05360f6fc699ac12e794b1764b4a952713a3017","modified":1613713792191},{"_id":"public/js/themecolor.js","hash":"8295e112233778d8f20c31b06c19659f60edbb22","modified":1613713792191},{"_id":"public/js/jquery.tagcloud.js","hash":"4e5fd0b07f3bd935f2e603710447e039e3677211","modified":1613713792191},{"_id":"public/js/viewer/pic-viewer.js","hash":"9bf7c37cce781628346803ed7ce8f02623c2d013","modified":1613713792191},{"_id":"public/css/beantech.min.css","hash":"72f04fb959945036bc0097cab17ed0605770c6cb","modified":1613713792191},{"_id":"public/css/hux-blog.min.css","hash":"1baef04de262aeb7023d835429b49a805ac4ab40","modified":1613713792191},{"_id":"public/css/beantech.css","hash":"c192d3170301f774fa4c2185dc125cb3d6ec4929","modified":1613713792191},{"_id":"public/css/gitalk.css","hash":"51783fd60dff05e8e339ff83b41504538662f6ca","modified":1613713792191},{"_id":"public/css/themecolor.css","hash":"04e045215c6132af46eb7a85fd0aae3d9302312c","modified":1613713792191},{"_id":"public/js/bootstrap.min.js","hash":"b3f2ef9f985e7906c9360756b73cd64bf7733647","modified":1613713792191},{"_id":"public/js/ziploader.js","hash":"9c25324caf53b56cb68839dcfb34e61e5a6a63f3","modified":1613713792191},{"_id":"public/js/bootstrap.js","hash":"f8752e9ae24daec0a0baffd7819122f8c6fd9103","modified":1613713792191},{"_id":"public/css/bootstrap.min.css","hash":"e908927337273ee3d4c36c4d989c299f9cc64445","modified":1613713792191},{"_id":"public/css/bootstrap.css","hash":"41c54bf695145ae0b4d9020a1da308ceb05dcaf3","modified":1613713792191},{"_id":"public/js/jquery.min.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1613713792191},{"_id":"public/js/viewer/viewer.min.js","hash":"ae5380974b6fb8b0e15356c8418186c6c0821222","modified":1613713792191},{"_id":"public/js/jquery.js","hash":"1852661bd11a09ca9b9cb63d1aa6ff390fffaf4e","modified":1613713792191},{"_id":"public/2021/01/21/AIA-ch1-Q-A/ans_6.png","hash":"ae4b46c7a29be817c3a714ed9e82e96e6ba4cf2b","modified":1613713792191},{"_id":"public/2021/01/21/AIA-ch1-Q-A/ans_7.png","hash":"f46094ccc0fa1dc18fa6a1202626871122758cbb","modified":1613713792191},{"_id":"public/2021/02/15/AIA-ch4-Q-A/e7.png","hash":"1346138e7018b4a8a6035812438b504b4276168f","modified":1613713792191},{"_id":"public/2021/01/24/AIA-ch2-Q-A/s_c_graph.png","hash":"3ad7d2bb106746c5d099e0f74182f69250d5f62b","modified":1613713792191},{"_id":"public/2021/02/15/AIA-ch4-Q-A/e5.png","hash":"ae1b2042ca6d53fd64fb41c962a11ec066bef263","modified":1613713792191},{"_id":"public/js/comment/gitalk.js","hash":"9256bc4b8f7341f60083da291d5c7c9f0fe5f1bd","modified":1613713792191},{"_id":"public/2021/01/21/AIA-ch1-Q-A/cruves.png","hash":"5d7d95fe2928fe72d1189470fb4aff1388a4a028","modified":1613713792191},{"_id":"public/2021/01/24/AIA-ch2-Q-A/dequeue.png","hash":"4b1233a4125572dd9afecf3517382e702196cb18","modified":1613713792191},{"_id":"public/2021/01/24/AIA-ch2-Q-A/binary_counter.png","hash":"2ae99260651869b510d0360ea94fe09fce2cef68","modified":1613713792191},{"_id":"public/img/header_img/la.jpg","hash":"a43e322e76cac84e3b92995503ae08c8641b9611","modified":1613713792191},{"_id":"public/2021/02/06/AIA-ch3-Q-A/heap.gif","hash":"366a3658ef590051972557e6152f458842e2f24e","modified":1613713792191},{"_id":"public/img/header_img/coast.jpg","hash":"d770c4659027f3d4fe479afb6909ed6968f56d68","modified":1613713792191},{"_id":"public/img/header_img/big_bear_lake.jpg","hash":"f009c33343e5a6dc8835a184fbc9e37a19d8ee7c","modified":1613713792191},{"_id":"public/img/header_img/404_bg.jpg","hash":"9a899c297a352c1664d0b7ec44d5fbc0c8c048fd","modified":1613713792191},{"_id":"public/img/header_img/sumset.jpg","hash":"c572aa5a4ed446f43c898c3864bf8b144844ef35","modified":1613713792191},{"_id":"public/img/header_img/snow.jpg","hash":"0cf9fb6a4fdad42dcc936dc9e90cfd3e5b7b8cef","modified":1613713792191}],"Category":[{"name":"CSCI 570","_id":"cklbvizoo0003xctt04n4ckk3"}],"Data":[],"Page":[{"layout":"404","description":"uhhhhhh... 你都点到哪里去了，麻溜的后退一步。 赶快！ ","header-img":"img/header_img/404_bg.jpg","_content":"","source":"404.md","raw":"---\nlayout: 404\ndescription: \"uhhhhhh... 你都点到哪里去了，麻溜的后退一步。 赶快！ \"\nheader-img: \"img/header_img/404_bg.jpg\"\n---\n","date":"2021-01-14T06:53:32.617Z","updated":"2021-01-14T06:53:32.617Z","path":"404.html","title":"","comments":1,"_id":"cklbviznj0000xcttc3hbe212","content":"","site":{"data":{}},"excerpt":"","more":""},{"layout":"categories","title":"Categories|分类","description":"","header-img":"img/header_img/coast.jpg","_content":"","source":"categories/index.md","raw":"---\nlayout: \"categories\"\ntitle: \"Categories|分类\"\ndescription: \"\"\nheader-img: \"img/header_img/coast.jpg\"\n---\n","date":"2021-01-24T06:07:29.950Z","updated":"2021-01-24T06:07:29.950Z","path":"categories/index.html","comments":1,"_id":"cklbvizpa000txcttbtfn52ki","content":"","site":{"data":{}},"excerpt":"","more":""},{"layout":"about","title":"About|关于","date":"2021-01-14T06:48:33.000Z","description":"If it hurts, it works. 疼！那就对了。","header-img":"img/header_img/la.jpg","_content":"\n## 搞那么复杂\n我叫杨博(Aaron也可以)\n","source":"about/index.md","raw":"---\nlayout: \"about\"\ntitle: \"About|关于\"\ndate: 2021-01-13 22:48:33\ndescription: \"If it hurts, it works. 疼！那就对了。\"\nheader-img: \"img/header_img/la.jpg\"\n---\n\n## 搞那么复杂\n我叫杨博(Aaron也可以)\n","updated":"2021-01-24T06:06:59.780Z","path":"about/index.html","comments":1,"_id":"cklbvizpb000uxctt3c9n9m5h","content":"<h2 id=\"搞那么复杂\"><a href=\"#搞那么复杂\" class=\"headerlink\" title=\"搞那么复杂\"></a>搞那么复杂</h2><p>我叫杨博(Aaron也可以)</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"搞那么复杂\"><a href=\"#搞那么复杂\" class=\"headerlink\" title=\"搞那么复杂\"></a>搞那么复杂</h2><p>我叫杨博(Aaron也可以)</p>\n"}],"Post":[{"title":"$$[Algorithms \\, In \\, Action]-CH1\\,Review$$","catalog":true,"mathjax":true,"date":"2021-01-21T19:03:51.000Z","subtitle":null,"header-img":"cruves.png","_content":"\nFor any monotonic functions, *f*, *g* from the positive integers to the positive integers, we say **f(n) = O(g(n))** or **f(n) = Ω(g(n))** or **f(n) = Θ(g(n))**\n\n### Concepts\n  - **T(n)** counts the \\# of steps, where *n* is the input size.\n  - **O** big O, $$\\exists \\, c $$ which *c* > 0 and real number $${n_0}$$, has $$f(n) \t\\leqslant c \\cdot g(n)$$, for all  $$n \\geqslant {n_0}$$.\n  - **Ω** big Omega, $$\\exists \\, c $$ which *c* > 0 and real number $${n_0}$$, has $$f(n) \t\\geqslant c \\cdot g(n)$$, for all  $$n \\geqslant {n_0}$$.\n  - **Θ** big Theta, $$\\exists \\, {c_1} \\, and \\, {c_2} $$ which $${c_1}$$ > 0 and $${c_2}$$ > 0 and real number $${n_0}$$, has $${c_1} \\cdot g(n) \\leqslant f(n)\t\\leqslant {c_2} \\cdot g(n)$$, for all  $$n \\geqslant {n_0}$$.\n\n![as](fn_gn.png)\n  \n### Theorems\n  - *G = (V, E), the following statements are equivalent:*<img src=\"lecture.png\" style=\"width:30px;display:inline;box-shadow: none !important;\">\n    > 1. G is a tree.\n    > 2. Every two vertices of G are connected by a unique path\n    > 3. G is connected and V = E + 1\n    > 4. G is acyclic and V = E + 1\n    > 5. G is acyclic and if any two non-adjacent vertices are joined by an edge, the resulting graph has exactly one cycle. \n  - *In an undirected simple graph G = (V, E), there are at most $$\\frac{V \\cdot (V - 1)}{2}$$ edges. In short, by using the asymptotic notation, $$E = O(V^2)$$.*\n  - *three way to traversal a graph:*\n    > 1. depth-first-search\n    > 2. breadth-first-search\n    > 3. topological sort\n      - the result of topological sort is not unique\n  -  *If G is a connected planar graph with V vertices, E edges, and F faces, then V - E + F = 2*\n    > faces represent disjoint area.\n    <img src=\"v_e_f_2.png\"  style=\"display:inline;box-shadow: none !important;\">\n  - *In any simple connected planar graph with at least 3 vertices, $$E < 3 \\cdot V - 6$$*\n  - *A simple connected planar graph with at least 3 vertices has a vertex of degree 5 or less.*\n  - *[Coloring Planar Graph] every planar graph can be colored with at most six colors.*\n  - *A graph is bipartite if and only if it dose not contain an odd length cycle.*\n  - *A connected graph G is a Eulerian graph if and only if all vertices of G are of even degree*\n\n### Review Q&A\n1. Mark the following assertions as TRUE or FALSE. No need to provide any justification.<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\">\n  - a. $$n = O(n^2)$$\n    > - **True**. since $$f(n) = n \\, and \\, g(n) = n^2 $$ and this is big O annotation, which requires $$f(n) \t\\leqslant c \\cdot g(n)$$ when  $$n \\geqslant {n_0}$$. <br>In the issue, $$n <= c \\cdot n^2$$, meets the requirements, so it is correct.\n  - b. $$n = O( \\sqrt[2]{n})$$\n    > - **False**. $$n >= c \\cdot \\sqrt[2]{n}$$ should use Ω\n  - c. $$log(n) = Ω(n)$$\n    > - **False**. $$log(n) <= c \\cdot n$$ should use O\n  - d. $$n^2 = \\Omega(n \\cdot log(n))$$\n    > - **True**. $$n^2 >= c \\cdot n \\cdot log(n)$$\n  - e. $$n^2 \\cdot log(n) = \\Theta(n^2)$$\n    > - **False**. $$n^2 \\cdot log(n) >= n^2 $$ should use $$\\Omega$$\n  - f. $$7 \\cdot (log(n))^2 + 2n \\cdot log(n) = Ω(log(n))$$\n    > - **True**. let $$A = log(n)$$, so we have $$7A^2 + 2 \\cdot n \\cdot A >= A$$\n  - g. $$5n \\cdot log(n) + 1024 n \\cdot log(log(n)) = Θ(n \\cdot log(n))$$\n    > - **True**. let $$A = log(n)$$,<br> so we have $$5 \\cdot n \\cdot A + 1024 \\cdot n \\cdot log(A) = \\Theta(n \\cdot A)$$. not easy to compare. but we already knew log(n) < n. <br> So $$5 \\cdot n \\cdot A + 1024 \\cdot n \\cdot log(A) < 5 \\cdot n \\cdot A + 1024 \\cdot n \\cdot A$$. <br> let $$B = n \\cdot log(n) $$, we will have $$5 \\cdot B + 1024 \\cdot B = 1029B \\, v.s. \\Theta(B)$$. <br>f(n) = 1029B, g(n) = B. There exist many $${c_1} \\, {c_2}$$ could meet $${c_1} \\cdot g(n) \\leqslant f(n)\t\\leqslant {c_2} \\cdot g(n)$$.\n  - h. $$2^n + 100 \\cdot n^2 + n^{100}= O(n^{101})$$\n    > - **False**. u can see the head img. $$2^n$$ grow faster than $$n^{100}$$. so left part bigger than right. <br>The statement is wrong, and should use $$\\Omega$$\n  - i. $$(1/3)^n + 100 = O(1)$$\n    > - **False**. $$(1/3)^n$$ will going to zero when n > 0. the left part will never beat the 101. so LHS is smaller or bigger than RHS when choose different *c*. Thus the statement is wrong.\n2. **(T/F)** Any function which is $$Ω(log(n))$$ is also $$Ω(log(log(n)))$$.<img src=\"lecture.png\" style=\"width:30px;display:inline;box-shadow: none !important;\">\n  > - **True**. Assume there is a f(n) >= c * log(n).<br>\n  and we also knew, log(n) > log(log(n)) in any suitation. so we have f(n) >= c * log(n) > c * log(log(n)). \n3. **(T/F)** If f(n) = Θ(g(n)) then g(n) = Θ(f(n))<img src=\"lecture.png\" style=\"width:30px;display:inline;box-shadow: none !important;\">\n  > - **True**. becasue f(n) = Θ(g(n)), we have $$c_1 \\cdot g(n) <= f(n) <= c_2 \\cdot g(n)$$. LHS multiplt $$1 / c_1$$ => $$g(n) <= \\frac{1}{c_1}f(n)$$. RHS multiplt $$1 / c_2$$ => $$\\frac{1}{c_2}f(n) <= g(n)$$. <br>In all, we have $$\\frac{1}{c_2}f(n) <= g(n) <= \\frac{1}{c_1}f(n) \\, $$ => $$\\, b_1f(n) <= g(n) <= b_2f(n)$$\n4. **(T/F)** If f(n) = Θ(g(n)) then f(n) = Ω(g(n)).\n  > - **True**. becasue f(n) = Θ(g(n)), we have $$c_1 \\cdot g(n) <= f(n) <= c_2 \\cdot g(n)$$. LHS is what you need. so this is true.\n5. **(T/F)** If f(n) = Ω(g(n)) then $$2^{f(n)} = Ω(2^{g(n)})$$.<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\">\n  > - **False** prove it by contradiction. <br>\n  e.g. f(n) = 2n, g(n) = 4n. when c = 0.25. f(n) >= c * g(n). <br>\n  but $$2^{f(n)} = 4^n, 2^{g(n)} = 16^n$$, $$2^{f(n)} <= 2^{g(n)}$$. so this statement is wrong.\n6. **(T/F)** BFS can be used to find the shortest path between any two nodes in a non-weighted graph.\n  > - **True**. as the professor said. BFS find node in level order.\n7. **(T/F)** A DFS tree is never the same as a BFS tree.\n  > - **False**. could be the same.\n8. **(T/F)** Algorithm A has a running time of $$O(n^2)$$ and algorithm B has a running time of $$O(n \\cdot log(n)).$$ From this we conclude that A can never run faster than B on the same input.\n  > - **False**. Big O annotation is just telling you the maximum time that your algorithm will cost. But when running in real life, the actual data could be easily handled. \n9. **(T/F)** Planar graph is a sparse graph.\n  > - **False**. could be a dense graph.\n10. **(T/F)** Every DAG contains a vertex with no incoming edges.\n  > - **True**. DAG (directed acyclic graph) cannot has a circle.\n\n### Exercise Q&A\n1. Prove g(n) = Ω(f(n)) if and only if f(n) = O(g(n)).\n  > - **Solution** To prove a theorem of the form *A IF AND ONLY IF B*, you first prove *IF A THEN B*, then you prove *IF B THEN A*, and that's enough to complete the proof. \n  >> **Proof**\n  >> - $A \\rightrightarrows B$\n  >>> g(n) = Ω(f(n)), means g(n) >=  c \\* f(n), c > 0 <br>\n    we multiply 1 / c on both side, and we have $$\\frac{1}{c} \\cdot g((n)$$ >= f(n) which equals to <br>  f(n) <= $${b} \\cdot g((n)$$, *b* > 0 , so we can say f(n) = O(g(n)).\n  >> - $B \\leftleftarrows A$\n  >>> f(n) = O(g(n)), means f(n) <= c \\* g(n), c > 0 <br>\n    we multiply 1 / c on both side, and we have $$\\frac{1}{c} \\cdot f((n)$$ <= g(n) which equals to <br>  g(n) >= $${b} \\cdot f((n)$$, *b* > 0 , so we can say g(n) = Ω(f(n)).\n\n2. Prove or disprove f(n) = O(g(n)) implies $$2^{f(n)} = O(2^{g(n)})$$.<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\">\n  > - **Solution** prove it by contradiction. <br>\n  e.g. f(n) = 2n, g(n) = n. when c = 4. f(n) <= c \\* g(n).<br> \n  but $$2^{f(n)} = 4^n, 2^{g(n)} = 2^n$$, $$2^{f(n)} >= 2^{g(n)}$$. so this statement is wrong.\n\n3. Arrange the following functions<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\">\n$$log(n^n),\\, n^2,\\, n^{log(n)},\\, nlog(log(n)),\\, 2^{log(n)},\\, (log(n))^2,\\, n^{\\sqrt{2}}$$\nin increasing order of growth rate, with g(n) following f(n) in your list if and only if f(n) = O(g(n)).\n  > - **Solution** we can follow this order\n  $O(1) <= O(log(n)) <= O((log(n))^C) <= O(C^{log(n)}) <= O(n) <= O(n \\cdot log(n)) <= O(n^C) <= O((log(n))!) <= O(n^{log(n)}) <= O(C^n)$\n  And we can simply some of them in first place.\n  $$① \\, log(n^n) = n \\cdot log(n) \\, ⑤ \\, 2^{log_2 n} = log_2 2^n = n \\cdot 1 = n$$,\n  So , finally, we have <br>\n  $nlog(n),\\, n^2,\\, n^{log(n)},\\, nlog(log(n)),\\, n,\\, (log(n))^2,\\, n^{\\sqrt{2}}$ <br>\n  $O(1) \\Rightarrow None$\n  $O(log(n)) \\Rightarrow None$\n  $O((log(n))^C) \\Rightarrow ⑥$\n  $O(C^{log(n)}) \\Rightarrow None$\n  $O(n) \\Rightarrow ⑤$\n  $O(n \\cdot log(n)) \\Rightarrow ①④ since \\, n > log(n) \\Rightarrow ④①$\n  $O(n^C) \\Rightarrow ②⑦ since \\, \\sqrt(2) < 2 \\, and \\, log(n)\\, grow \\,slower \\,than \\,exponential \\,func $\n  $\\quad especially \\,when \\,a > 1 \\, so, ⑦②$\n  $O((log(n))!) \\Rightarrow None$\n  $O(n^{log(n)}) \\Rightarrow ③$\n  $O(C^n) \\Rightarrow None$<br>\n  the answers is: ⑥<⑤<④<①<⑦<②<③\n  $(log(n))^2,\\, 2^{log(n)},\\, nlog(log(n)),\\, log(n^n),\\, n^{\\sqrt{2}}, \\, n^2,\\, n^{log(n)}$\n\n4. Arrange the following functions\n$$4^{log(n)},\\, \\sqrt{log(n)},\\, n^{log(log(n))},\\, (\\sqrt{2})^{log(n)},\\, 2^{\\sqrt{2log(n)}},\\, n^{1/log(n)},\\, (log(n))!$$\nin increasing order of growth rate with g(n) following f(n) in your list if and only if f(n) = O(g(n)).<img src=\"lecture.png\" style=\"width:30px;display:inline;box-shadow: none !important;\">\n  > - **Solution** we can follow this order\n  $O(1) <= O(log(n)) <= O((log(n))^C) <= O(C^{log(n)}) <= O(n) <= O(n \\cdot log(n)) <= O(n^C) <= O((log(n))!) <= O(n^{log(n)}) <= O(C^n)$\n  And we can simply some of them in first place.\n  $$① \\, 4^{log_2 n} = (2^2)^{log(n)} = 2^{2*log(n)} = 2^{log(n^2)} = log_2 2^{n^2} = n^2$$,<br>\n  $$⑥ \\, n^{1/log(n)} = n^{log_2 2/log_2 n} = n^{log_n 2} = 2$$,\n  So , finally, we have <br>\n  $n^2, \\, \\sqrt{log(n)},\\, n^{log(log(n))},\\, (\\sqrt{2})^{log(n)},\\, 2^{\\sqrt{2log(n)}},\\, 2, \\, (log(n))!$ <br>\n  $O(1) \\Rightarrow ⑥$\n  $O(log(n)) \\Rightarrow None$\n  $O((log(n))^C) \\Rightarrow ②$\n  $O(C^{log(n)}) \\Rightarrow ④⑤ \\quad (\\sqrt{2})^{log(n)} = 2^{log(n) / 2} $\n  $\\quad \\,we \\, can \\, just \\, compare \\, log(n) / 2 \\, v.s. \\sqrt{2 \\cdot log(n)} \\, so, ⑤④$\n  $O(n) \\Rightarrow None$\n  $O(n \\cdot log(n)) \\Rightarrow None$\n  $O(n^C) \\Rightarrow ①$\n  $O((log(n))!) \\Rightarrow ⑦$\n  $O(n^{log(n)}) \\Rightarrow ③$\n  $O(C^n) \\Rightarrow None$ <br>\n  the answers is: ⑥<②<⑤<④<①<⑦<③\n  $(log(n))^2,\\, 2^{log(n)},\\, nlog(log(n)),\\, log(n^n),\\, n^{\\sqrt{2}}, \\, n^2,\\, n^{log(n)}$\n\n5. What is the Big-O runtime complexity of the following function?<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\">\n  ```\n  void bigOh1 (int n):\n    for i=1 to n\n      j=1;\n      while j < n\n        j = j*2;\n  ```\n  > - **Solution** $$O(n \\cdot log(n))$$\n  > <img src=\"ans_5.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n6. What is the Big-O runtime complexity of the following function?<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\">\n  ```\n  string bigOh3 (int n):\n    if(n == 0) return \"a\";\n    string str = bigOh3(n-1);\n    return str + str;\n  ```\n  > - **Solution** $$O(n \\cdot 2^n)$$\n  > <img src=\"ans_6.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n7. What is the Big-Theta runtime complexity of the following function? Here *find_max* finds the maximum element in the array L[0], L[1], …, L[n - 1].<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\">\n  ```\n  void bigOh2 (int[] L, int n):\n    while (n > 0)\n      find_max(L, n);\n      n = n/4;\n  ```\n  > - **Solution**\n  > <img src=\"ans_7.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n8. The complete graph on n vertices, denoted $$K_n$$, is a simple graph in which there is an edge between every pair of distinct vertices. What is the height of the DFS tree for the complete graph $$K_n$$? What is the height of the BFS tree for the complete graph $$K_n$$?\n  > - **Solution**\n\n9. We are interested in finding a simple path in a directed acyclic graph that visits all vertices once and only once. Design a linear time algorithm to determine if there is such a path in a given DAG.\n  > - **Solution**\n\n10. Prove that a complete graph $$K_5$$ is not a planar graph.\n  > - **Solution**\n\n11. Prove that a complete bipartite graph $$K_{3,3}$$ is not a planar graph.\n  > - **Solution**\n\n12. In a connected bipartite graph, is the bipartition unique? Justify your answer.\n  > - **Solution**\n\n13. Given a directed graph G = (V, E) and a particular node v ∈ V, design a linear time algorithm to determine whether v is in a triangle of edges (a cycle of length 3).\n  > - **Solution**\n\n14. Design a linear time algorithm which, given an undirected graph G = (V, E) and a particular edge e ∈ E, determines whether G has a cycle containing e.\n  > - **Solution**\n\n15. Given an undirected graph G = (V, E), prove that S is an independent set if and only if V - S is a vertex cover\n  > - **Solution**\n\n","source":"_posts/AIA-ch1-Q-A.md","raw":"---\ntitle: $$[Algorithms \\, In \\, Action]-CH1\\,Review$$\ncatalog: true\nmathjax: true\ndate: 2021-01-21 11:03:51\nsubtitle:\nheader-img: cruves.png\ntags:\n- Review\n- Graph\n- Q&A\ncategories:\n- CSCI 570\n---\n\nFor any monotonic functions, *f*, *g* from the positive integers to the positive integers, we say **f(n) = O(g(n))** or **f(n) = Ω(g(n))** or **f(n) = Θ(g(n))**\n\n### Concepts\n  - **T(n)** counts the \\# of steps, where *n* is the input size.\n  - **O** big O, $$\\exists \\, c $$ which *c* > 0 and real number $${n_0}$$, has $$f(n) \t\\leqslant c \\cdot g(n)$$, for all  $$n \\geqslant {n_0}$$.\n  - **Ω** big Omega, $$\\exists \\, c $$ which *c* > 0 and real number $${n_0}$$, has $$f(n) \t\\geqslant c \\cdot g(n)$$, for all  $$n \\geqslant {n_0}$$.\n  - **Θ** big Theta, $$\\exists \\, {c_1} \\, and \\, {c_2} $$ which $${c_1}$$ > 0 and $${c_2}$$ > 0 and real number $${n_0}$$, has $${c_1} \\cdot g(n) \\leqslant f(n)\t\\leqslant {c_2} \\cdot g(n)$$, for all  $$n \\geqslant {n_0}$$.\n\n![as](fn_gn.png)\n  \n### Theorems\n  - *G = (V, E), the following statements are equivalent:*<img src=\"lecture.png\" style=\"width:30px;display:inline;box-shadow: none !important;\">\n    > 1. G is a tree.\n    > 2. Every two vertices of G are connected by a unique path\n    > 3. G is connected and V = E + 1\n    > 4. G is acyclic and V = E + 1\n    > 5. G is acyclic and if any two non-adjacent vertices are joined by an edge, the resulting graph has exactly one cycle. \n  - *In an undirected simple graph G = (V, E), there are at most $$\\frac{V \\cdot (V - 1)}{2}$$ edges. In short, by using the asymptotic notation, $$E = O(V^2)$$.*\n  - *three way to traversal a graph:*\n    > 1. depth-first-search\n    > 2. breadth-first-search\n    > 3. topological sort\n      - the result of topological sort is not unique\n  -  *If G is a connected planar graph with V vertices, E edges, and F faces, then V - E + F = 2*\n    > faces represent disjoint area.\n    <img src=\"v_e_f_2.png\"  style=\"display:inline;box-shadow: none !important;\">\n  - *In any simple connected planar graph with at least 3 vertices, $$E < 3 \\cdot V - 6$$*\n  - *A simple connected planar graph with at least 3 vertices has a vertex of degree 5 or less.*\n  - *[Coloring Planar Graph] every planar graph can be colored with at most six colors.*\n  - *A graph is bipartite if and only if it dose not contain an odd length cycle.*\n  - *A connected graph G is a Eulerian graph if and only if all vertices of G are of even degree*\n\n### Review Q&A\n1. Mark the following assertions as TRUE or FALSE. No need to provide any justification.<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\">\n  - a. $$n = O(n^2)$$\n    > - **True**. since $$f(n) = n \\, and \\, g(n) = n^2 $$ and this is big O annotation, which requires $$f(n) \t\\leqslant c \\cdot g(n)$$ when  $$n \\geqslant {n_0}$$. <br>In the issue, $$n <= c \\cdot n^2$$, meets the requirements, so it is correct.\n  - b. $$n = O( \\sqrt[2]{n})$$\n    > - **False**. $$n >= c \\cdot \\sqrt[2]{n}$$ should use Ω\n  - c. $$log(n) = Ω(n)$$\n    > - **False**. $$log(n) <= c \\cdot n$$ should use O\n  - d. $$n^2 = \\Omega(n \\cdot log(n))$$\n    > - **True**. $$n^2 >= c \\cdot n \\cdot log(n)$$\n  - e. $$n^2 \\cdot log(n) = \\Theta(n^2)$$\n    > - **False**. $$n^2 \\cdot log(n) >= n^2 $$ should use $$\\Omega$$\n  - f. $$7 \\cdot (log(n))^2 + 2n \\cdot log(n) = Ω(log(n))$$\n    > - **True**. let $$A = log(n)$$, so we have $$7A^2 + 2 \\cdot n \\cdot A >= A$$\n  - g. $$5n \\cdot log(n) + 1024 n \\cdot log(log(n)) = Θ(n \\cdot log(n))$$\n    > - **True**. let $$A = log(n)$$,<br> so we have $$5 \\cdot n \\cdot A + 1024 \\cdot n \\cdot log(A) = \\Theta(n \\cdot A)$$. not easy to compare. but we already knew log(n) < n. <br> So $$5 \\cdot n \\cdot A + 1024 \\cdot n \\cdot log(A) < 5 \\cdot n \\cdot A + 1024 \\cdot n \\cdot A$$. <br> let $$B = n \\cdot log(n) $$, we will have $$5 \\cdot B + 1024 \\cdot B = 1029B \\, v.s. \\Theta(B)$$. <br>f(n) = 1029B, g(n) = B. There exist many $${c_1} \\, {c_2}$$ could meet $${c_1} \\cdot g(n) \\leqslant f(n)\t\\leqslant {c_2} \\cdot g(n)$$.\n  - h. $$2^n + 100 \\cdot n^2 + n^{100}= O(n^{101})$$\n    > - **False**. u can see the head img. $$2^n$$ grow faster than $$n^{100}$$. so left part bigger than right. <br>The statement is wrong, and should use $$\\Omega$$\n  - i. $$(1/3)^n + 100 = O(1)$$\n    > - **False**. $$(1/3)^n$$ will going to zero when n > 0. the left part will never beat the 101. so LHS is smaller or bigger than RHS when choose different *c*. Thus the statement is wrong.\n2. **(T/F)** Any function which is $$Ω(log(n))$$ is also $$Ω(log(log(n)))$$.<img src=\"lecture.png\" style=\"width:30px;display:inline;box-shadow: none !important;\">\n  > - **True**. Assume there is a f(n) >= c * log(n).<br>\n  and we also knew, log(n) > log(log(n)) in any suitation. so we have f(n) >= c * log(n) > c * log(log(n)). \n3. **(T/F)** If f(n) = Θ(g(n)) then g(n) = Θ(f(n))<img src=\"lecture.png\" style=\"width:30px;display:inline;box-shadow: none !important;\">\n  > - **True**. becasue f(n) = Θ(g(n)), we have $$c_1 \\cdot g(n) <= f(n) <= c_2 \\cdot g(n)$$. LHS multiplt $$1 / c_1$$ => $$g(n) <= \\frac{1}{c_1}f(n)$$. RHS multiplt $$1 / c_2$$ => $$\\frac{1}{c_2}f(n) <= g(n)$$. <br>In all, we have $$\\frac{1}{c_2}f(n) <= g(n) <= \\frac{1}{c_1}f(n) \\, $$ => $$\\, b_1f(n) <= g(n) <= b_2f(n)$$\n4. **(T/F)** If f(n) = Θ(g(n)) then f(n) = Ω(g(n)).\n  > - **True**. becasue f(n) = Θ(g(n)), we have $$c_1 \\cdot g(n) <= f(n) <= c_2 \\cdot g(n)$$. LHS is what you need. so this is true.\n5. **(T/F)** If f(n) = Ω(g(n)) then $$2^{f(n)} = Ω(2^{g(n)})$$.<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\">\n  > - **False** prove it by contradiction. <br>\n  e.g. f(n) = 2n, g(n) = 4n. when c = 0.25. f(n) >= c * g(n). <br>\n  but $$2^{f(n)} = 4^n, 2^{g(n)} = 16^n$$, $$2^{f(n)} <= 2^{g(n)}$$. so this statement is wrong.\n6. **(T/F)** BFS can be used to find the shortest path between any two nodes in a non-weighted graph.\n  > - **True**. as the professor said. BFS find node in level order.\n7. **(T/F)** A DFS tree is never the same as a BFS tree.\n  > - **False**. could be the same.\n8. **(T/F)** Algorithm A has a running time of $$O(n^2)$$ and algorithm B has a running time of $$O(n \\cdot log(n)).$$ From this we conclude that A can never run faster than B on the same input.\n  > - **False**. Big O annotation is just telling you the maximum time that your algorithm will cost. But when running in real life, the actual data could be easily handled. \n9. **(T/F)** Planar graph is a sparse graph.\n  > - **False**. could be a dense graph.\n10. **(T/F)** Every DAG contains a vertex with no incoming edges.\n  > - **True**. DAG (directed acyclic graph) cannot has a circle.\n\n### Exercise Q&A\n1. Prove g(n) = Ω(f(n)) if and only if f(n) = O(g(n)).\n  > - **Solution** To prove a theorem of the form *A IF AND ONLY IF B*, you first prove *IF A THEN B*, then you prove *IF B THEN A*, and that's enough to complete the proof. \n  >> **Proof**\n  >> - $A \\rightrightarrows B$\n  >>> g(n) = Ω(f(n)), means g(n) >=  c \\* f(n), c > 0 <br>\n    we multiply 1 / c on both side, and we have $$\\frac{1}{c} \\cdot g((n)$$ >= f(n) which equals to <br>  f(n) <= $${b} \\cdot g((n)$$, *b* > 0 , so we can say f(n) = O(g(n)).\n  >> - $B \\leftleftarrows A$\n  >>> f(n) = O(g(n)), means f(n) <= c \\* g(n), c > 0 <br>\n    we multiply 1 / c on both side, and we have $$\\frac{1}{c} \\cdot f((n)$$ <= g(n) which equals to <br>  g(n) >= $${b} \\cdot f((n)$$, *b* > 0 , so we can say g(n) = Ω(f(n)).\n\n2. Prove or disprove f(n) = O(g(n)) implies $$2^{f(n)} = O(2^{g(n)})$$.<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\">\n  > - **Solution** prove it by contradiction. <br>\n  e.g. f(n) = 2n, g(n) = n. when c = 4. f(n) <= c \\* g(n).<br> \n  but $$2^{f(n)} = 4^n, 2^{g(n)} = 2^n$$, $$2^{f(n)} >= 2^{g(n)}$$. so this statement is wrong.\n\n3. Arrange the following functions<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\">\n$$log(n^n),\\, n^2,\\, n^{log(n)},\\, nlog(log(n)),\\, 2^{log(n)},\\, (log(n))^2,\\, n^{\\sqrt{2}}$$\nin increasing order of growth rate, with g(n) following f(n) in your list if and only if f(n) = O(g(n)).\n  > - **Solution** we can follow this order\n  $O(1) <= O(log(n)) <= O((log(n))^C) <= O(C^{log(n)}) <= O(n) <= O(n \\cdot log(n)) <= O(n^C) <= O((log(n))!) <= O(n^{log(n)}) <= O(C^n)$\n  And we can simply some of them in first place.\n  $$① \\, log(n^n) = n \\cdot log(n) \\, ⑤ \\, 2^{log_2 n} = log_2 2^n = n \\cdot 1 = n$$,\n  So , finally, we have <br>\n  $nlog(n),\\, n^2,\\, n^{log(n)},\\, nlog(log(n)),\\, n,\\, (log(n))^2,\\, n^{\\sqrt{2}}$ <br>\n  $O(1) \\Rightarrow None$\n  $O(log(n)) \\Rightarrow None$\n  $O((log(n))^C) \\Rightarrow ⑥$\n  $O(C^{log(n)}) \\Rightarrow None$\n  $O(n) \\Rightarrow ⑤$\n  $O(n \\cdot log(n)) \\Rightarrow ①④ since \\, n > log(n) \\Rightarrow ④①$\n  $O(n^C) \\Rightarrow ②⑦ since \\, \\sqrt(2) < 2 \\, and \\, log(n)\\, grow \\,slower \\,than \\,exponential \\,func $\n  $\\quad especially \\,when \\,a > 1 \\, so, ⑦②$\n  $O((log(n))!) \\Rightarrow None$\n  $O(n^{log(n)}) \\Rightarrow ③$\n  $O(C^n) \\Rightarrow None$<br>\n  the answers is: ⑥<⑤<④<①<⑦<②<③\n  $(log(n))^2,\\, 2^{log(n)},\\, nlog(log(n)),\\, log(n^n),\\, n^{\\sqrt{2}}, \\, n^2,\\, n^{log(n)}$\n\n4. Arrange the following functions\n$$4^{log(n)},\\, \\sqrt{log(n)},\\, n^{log(log(n))},\\, (\\sqrt{2})^{log(n)},\\, 2^{\\sqrt{2log(n)}},\\, n^{1/log(n)},\\, (log(n))!$$\nin increasing order of growth rate with g(n) following f(n) in your list if and only if f(n) = O(g(n)).<img src=\"lecture.png\" style=\"width:30px;display:inline;box-shadow: none !important;\">\n  > - **Solution** we can follow this order\n  $O(1) <= O(log(n)) <= O((log(n))^C) <= O(C^{log(n)}) <= O(n) <= O(n \\cdot log(n)) <= O(n^C) <= O((log(n))!) <= O(n^{log(n)}) <= O(C^n)$\n  And we can simply some of them in first place.\n  $$① \\, 4^{log_2 n} = (2^2)^{log(n)} = 2^{2*log(n)} = 2^{log(n^2)} = log_2 2^{n^2} = n^2$$,<br>\n  $$⑥ \\, n^{1/log(n)} = n^{log_2 2/log_2 n} = n^{log_n 2} = 2$$,\n  So , finally, we have <br>\n  $n^2, \\, \\sqrt{log(n)},\\, n^{log(log(n))},\\, (\\sqrt{2})^{log(n)},\\, 2^{\\sqrt{2log(n)}},\\, 2, \\, (log(n))!$ <br>\n  $O(1) \\Rightarrow ⑥$\n  $O(log(n)) \\Rightarrow None$\n  $O((log(n))^C) \\Rightarrow ②$\n  $O(C^{log(n)}) \\Rightarrow ④⑤ \\quad (\\sqrt{2})^{log(n)} = 2^{log(n) / 2} $\n  $\\quad \\,we \\, can \\, just \\, compare \\, log(n) / 2 \\, v.s. \\sqrt{2 \\cdot log(n)} \\, so, ⑤④$\n  $O(n) \\Rightarrow None$\n  $O(n \\cdot log(n)) \\Rightarrow None$\n  $O(n^C) \\Rightarrow ①$\n  $O((log(n))!) \\Rightarrow ⑦$\n  $O(n^{log(n)}) \\Rightarrow ③$\n  $O(C^n) \\Rightarrow None$ <br>\n  the answers is: ⑥<②<⑤<④<①<⑦<③\n  $(log(n))^2,\\, 2^{log(n)},\\, nlog(log(n)),\\, log(n^n),\\, n^{\\sqrt{2}}, \\, n^2,\\, n^{log(n)}$\n\n5. What is the Big-O runtime complexity of the following function?<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\">\n  ```\n  void bigOh1 (int n):\n    for i=1 to n\n      j=1;\n      while j < n\n        j = j*2;\n  ```\n  > - **Solution** $$O(n \\cdot log(n))$$\n  > <img src=\"ans_5.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n6. What is the Big-O runtime complexity of the following function?<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\">\n  ```\n  string bigOh3 (int n):\n    if(n == 0) return \"a\";\n    string str = bigOh3(n-1);\n    return str + str;\n  ```\n  > - **Solution** $$O(n \\cdot 2^n)$$\n  > <img src=\"ans_6.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n7. What is the Big-Theta runtime complexity of the following function? Here *find_max* finds the maximum element in the array L[0], L[1], …, L[n - 1].<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\">\n  ```\n  void bigOh2 (int[] L, int n):\n    while (n > 0)\n      find_max(L, n);\n      n = n/4;\n  ```\n  > - **Solution**\n  > <img src=\"ans_7.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n8. The complete graph on n vertices, denoted $$K_n$$, is a simple graph in which there is an edge between every pair of distinct vertices. What is the height of the DFS tree for the complete graph $$K_n$$? What is the height of the BFS tree for the complete graph $$K_n$$?\n  > - **Solution**\n\n9. We are interested in finding a simple path in a directed acyclic graph that visits all vertices once and only once. Design a linear time algorithm to determine if there is such a path in a given DAG.\n  > - **Solution**\n\n10. Prove that a complete graph $$K_5$$ is not a planar graph.\n  > - **Solution**\n\n11. Prove that a complete bipartite graph $$K_{3,3}$$ is not a planar graph.\n  > - **Solution**\n\n12. In a connected bipartite graph, is the bipartition unique? Justify your answer.\n  > - **Solution**\n\n13. Given a directed graph G = (V, E) and a particular node v ∈ V, design a linear time algorithm to determine whether v is in a triangle of edges (a cycle of length 3).\n  > - **Solution**\n\n14. Design a linear time algorithm which, given an undirected graph G = (V, E) and a particular edge e ∈ E, determines whether G has a cycle containing e.\n  > - **Solution**\n\n15. Given an undirected graph G = (V, E), prove that S is an independent set if and only if V - S is a vertex cover\n  > - **Solution**\n\n","slug":"AIA-ch1-Q-A","published":1,"updated":"2021-02-02T19:13:45.287Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cklbvizok0001xctt3ijn03c1","content":"<p>For any monotonic functions, <em>f</em>, <em>g</em> from the positive integers to the positive integers, we say <strong>f(n) = O(g(n))</strong> or <strong>f(n) = Ω(g(n))</strong> or <strong>f(n) = Θ(g(n))</strong></p>\n<h3 id=\"Concepts\"><a href=\"#Concepts\" class=\"headerlink\" title=\"Concepts\"></a>Concepts</h3><ul>\n<li><strong>T(n)</strong> counts the # of steps, where <em>n</em> is the input size.</li>\n<li><strong>O</strong> big O, <script type=\"math/tex\">\\exists \\, c</script> which <em>c</em> &gt; 0 and real number <script type=\"math/tex\">{n_0}</script>, has <script type=\"math/tex\">f(n)     \\leqslant c \\cdot g(n)</script>, for all  <script type=\"math/tex\">n \\geqslant {n_0}</script>.</li>\n<li><strong>Ω</strong> big Omega, <script type=\"math/tex\">\\exists \\, c</script> which <em>c</em> &gt; 0 and real number <script type=\"math/tex\">{n_0}</script>, has <script type=\"math/tex\">f(n)     \\geqslant c \\cdot g(n)</script>, for all  <script type=\"math/tex\">n \\geqslant {n_0}</script>.</li>\n<li><strong>Θ</strong> big Theta, <script type=\"math/tex\">\\exists \\, {c_1} \\, and \\, {c_2}</script> which <script type=\"math/tex\">{c_1}</script> &gt; 0 and <script type=\"math/tex\">{c_2}</script> &gt; 0 and real number <script type=\"math/tex\">{n_0}</script>, has <script type=\"math/tex\">{c_1} \\cdot g(n) \\leqslant f(n)    \\leqslant {c_2} \\cdot g(n)</script>, for all  <script type=\"math/tex\">n \\geqslant {n_0}</script>.</li>\n</ul>\n<p><img src=\"fn_gn.png\" alt=\"as\"></p>\n<h3 id=\"Theorems\"><a href=\"#Theorems\" class=\"headerlink\" title=\"Theorems\"></a>Theorems</h3><ul>\n<li><em>G = (V, E), the following statements are equivalent:</em><img src=\"lecture.png\" style=\"width:30px;display:inline;box-shadow: none !important;\"><blockquote>\n<ol>\n<li>G is a tree.</li>\n<li>Every two vertices of G are connected by a unique path</li>\n<li>G is connected and V = E + 1</li>\n<li>G is acyclic and V = E + 1</li>\n<li>G is acyclic and if any two non-adjacent vertices are joined by an edge, the resulting graph has exactly one cycle. </li>\n</ol>\n</blockquote>\n</li>\n<li><em>In an undirected simple graph G = (V, E), there are at most <script type=\"math/tex\">\\frac{V \\cdot (V - 1)}{2}</script> edges. In short, by using the asymptotic notation, <script type=\"math/tex\">E = O(V^2)</script>.</em></li>\n<li><em>three way to traversal a graph:</em><blockquote>\n<ol>\n<li>depth-first-search</li>\n<li>breadth-first-search</li>\n<li>topological sort<ul>\n<li>the result of topological sort is not unique</li>\n</ul>\n</li>\n</ol>\n</blockquote>\n</li>\n<li><em>If G is a connected planar graph with V vertices, E edges, and F faces, then V - E + F = 2</em><blockquote>\n<p>faces represent disjoint area.<br><img src=\"v_e_f_2.png\"  style=\"display:inline;box-shadow: none !important;\"></p>\n</blockquote>\n</li>\n<li><em>In any simple connected planar graph with at least 3 vertices, <script type=\"math/tex\">E < 3 \\cdot V - 6</script></em></li>\n<li><em>A simple connected planar graph with at least 3 vertices has a vertex of degree 5 or less.</em></li>\n<li><em>[Coloring Planar Graph] every planar graph can be colored with at most six colors.</em></li>\n<li><em>A graph is bipartite if and only if it dose not contain an odd length cycle.</em></li>\n<li><em>A connected graph G is a Eulerian graph if and only if all vertices of G are of even degree</em></li>\n</ul>\n<h3 id=\"Review-Q-amp-A\"><a href=\"#Review-Q-amp-A\" class=\"headerlink\" title=\"Review Q&amp;A\"></a>Review Q&amp;A</h3><ol>\n<li>Mark the following assertions as TRUE or FALSE. No need to provide any justification.<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\"><ul>\n<li>a. <script type=\"math/tex\">n = O(n^2)</script><blockquote>\n<ul>\n<li><strong>True</strong>. since <script type=\"math/tex\">f(n) = n \\, and \\, g(n) = n^2</script> and this is big O annotation, which requires <script type=\"math/tex\">f(n)     \\leqslant c \\cdot g(n)</script> when  <script type=\"math/tex\">n \\geqslant {n_0}</script>. <br>In the issue, <script type=\"math/tex\">n <= c \\cdot n^2</script>, meets the requirements, so it is correct.</li>\n</ul>\n</blockquote>\n</li>\n<li>b. <script type=\"math/tex\">n = O( \\sqrt[2]{n})</script><blockquote>\n<ul>\n<li><strong>False</strong>. <script type=\"math/tex\">n >= c \\cdot \\sqrt[2]{n}</script> should use Ω</li>\n</ul>\n</blockquote>\n</li>\n<li>c. <script type=\"math/tex\">log(n) = Ω(n)</script><blockquote>\n<ul>\n<li><strong>False</strong>. <script type=\"math/tex\">log(n) <= c \\cdot n</script> should use O</li>\n</ul>\n</blockquote>\n</li>\n<li>d. <script type=\"math/tex\">n^2 = \\Omega(n \\cdot log(n))</script><blockquote>\n<ul>\n<li><strong>True</strong>. <script type=\"math/tex\">n^2 >= c \\cdot n \\cdot log(n)</script></li>\n</ul>\n</blockquote>\n</li>\n<li>e. <script type=\"math/tex\">n^2 \\cdot log(n) = \\Theta(n^2)</script><blockquote>\n<ul>\n<li><strong>False</strong>. <script type=\"math/tex\">n^2 \\cdot log(n) >= n^2</script> should use <script type=\"math/tex\">\\Omega</script></li>\n</ul>\n</blockquote>\n</li>\n<li>f. <script type=\"math/tex\">7 \\cdot (log(n))^2 + 2n \\cdot log(n) = Ω(log(n))</script><blockquote>\n<ul>\n<li><strong>True</strong>. let <script type=\"math/tex\">A = log(n)</script>, so we have <script type=\"math/tex\">7A^2 + 2 \\cdot n \\cdot A >= A</script></li>\n</ul>\n</blockquote>\n</li>\n<li>g. <script type=\"math/tex\">5n \\cdot log(n) + 1024 n \\cdot log(log(n)) = Θ(n \\cdot log(n))</script><blockquote>\n<ul>\n<li><strong>True</strong>. let <script type=\"math/tex\">A = log(n)</script>,<br> so we have <script type=\"math/tex\">5 \\cdot n \\cdot A + 1024 \\cdot n \\cdot log(A) = \\Theta(n \\cdot A)</script>. not easy to compare. but we already knew log(n) &lt; n. <br> So <script type=\"math/tex\">5 \\cdot n \\cdot A + 1024 \\cdot n \\cdot log(A) < 5 \\cdot n \\cdot A + 1024 \\cdot n \\cdot A</script>. <br> let <script type=\"math/tex\">B = n \\cdot log(n)</script>, we will have <script type=\"math/tex\">5 \\cdot B + 1024 \\cdot B = 1029B \\, v.s. \\Theta(B)</script>. <br>f(n) = 1029B, g(n) = B. There exist many <script type=\"math/tex\">{c_1} \\, {c_2}</script> could meet <script type=\"math/tex\">{c_1} \\cdot g(n) \\leqslant f(n)    \\leqslant {c_2} \\cdot g(n)</script>.</li>\n</ul>\n</blockquote>\n</li>\n<li>h. <script type=\"math/tex\">2^n + 100 \\cdot n^2 + n^{100}= O(n^{101})</script><blockquote>\n<ul>\n<li><strong>False</strong>. u can see the head img. <script type=\"math/tex\">2^n</script> grow faster than <script type=\"math/tex\">n^{100}</script>. so left part bigger than right. <br>The statement is wrong, and should use <script type=\"math/tex\">\\Omega</script></li>\n</ul>\n</blockquote>\n</li>\n<li>i. <script type=\"math/tex\">(1/3)^n + 100 = O(1)</script><blockquote>\n<ul>\n<li><strong>False</strong>. <script type=\"math/tex\">(1/3)^n</script> will going to zero when n &gt; 0. the left part will never beat the 101. so LHS is smaller or bigger than RHS when choose different <em>c</em>. Thus the statement is wrong.</li>\n</ul>\n</blockquote>\n</li>\n</ul>\n</li>\n<li><strong>(T/F)</strong> Any function which is <script type=\"math/tex\">Ω(log(n))</script> is also <script type=\"math/tex\">Ω(log(log(n)))</script>.<img src=\"lecture.png\" style=\"width:30px;display:inline;box-shadow: none !important;\"><blockquote>\n<ul>\n<li><strong>True</strong>. Assume there is a f(n) &gt;= c <em> log(n).<br><br>and we also knew, log(n) &gt; log(log(n)) in any suitation. so we have f(n) &gt;= c </em> log(n) &gt; c * log(log(n)). </li>\n</ul>\n</blockquote>\n</li>\n<li><strong>(T/F)</strong> If f(n) = Θ(g(n)) then g(n) = Θ(f(n))<img src=\"lecture.png\" style=\"width:30px;display:inline;box-shadow: none !important;\"><blockquote>\n<ul>\n<li><strong>True</strong>. becasue f(n) = Θ(g(n)), we have <script type=\"math/tex\">c_1 \\cdot g(n) <= f(n) <= c_2 \\cdot g(n)</script>. LHS multiplt <script type=\"math/tex\">1 / c_1</script> =&gt; <script type=\"math/tex\">g(n) <= \\frac{1}{c_1}f(n)</script>. RHS multiplt <script type=\"math/tex\">1 / c_2</script> =&gt; <script type=\"math/tex\">\\frac{1}{c_2}f(n) <= g(n)</script>. <br>In all, we have <script type=\"math/tex\">\\frac{1}{c_2}f(n) <= g(n) <= \\frac{1}{c_1}f(n) \\,</script> =&gt; <script type=\"math/tex\">\\, b_1f(n) <= g(n) <= b_2f(n)</script></li>\n</ul>\n</blockquote>\n</li>\n<li><strong>(T/F)</strong> If f(n) = Θ(g(n)) then f(n) = Ω(g(n)).<blockquote>\n<ul>\n<li><strong>True</strong>. becasue f(n) = Θ(g(n)), we have <script type=\"math/tex\">c_1 \\cdot g(n) <= f(n) <= c_2 \\cdot g(n)</script>. LHS is what you need. so this is true.</li>\n</ul>\n</blockquote>\n</li>\n<li><strong>(T/F)</strong> If f(n) = Ω(g(n)) then <script type=\"math/tex\">2^{f(n)} = Ω(2^{g(n)})</script>.<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\"><blockquote>\n<ul>\n<li><strong>False</strong> prove it by contradiction. <br><br>e.g. f(n) = 2n, g(n) = 4n. when c = 0.25. f(n) &gt;= c * g(n). <br><br>but <script type=\"math/tex\">2^{f(n)} = 4^n, 2^{g(n)} = 16^n</script>, <script type=\"math/tex\">2^{f(n)} <= 2^{g(n)}</script>. so this statement is wrong.</li>\n</ul>\n</blockquote>\n</li>\n<li><strong>(T/F)</strong> BFS can be used to find the shortest path between any two nodes in a non-weighted graph.<blockquote>\n<ul>\n<li><strong>True</strong>. as the professor said. BFS find node in level order.</li>\n</ul>\n</blockquote>\n</li>\n<li><strong>(T/F)</strong> A DFS tree is never the same as a BFS tree.<blockquote>\n<ul>\n<li><strong>False</strong>. could be the same.</li>\n</ul>\n</blockquote>\n</li>\n<li><strong>(T/F)</strong> Algorithm A has a running time of <script type=\"math/tex\">O(n^2)</script> and algorithm B has a running time of <script type=\"math/tex\">O(n \\cdot log(n)).</script> From this we conclude that A can never run faster than B on the same input.<blockquote>\n<ul>\n<li><strong>False</strong>. Big O annotation is just telling you the maximum time that your algorithm will cost. But when running in real life, the actual data could be easily handled. </li>\n</ul>\n</blockquote>\n</li>\n<li><strong>(T/F)</strong> Planar graph is a sparse graph.<blockquote>\n<ul>\n<li><strong>False</strong>. could be a dense graph.</li>\n</ul>\n</blockquote>\n</li>\n<li><strong>(T/F)</strong> Every DAG contains a vertex with no incoming edges.<blockquote>\n<ul>\n<li><strong>True</strong>. DAG (directed acyclic graph) cannot has a circle.</li>\n</ul>\n</blockquote>\n</li>\n</ol>\n<h3 id=\"Exercise-Q-amp-A\"><a href=\"#Exercise-Q-amp-A\" class=\"headerlink\" title=\"Exercise Q&amp;A\"></a>Exercise Q&amp;A</h3><ol>\n<li><p>Prove g(n) = Ω(f(n)) if and only if f(n) = O(g(n)).</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong> To prove a theorem of the form <em>A IF AND ONLY IF B</em>, you first prove <em>IF A THEN B</em>, then you prove <em>IF B THEN A</em>, and that’s enough to complete the proof. <blockquote>\n<p><strong>Proof</strong></p>\n<ul>\n<li>$A \\rightrightarrows B$<blockquote>\n<p>g(n) = Ω(f(n)), means g(n) &gt;=  c * f(n), c &gt; 0 <br><br>we multiply 1 / c on both side, and we have <script type=\"math/tex\">\\frac{1}{c} \\cdot g((n)</script> &gt;= f(n) which equals to <br>  f(n) &lt;= <script type=\"math/tex\">{b} \\cdot g((n)</script>, <em>b</em> &gt; 0 , so we can say f(n) = O(g(n)).</p>\n</blockquote>\n</li>\n<li>$B \\leftleftarrows A$<blockquote>\n<p>f(n) = O(g(n)), means f(n) &lt;= c * g(n), c &gt; 0 <br><br>we multiply 1 / c on both side, and we have <script type=\"math/tex\">\\frac{1}{c} \\cdot f((n)</script> &lt;= g(n) which equals to <br>  g(n) &gt;= <script type=\"math/tex\">{b} \\cdot f((n)</script>, <em>b</em> &gt; 0 , so we can say g(n) = Ω(f(n)).</p>\n</blockquote>\n</li>\n</ul>\n</blockquote>\n</li>\n</ul>\n</blockquote>\n</li>\n<li><p>Prove or disprove f(n) = O(g(n)) implies <script type=\"math/tex\">2^{f(n)} = O(2^{g(n)})</script>.<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\"></p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong> prove it by contradiction. <br><br>e.g. f(n) = 2n, g(n) = n. when c = 4. f(n) &lt;= c * g(n).<br><br>but <script type=\"math/tex\">2^{f(n)} = 4^n, 2^{g(n)} = 2^n</script>, <script type=\"math/tex\">2^{f(n)} >= 2^{g(n)}</script>. so this statement is wrong.</li>\n</ul>\n</blockquote>\n</li>\n<li><p>Arrange the following functions<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\"></p>\n<script type=\"math/tex; mode=display\">log(n^n),\\, n^2,\\, n^{log(n)},\\, nlog(log(n)),\\, 2^{log(n)},\\, (log(n))^2,\\, n^{\\sqrt{2}}</script><p>in increasing order of growth rate, with g(n) following f(n) in your list if and only if f(n) = O(g(n)).</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong> we can follow this order<br>$O(1) &lt;= O(log(n)) &lt;= O((log(n))^C) &lt;= O(C^{log(n)}) &lt;= O(n) &lt;= O(n \\cdot log(n)) &lt;= O(n^C) &lt;= O((log(n))!) &lt;= O(n^{log(n)}) &lt;= O(C^n)$<br>And we can simply some of them in first place.<br><script type=\"math/tex\">① \\, log(n^n) = n \\cdot log(n) \\, ⑤ \\, 2^{log_2 n} = log_2 2^n = n \\cdot 1 = n</script>,<br>So , finally, we have <br><br>$nlog(n),\\, n^2,\\, n^{log(n)},\\, nlog(log(n)),\\, n,\\, (log(n))^2,\\, n^{\\sqrt{2}}$ <br><br>$O(1) \\Rightarrow None$<br>$O(log(n)) \\Rightarrow None$<br>$O((log(n))^C) \\Rightarrow ⑥$<br>$O(C^{log(n)}) \\Rightarrow None$<br>$O(n) \\Rightarrow ⑤$<br>$O(n \\cdot log(n)) \\Rightarrow ①④ since \\, n &gt; log(n) \\Rightarrow ④①$<br>$O(n^C) \\Rightarrow ②⑦ since \\, \\sqrt(2) &lt; 2 \\, and \\, log(n)\\, grow \\,slower \\,than \\,exponential \\,func $<br>$\\quad especially \\,when \\,a &gt; 1 \\, so, ⑦②$<br>$O((log(n))!) \\Rightarrow None$<br>$O(n^{log(n)}) \\Rightarrow ③$<br>$O(C^n) \\Rightarrow None$<br><br>the answers is: ⑥&lt;⑤&lt;④&lt;①&lt;⑦&lt;②&lt;③<br>$(log(n))^2,\\, 2^{log(n)},\\, nlog(log(n)),\\, log(n^n),\\, n^{\\sqrt{2}}, \\, n^2,\\, n^{log(n)}$</li>\n</ul>\n</blockquote>\n</li>\n<li><p>Arrange the following functions</p>\n<script type=\"math/tex; mode=display\">4^{log(n)},\\, \\sqrt{log(n)},\\, n^{log(log(n))},\\, (\\sqrt{2})^{log(n)},\\, 2^{\\sqrt{2log(n)}},\\, n^{1/log(n)},\\, (log(n))!</script><p>in increasing order of growth rate with g(n) following f(n) in your list if and only if f(n) = O(g(n)).<img src=\"lecture.png\" style=\"width:30px;display:inline;box-shadow: none !important;\"></p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong> we can follow this order<br>$O(1) &lt;= O(log(n)) &lt;= O((log(n))^C) &lt;= O(C^{log(n)}) &lt;= O(n) &lt;= O(n \\cdot log(n)) &lt;= O(n^C) &lt;= O((log(n))!) &lt;= O(n^{log(n)}) &lt;= O(C^n)$<br>And we can simply some of them in first place.<br><script type=\"math/tex\">① \\, 4^{log_2 n} = (2^2)^{log(n)} = 2^{2*log(n)} = 2^{log(n^2)} = log_2 2^{n^2} = n^2</script>,<br><br><script type=\"math/tex\">⑥ \\, n^{1/log(n)} = n^{log_2 2/log_2 n} = n^{log_n 2} = 2</script>,<br>So , finally, we have <br><br>$n^2, \\, \\sqrt{log(n)},\\, n^{log(log(n))},\\, (\\sqrt{2})^{log(n)},\\, 2^{\\sqrt{2log(n)}},\\, 2, \\, (log(n))!$ <br><br>$O(1) \\Rightarrow ⑥$<br>$O(log(n)) \\Rightarrow None$<br>$O((log(n))^C) \\Rightarrow ②$<br>$O(C^{log(n)}) \\Rightarrow ④⑤ \\quad (\\sqrt{2})^{log(n)} = 2^{log(n) / 2} $<br>$\\quad \\,we \\, can \\, just \\, compare \\, log(n) / 2 \\, v.s. \\sqrt{2 \\cdot log(n)} \\, so, ⑤④$<br>$O(n) \\Rightarrow None$<br>$O(n \\cdot log(n)) \\Rightarrow None$<br>$O(n^C) \\Rightarrow ①$<br>$O((log(n))!) \\Rightarrow ⑦$<br>$O(n^{log(n)}) \\Rightarrow ③$<br>$O(C^n) \\Rightarrow None$ <br><br>the answers is: ⑥&lt;②&lt;⑤&lt;④&lt;①&lt;⑦&lt;③<br>$(log(n))^2,\\, 2^{log(n)},\\, nlog(log(n)),\\, log(n^n),\\, n^{\\sqrt{2}}, \\, n^2,\\, n^{log(n)}$</li>\n</ul>\n</blockquote>\n</li>\n<li><p>What is the Big-O runtime complexity of the following function?<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\"></p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void bigOh1 (int n):</span><br><span class=\"line\">  <span class=\"keyword\">for</span> <span class=\"attribute\">i</span>=1 <span class=\"keyword\">to</span> n</span><br><span class=\"line\">    <span class=\"attribute\">j</span>=1;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> j &lt; n</span><br><span class=\"line\">      j = j<span class=\"number\">*2</span>;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<ul>\n<li><strong>Solution</strong> <script type=\"math/tex\">O(n \\cdot log(n))</script><br><img src=\"ans_5.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p>What is the Big-O runtime complexity of the following function?<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\"></p>\n<figure class=\"highlight angelscript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">string</span> bigOh3 (<span class=\"built_in\">int</span> n):</span><br><span class=\"line\">  <span class=\"keyword\">if</span>(n == <span class=\"number\">0</span>) <span class=\"keyword\">return</span> <span class=\"string\">\"a\"</span>;</span><br><span class=\"line\">  <span class=\"built_in\">string</span> str = bigOh3(n<span class=\"number\">-1</span>);</span><br><span class=\"line\">  <span class=\"keyword\">return</span> str + str;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<ul>\n<li><strong>Solution</strong> <script type=\"math/tex\">O(n \\cdot 2^n)</script><br><img src=\"ans_6.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p>What is the Big-Theta runtime complexity of the following function? Here <em>find_max</em> finds the maximum element in the array L[0], L[1], …, L[n - 1].<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\"></p>\n<figure class=\"highlight excel\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void bigOh2 (<span class=\"built_in\">int</span>[] L, <span class=\"built_in\">int</span> <span class=\"built_in\">n</span>)<span class=\"symbol\">:</span></span><br><span class=\"line\">  while (<span class=\"built_in\">n</span> &gt; <span class=\"number\">0</span>)</span><br><span class=\"line\">    find_max(L, <span class=\"built_in\">n</span>);</span><br><span class=\"line\">    <span class=\"built_in\">n</span> = <span class=\"built_in\">n</span>/<span class=\"number\">4</span>;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><br><img src=\"ans_7.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p>The complete graph on n vertices, denoted <script type=\"math/tex\">K_n</script>, is a simple graph in which there is an edge between every pair of distinct vertices. What is the height of the DFS tree for the complete graph <script type=\"math/tex\">K_n</script>? What is the height of the BFS tree for the complete graph <script type=\"math/tex\">K_n</script>?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>We are interested in finding a simple path in a directed acyclic graph that visits all vertices once and only once. Design a linear time algorithm to determine if there is such a path in a given DAG.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Prove that a complete graph <script type=\"math/tex\">K_5</script> is not a planar graph.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Prove that a complete bipartite graph <script type=\"math/tex\">K_{3,3}</script> is not a planar graph.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>In a connected bipartite graph, is the bipartition unique? Justify your answer.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Given a directed graph G = (V, E) and a particular node v ∈ V, design a linear time algorithm to determine whether v is in a triangle of edges (a cycle of length 3).</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Design a linear time algorithm which, given an undirected graph G = (V, E) and a particular edge e ∈ E, determines whether G has a cycle containing e.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Given an undirected graph G = (V, E), prove that S is an independent set if and only if V - S is a vertex cover</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<p>For any monotonic functions, <em>f</em>, <em>g</em> from the positive integers to the positive integers, we say <strong>f(n) = O(g(n))</strong> or <strong>f(n) = Ω(g(n))</strong> or <strong>f(n) = Θ(g(n))</strong></p>\n<h3 id=\"Concepts\"><a href=\"#Concepts\" class=\"headerlink\" title=\"Concepts\"></a>Concepts</h3><ul>\n<li><strong>T(n)</strong> counts the # of steps, where <em>n</em> is the input size.</li>\n<li><strong>O</strong> big O, <script type=\"math/tex\">\\exists \\, c</script> which <em>c</em> &gt; 0 and real number <script type=\"math/tex\">{n_0}</script>, has <script type=\"math/tex\">f(n)     \\leqslant c \\cdot g(n)</script>, for all  <script type=\"math/tex\">n \\geqslant {n_0}</script>.</li>\n<li><strong>Ω</strong> big Omega, <script type=\"math/tex\">\\exists \\, c</script> which <em>c</em> &gt; 0 and real number <script type=\"math/tex\">{n_0}</script>, has <script type=\"math/tex\">f(n)     \\geqslant c \\cdot g(n)</script>, for all  <script type=\"math/tex\">n \\geqslant {n_0}</script>.</li>\n<li><strong>Θ</strong> big Theta, <script type=\"math/tex\">\\exists \\, {c_1} \\, and \\, {c_2}</script> which <script type=\"math/tex\">{c_1}</script> &gt; 0 and <script type=\"math/tex\">{c_2}</script> &gt; 0 and real number <script type=\"math/tex\">{n_0}</script>, has <script type=\"math/tex\">{c_1} \\cdot g(n) \\leqslant f(n)    \\leqslant {c_2} \\cdot g(n)</script>, for all  <script type=\"math/tex\">n \\geqslant {n_0}</script>.</li>\n</ul>\n<p><img src=\"fn_gn.png\" alt=\"as\"></p>\n<h3 id=\"Theorems\"><a href=\"#Theorems\" class=\"headerlink\" title=\"Theorems\"></a>Theorems</h3><ul>\n<li><em>G = (V, E), the following statements are equivalent:</em><img src=\"lecture.png\" style=\"width:30px;display:inline;box-shadow: none !important;\"><blockquote>\n<ol>\n<li>G is a tree.</li>\n<li>Every two vertices of G are connected by a unique path</li>\n<li>G is connected and V = E + 1</li>\n<li>G is acyclic and V = E + 1</li>\n<li>G is acyclic and if any two non-adjacent vertices are joined by an edge, the resulting graph has exactly one cycle. </li>\n</ol>\n</blockquote>\n</li>\n<li><em>In an undirected simple graph G = (V, E), there are at most <script type=\"math/tex\">\\frac{V \\cdot (V - 1)}{2}</script> edges. In short, by using the asymptotic notation, <script type=\"math/tex\">E = O(V^2)</script>.</em></li>\n<li><em>three way to traversal a graph:</em><blockquote>\n<ol>\n<li>depth-first-search</li>\n<li>breadth-first-search</li>\n<li>topological sort<ul>\n<li>the result of topological sort is not unique</li>\n</ul>\n</li>\n</ol>\n</blockquote>\n</li>\n<li><em>If G is a connected planar graph with V vertices, E edges, and F faces, then V - E + F = 2</em><blockquote>\n<p>faces represent disjoint area.<br><img src=\"v_e_f_2.png\"  style=\"display:inline;box-shadow: none !important;\"></p>\n</blockquote>\n</li>\n<li><em>In any simple connected planar graph with at least 3 vertices, <script type=\"math/tex\">E < 3 \\cdot V - 6</script></em></li>\n<li><em>A simple connected planar graph with at least 3 vertices has a vertex of degree 5 or less.</em></li>\n<li><em>[Coloring Planar Graph] every planar graph can be colored with at most six colors.</em></li>\n<li><em>A graph is bipartite if and only if it dose not contain an odd length cycle.</em></li>\n<li><em>A connected graph G is a Eulerian graph if and only if all vertices of G are of even degree</em></li>\n</ul>\n<h3 id=\"Review-Q-amp-A\"><a href=\"#Review-Q-amp-A\" class=\"headerlink\" title=\"Review Q&amp;A\"></a>Review Q&amp;A</h3><ol>\n<li>Mark the following assertions as TRUE or FALSE. No need to provide any justification.<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\"><ul>\n<li>a. <script type=\"math/tex\">n = O(n^2)</script><blockquote>\n<ul>\n<li><strong>True</strong>. since <script type=\"math/tex\">f(n) = n \\, and \\, g(n) = n^2</script> and this is big O annotation, which requires <script type=\"math/tex\">f(n)     \\leqslant c \\cdot g(n)</script> when  <script type=\"math/tex\">n \\geqslant {n_0}</script>. <br>In the issue, <script type=\"math/tex\">n <= c \\cdot n^2</script>, meets the requirements, so it is correct.</li>\n</ul>\n</blockquote>\n</li>\n<li>b. <script type=\"math/tex\">n = O( \\sqrt[2]{n})</script><blockquote>\n<ul>\n<li><strong>False</strong>. <script type=\"math/tex\">n >= c \\cdot \\sqrt[2]{n}</script> should use Ω</li>\n</ul>\n</blockquote>\n</li>\n<li>c. <script type=\"math/tex\">log(n) = Ω(n)</script><blockquote>\n<ul>\n<li><strong>False</strong>. <script type=\"math/tex\">log(n) <= c \\cdot n</script> should use O</li>\n</ul>\n</blockquote>\n</li>\n<li>d. <script type=\"math/tex\">n^2 = \\Omega(n \\cdot log(n))</script><blockquote>\n<ul>\n<li><strong>True</strong>. <script type=\"math/tex\">n^2 >= c \\cdot n \\cdot log(n)</script></li>\n</ul>\n</blockquote>\n</li>\n<li>e. <script type=\"math/tex\">n^2 \\cdot log(n) = \\Theta(n^2)</script><blockquote>\n<ul>\n<li><strong>False</strong>. <script type=\"math/tex\">n^2 \\cdot log(n) >= n^2</script> should use <script type=\"math/tex\">\\Omega</script></li>\n</ul>\n</blockquote>\n</li>\n<li>f. <script type=\"math/tex\">7 \\cdot (log(n))^2 + 2n \\cdot log(n) = Ω(log(n))</script><blockquote>\n<ul>\n<li><strong>True</strong>. let <script type=\"math/tex\">A = log(n)</script>, so we have <script type=\"math/tex\">7A^2 + 2 \\cdot n \\cdot A >= A</script></li>\n</ul>\n</blockquote>\n</li>\n<li>g. <script type=\"math/tex\">5n \\cdot log(n) + 1024 n \\cdot log(log(n)) = Θ(n \\cdot log(n))</script><blockquote>\n<ul>\n<li><strong>True</strong>. let <script type=\"math/tex\">A = log(n)</script>,<br> so we have <script type=\"math/tex\">5 \\cdot n \\cdot A + 1024 \\cdot n \\cdot log(A) = \\Theta(n \\cdot A)</script>. not easy to compare. but we already knew log(n) &lt; n. <br> So <script type=\"math/tex\">5 \\cdot n \\cdot A + 1024 \\cdot n \\cdot log(A) < 5 \\cdot n \\cdot A + 1024 \\cdot n \\cdot A</script>. <br> let <script type=\"math/tex\">B = n \\cdot log(n)</script>, we will have <script type=\"math/tex\">5 \\cdot B + 1024 \\cdot B = 1029B \\, v.s. \\Theta(B)</script>. <br>f(n) = 1029B, g(n) = B. There exist many <script type=\"math/tex\">{c_1} \\, {c_2}</script> could meet <script type=\"math/tex\">{c_1} \\cdot g(n) \\leqslant f(n)    \\leqslant {c_2} \\cdot g(n)</script>.</li>\n</ul>\n</blockquote>\n</li>\n<li>h. <script type=\"math/tex\">2^n + 100 \\cdot n^2 + n^{100}= O(n^{101})</script><blockquote>\n<ul>\n<li><strong>False</strong>. u can see the head img. <script type=\"math/tex\">2^n</script> grow faster than <script type=\"math/tex\">n^{100}</script>. so left part bigger than right. <br>The statement is wrong, and should use <script type=\"math/tex\">\\Omega</script></li>\n</ul>\n</blockquote>\n</li>\n<li>i. <script type=\"math/tex\">(1/3)^n + 100 = O(1)</script><blockquote>\n<ul>\n<li><strong>False</strong>. <script type=\"math/tex\">(1/3)^n</script> will going to zero when n &gt; 0. the left part will never beat the 101. so LHS is smaller or bigger than RHS when choose different <em>c</em>. Thus the statement is wrong.</li>\n</ul>\n</blockquote>\n</li>\n</ul>\n</li>\n<li><strong>(T/F)</strong> Any function which is <script type=\"math/tex\">Ω(log(n))</script> is also <script type=\"math/tex\">Ω(log(log(n)))</script>.<img src=\"lecture.png\" style=\"width:30px;display:inline;box-shadow: none !important;\"><blockquote>\n<ul>\n<li><strong>True</strong>. Assume there is a f(n) &gt;= c <em> log(n).<br><br>and we also knew, log(n) &gt; log(log(n)) in any suitation. so we have f(n) &gt;= c </em> log(n) &gt; c * log(log(n)). </li>\n</ul>\n</blockquote>\n</li>\n<li><strong>(T/F)</strong> If f(n) = Θ(g(n)) then g(n) = Θ(f(n))<img src=\"lecture.png\" style=\"width:30px;display:inline;box-shadow: none !important;\"><blockquote>\n<ul>\n<li><strong>True</strong>. becasue f(n) = Θ(g(n)), we have <script type=\"math/tex\">c_1 \\cdot g(n) <= f(n) <= c_2 \\cdot g(n)</script>. LHS multiplt <script type=\"math/tex\">1 / c_1</script> =&gt; <script type=\"math/tex\">g(n) <= \\frac{1}{c_1}f(n)</script>. RHS multiplt <script type=\"math/tex\">1 / c_2</script> =&gt; <script type=\"math/tex\">\\frac{1}{c_2}f(n) <= g(n)</script>. <br>In all, we have <script type=\"math/tex\">\\frac{1}{c_2}f(n) <= g(n) <= \\frac{1}{c_1}f(n) \\,</script> =&gt; <script type=\"math/tex\">\\, b_1f(n) <= g(n) <= b_2f(n)</script></li>\n</ul>\n</blockquote>\n</li>\n<li><strong>(T/F)</strong> If f(n) = Θ(g(n)) then f(n) = Ω(g(n)).<blockquote>\n<ul>\n<li><strong>True</strong>. becasue f(n) = Θ(g(n)), we have <script type=\"math/tex\">c_1 \\cdot g(n) <= f(n) <= c_2 \\cdot g(n)</script>. LHS is what you need. so this is true.</li>\n</ul>\n</blockquote>\n</li>\n<li><strong>(T/F)</strong> If f(n) = Ω(g(n)) then <script type=\"math/tex\">2^{f(n)} = Ω(2^{g(n)})</script>.<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\"><blockquote>\n<ul>\n<li><strong>False</strong> prove it by contradiction. <br><br>e.g. f(n) = 2n, g(n) = 4n. when c = 0.25. f(n) &gt;= c * g(n). <br><br>but <script type=\"math/tex\">2^{f(n)} = 4^n, 2^{g(n)} = 16^n</script>, <script type=\"math/tex\">2^{f(n)} <= 2^{g(n)}</script>. so this statement is wrong.</li>\n</ul>\n</blockquote>\n</li>\n<li><strong>(T/F)</strong> BFS can be used to find the shortest path between any two nodes in a non-weighted graph.<blockquote>\n<ul>\n<li><strong>True</strong>. as the professor said. BFS find node in level order.</li>\n</ul>\n</blockquote>\n</li>\n<li><strong>(T/F)</strong> A DFS tree is never the same as a BFS tree.<blockquote>\n<ul>\n<li><strong>False</strong>. could be the same.</li>\n</ul>\n</blockquote>\n</li>\n<li><strong>(T/F)</strong> Algorithm A has a running time of <script type=\"math/tex\">O(n^2)</script> and algorithm B has a running time of <script type=\"math/tex\">O(n \\cdot log(n)).</script> From this we conclude that A can never run faster than B on the same input.<blockquote>\n<ul>\n<li><strong>False</strong>. Big O annotation is just telling you the maximum time that your algorithm will cost. But when running in real life, the actual data could be easily handled. </li>\n</ul>\n</blockquote>\n</li>\n<li><strong>(T/F)</strong> Planar graph is a sparse graph.<blockquote>\n<ul>\n<li><strong>False</strong>. could be a dense graph.</li>\n</ul>\n</blockquote>\n</li>\n<li><strong>(T/F)</strong> Every DAG contains a vertex with no incoming edges.<blockquote>\n<ul>\n<li><strong>True</strong>. DAG (directed acyclic graph) cannot has a circle.</li>\n</ul>\n</blockquote>\n</li>\n</ol>\n<h3 id=\"Exercise-Q-amp-A\"><a href=\"#Exercise-Q-amp-A\" class=\"headerlink\" title=\"Exercise Q&amp;A\"></a>Exercise Q&amp;A</h3><ol>\n<li><p>Prove g(n) = Ω(f(n)) if and only if f(n) = O(g(n)).</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong> To prove a theorem of the form <em>A IF AND ONLY IF B</em>, you first prove <em>IF A THEN B</em>, then you prove <em>IF B THEN A</em>, and that’s enough to complete the proof. <blockquote>\n<p><strong>Proof</strong></p>\n<ul>\n<li>$A \\rightrightarrows B$<blockquote>\n<p>g(n) = Ω(f(n)), means g(n) &gt;=  c * f(n), c &gt; 0 <br><br>we multiply 1 / c on both side, and we have <script type=\"math/tex\">\\frac{1}{c} \\cdot g((n)</script> &gt;= f(n) which equals to <br>  f(n) &lt;= <script type=\"math/tex\">{b} \\cdot g((n)</script>, <em>b</em> &gt; 0 , so we can say f(n) = O(g(n)).</p>\n</blockquote>\n</li>\n<li>$B \\leftleftarrows A$<blockquote>\n<p>f(n) = O(g(n)), means f(n) &lt;= c * g(n), c &gt; 0 <br><br>we multiply 1 / c on both side, and we have <script type=\"math/tex\">\\frac{1}{c} \\cdot f((n)</script> &lt;= g(n) which equals to <br>  g(n) &gt;= <script type=\"math/tex\">{b} \\cdot f((n)</script>, <em>b</em> &gt; 0 , so we can say g(n) = Ω(f(n)).</p>\n</blockquote>\n</li>\n</ul>\n</blockquote>\n</li>\n</ul>\n</blockquote>\n</li>\n<li><p>Prove or disprove f(n) = O(g(n)) implies <script type=\"math/tex\">2^{f(n)} = O(2^{g(n)})</script>.<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\"></p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong> prove it by contradiction. <br><br>e.g. f(n) = 2n, g(n) = n. when c = 4. f(n) &lt;= c * g(n).<br><br>but <script type=\"math/tex\">2^{f(n)} = 4^n, 2^{g(n)} = 2^n</script>, <script type=\"math/tex\">2^{f(n)} >= 2^{g(n)}</script>. so this statement is wrong.</li>\n</ul>\n</blockquote>\n</li>\n<li><p>Arrange the following functions<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\"></p>\n<script type=\"math/tex; mode=display\">log(n^n),\\, n^2,\\, n^{log(n)},\\, nlog(log(n)),\\, 2^{log(n)},\\, (log(n))^2,\\, n^{\\sqrt{2}}</script><p>in increasing order of growth rate, with g(n) following f(n) in your list if and only if f(n) = O(g(n)).</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong> we can follow this order<br>$O(1) &lt;= O(log(n)) &lt;= O((log(n))^C) &lt;= O(C^{log(n)}) &lt;= O(n) &lt;= O(n \\cdot log(n)) &lt;= O(n^C) &lt;= O((log(n))!) &lt;= O(n^{log(n)}) &lt;= O(C^n)$<br>And we can simply some of them in first place.<br><script type=\"math/tex\">① \\, log(n^n) = n \\cdot log(n) \\, ⑤ \\, 2^{log_2 n} = log_2 2^n = n \\cdot 1 = n</script>,<br>So , finally, we have <br><br>$nlog(n),\\, n^2,\\, n^{log(n)},\\, nlog(log(n)),\\, n,\\, (log(n))^2,\\, n^{\\sqrt{2}}$ <br><br>$O(1) \\Rightarrow None$<br>$O(log(n)) \\Rightarrow None$<br>$O((log(n))^C) \\Rightarrow ⑥$<br>$O(C^{log(n)}) \\Rightarrow None$<br>$O(n) \\Rightarrow ⑤$<br>$O(n \\cdot log(n)) \\Rightarrow ①④ since \\, n &gt; log(n) \\Rightarrow ④①$<br>$O(n^C) \\Rightarrow ②⑦ since \\, \\sqrt(2) &lt; 2 \\, and \\, log(n)\\, grow \\,slower \\,than \\,exponential \\,func $<br>$\\quad especially \\,when \\,a &gt; 1 \\, so, ⑦②$<br>$O((log(n))!) \\Rightarrow None$<br>$O(n^{log(n)}) \\Rightarrow ③$<br>$O(C^n) \\Rightarrow None$<br><br>the answers is: ⑥&lt;⑤&lt;④&lt;①&lt;⑦&lt;②&lt;③<br>$(log(n))^2,\\, 2^{log(n)},\\, nlog(log(n)),\\, log(n^n),\\, n^{\\sqrt{2}}, \\, n^2,\\, n^{log(n)}$</li>\n</ul>\n</blockquote>\n</li>\n<li><p>Arrange the following functions</p>\n<script type=\"math/tex; mode=display\">4^{log(n)},\\, \\sqrt{log(n)},\\, n^{log(log(n))},\\, (\\sqrt{2})^{log(n)},\\, 2^{\\sqrt{2log(n)}},\\, n^{1/log(n)},\\, (log(n))!</script><p>in increasing order of growth rate with g(n) following f(n) in your list if and only if f(n) = O(g(n)).<img src=\"lecture.png\" style=\"width:30px;display:inline;box-shadow: none !important;\"></p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong> we can follow this order<br>$O(1) &lt;= O(log(n)) &lt;= O((log(n))^C) &lt;= O(C^{log(n)}) &lt;= O(n) &lt;= O(n \\cdot log(n)) &lt;= O(n^C) &lt;= O((log(n))!) &lt;= O(n^{log(n)}) &lt;= O(C^n)$<br>And we can simply some of them in first place.<br><script type=\"math/tex\">① \\, 4^{log_2 n} = (2^2)^{log(n)} = 2^{2*log(n)} = 2^{log(n^2)} = log_2 2^{n^2} = n^2</script>,<br><br><script type=\"math/tex\">⑥ \\, n^{1/log(n)} = n^{log_2 2/log_2 n} = n^{log_n 2} = 2</script>,<br>So , finally, we have <br><br>$n^2, \\, \\sqrt{log(n)},\\, n^{log(log(n))},\\, (\\sqrt{2})^{log(n)},\\, 2^{\\sqrt{2log(n)}},\\, 2, \\, (log(n))!$ <br><br>$O(1) \\Rightarrow ⑥$<br>$O(log(n)) \\Rightarrow None$<br>$O((log(n))^C) \\Rightarrow ②$<br>$O(C^{log(n)}) \\Rightarrow ④⑤ \\quad (\\sqrt{2})^{log(n)} = 2^{log(n) / 2} $<br>$\\quad \\,we \\, can \\, just \\, compare \\, log(n) / 2 \\, v.s. \\sqrt{2 \\cdot log(n)} \\, so, ⑤④$<br>$O(n) \\Rightarrow None$<br>$O(n \\cdot log(n)) \\Rightarrow None$<br>$O(n^C) \\Rightarrow ①$<br>$O((log(n))!) \\Rightarrow ⑦$<br>$O(n^{log(n)}) \\Rightarrow ③$<br>$O(C^n) \\Rightarrow None$ <br><br>the answers is: ⑥&lt;②&lt;⑤&lt;④&lt;①&lt;⑦&lt;③<br>$(log(n))^2,\\, 2^{log(n)},\\, nlog(log(n)),\\, log(n^n),\\, n^{\\sqrt{2}}, \\, n^2,\\, n^{log(n)}$</li>\n</ul>\n</blockquote>\n</li>\n<li><p>What is the Big-O runtime complexity of the following function?<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\"></p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void bigOh1 (int n):</span><br><span class=\"line\">  <span class=\"keyword\">for</span> <span class=\"attribute\">i</span>=1 <span class=\"keyword\">to</span> n</span><br><span class=\"line\">    <span class=\"attribute\">j</span>=1;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> j &lt; n</span><br><span class=\"line\">      j = j<span class=\"number\">*2</span>;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<ul>\n<li><strong>Solution</strong> <script type=\"math/tex\">O(n \\cdot log(n))</script><br><img src=\"ans_5.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p>What is the Big-O runtime complexity of the following function?<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\"></p>\n<figure class=\"highlight angelscript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">string</span> bigOh3 (<span class=\"built_in\">int</span> n):</span><br><span class=\"line\">  <span class=\"keyword\">if</span>(n == <span class=\"number\">0</span>) <span class=\"keyword\">return</span> <span class=\"string\">\"a\"</span>;</span><br><span class=\"line\">  <span class=\"built_in\">string</span> str = bigOh3(n<span class=\"number\">-1</span>);</span><br><span class=\"line\">  <span class=\"keyword\">return</span> str + str;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<ul>\n<li><strong>Solution</strong> <script type=\"math/tex\">O(n \\cdot 2^n)</script><br><img src=\"ans_6.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p>What is the Big-Theta runtime complexity of the following function? Here <em>find_max</em> finds the maximum element in the array L[0], L[1], …, L[n - 1].<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\"></p>\n<figure class=\"highlight excel\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void bigOh2 (<span class=\"built_in\">int</span>[] L, <span class=\"built_in\">int</span> <span class=\"built_in\">n</span>)<span class=\"symbol\">:</span></span><br><span class=\"line\">  while (<span class=\"built_in\">n</span> &gt; <span class=\"number\">0</span>)</span><br><span class=\"line\">    find_max(L, <span class=\"built_in\">n</span>);</span><br><span class=\"line\">    <span class=\"built_in\">n</span> = <span class=\"built_in\">n</span>/<span class=\"number\">4</span>;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><br><img src=\"ans_7.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p>The complete graph on n vertices, denoted <script type=\"math/tex\">K_n</script>, is a simple graph in which there is an edge between every pair of distinct vertices. What is the height of the DFS tree for the complete graph <script type=\"math/tex\">K_n</script>? What is the height of the BFS tree for the complete graph <script type=\"math/tex\">K_n</script>?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>We are interested in finding a simple path in a directed acyclic graph that visits all vertices once and only once. Design a linear time algorithm to determine if there is such a path in a given DAG.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Prove that a complete graph <script type=\"math/tex\">K_5</script> is not a planar graph.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Prove that a complete bipartite graph <script type=\"math/tex\">K_{3,3}</script> is not a planar graph.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>In a connected bipartite graph, is the bipartition unique? Justify your answer.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Given a directed graph G = (V, E) and a particular node v ∈ V, design a linear time algorithm to determine whether v is in a triangle of edges (a cycle of length 3).</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Design a linear time algorithm which, given an undirected graph G = (V, E) and a particular edge e ∈ E, determines whether G has a cycle containing e.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Given an undirected graph G = (V, E), prove that S is an independent set if and only if V - S is a vertex cover</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n</ol>\n"},{"title":"$$[Algorithms \\, In \\, Action]-CH2\\,Amortized \\,\\, Analysis$$","catalog":true,"mathjax":true,"date":"2021-01-24T19:09:23.000Z","subtitle":null,"header-img":"cruves.png","_content":"\n### Amortized Analysis\nIn a sequence of operations, the worst-case time does not occur often in each oper ation; some operations may be cheap, some may be expensive. Therefore, a traditional worst-case per operation analysis **Big O** can give an overly pessimistic bound. \n> That why we need Amortized analysis.\n\nThere are generally three methods for performing amortized analysis:\n1. The aggregate method computes the upper bound **T(n)** on the total cost of **n** operations. The amortized cost is given by **T(n)/n**. In this method each operation will get the same amortized cost, even if there are several types of operations in the sequence.\n2. The accounting method (or the banker’s method) computes the individual cost of each operation. We assign different charges to each operation; some operations may charge more or less than they actually cost. The amount we charge an operation is called its amortized cost.\n3. The potential method (or the physicist’s method). We won’t use a potential method in this course\n\n#### Unbounded Array\n\n#### Binary Counter\n\n### Topological Sort\n  - **T(n)** counts the \\# of steps, where *n* is the input size.\n  - **O** big O, $$\\exists \\, c $$ which *c* > 0 and real number $${n_0}$$, has $$f(n) \t\\leqslant c \\cdot g(n)$$, for all  $$n \\geqslant {n_0}$$.\n  - **Ω** big Omega, $$\\exists \\, c $$ which *c* > 0 and real number $${n_0}$$, has $$f(n) \t\\geqslant c \\cdot g(n)$$, for all  $$n \\geqslant {n_0}$$.\n  - **Θ** big Theta, $$\\exists \\, {c_1} \\, and \\, {c_2} $$ which $${c_1}$$ > 0 and $${c_2}$$ > 0 and real number $${n_0}$$, has $${c_1} \\cdot g(n) \\leqslant f(n)\t\\leqslant {c_2} \\cdot g(n)$$, for all  $$n \\geqslant {n_0}$$.\n\n### Hamiltonian Path\n - finding the **longest path** in a directed acyclic graph (DAG)\n\n###Strongly Connected Graph\n - how to prove a graph is a strongly connected graph\n <img src=\"s_c_graph.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n\n### Review Q&A\n1. What is the definition of the amortized cost using the aggregate method? <img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\">\n\t> - **Solution**\n\t> - The aggregate method computes the upper bound **T(n)** on the total cost of **n** operations. The amortized cost is given by **T(n)/n**. In this method each operation will get the same amortized cost, even if there are several types of operations in the sequence.\n\n2. **(T/F)** Amortized analysis is used to determine the average runtime complexity of an algorithm.\n\t> - **False**\n\t> - what is \"average complexity\"? that is ask you to compute the runtime complexity of a single operation when given **n** random input.(focus on this operation and compute all best case, bad case and so on. )\n\t> - \"Amortized analysis\" is another concept, actually this analysis is looking at the worst-case run time per operation, rather than per input, that's the difference. (focus on a sequene of operation and in worst-case.)\n\n3. **(T/F)** Compared to the worst-case analysis, amortized analysis provides a more accurate upper bound on the performance of an algorithm.\n\t> - **True**\n\t> - that's what the definition says.\n\n4. **(T/F)** The total amortized cost of a sequence of **n** operations gives a lower bound on the total actual cost of the sequence.\n\t> - **False**\n\t> - The aggregate method computes the upper bound **T(n)** on the total cost of n operations.\n\n5. **(T/F)** Amortized constant time for a dynamic array is still guaranteed if we increase the array size by 5%.\n\t> - **True**\n\t> - In practice, programming languages, like JAVA and Python extend array capacity by multiple 1.6, which means increasing the array size by 60%. And ithey still can remain the constant runtime complexity. So if only increase 5%, it will work as well.\n\n6. **(T/F)** If an operation takes O(1) expected time, then it takes O(1) amortized time.\n\t> - **False**\n\t> - \"expected time\" equals to \"avgerage time\". \n\n7. Suppose you have a data structure such that a sequence of n operations has an amortized cost of **O(n * log n)**. What could be the highest actual time of a single operation?\n\t> - **Solution**\n\t> - less than **O(n * log n)**\n8. What is the worst-case runtime complexity of searching in an amortized dictionary?\n\t> - **Solution**\n\n### Exercise Q&A\n1. You have a stack data type, and you need to implement a FIFO queue. The stack has the usual POP and PUSH operations, and the cost of each operation is 1. The FIFO has two operations: ENQUEUE and DEQUEUE. We can implement a FIFO queue using two stacks. What is the amortized cost of ENQUEUE and DEQUEUE operations?\n\t> - **Solution**\n\t> <img src=\"dequeue.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n2. We are incrementing a binary counter, where flipping the i-th bit costs i + 1. Flipping the lowest-order bit costs 0 + 1 = 1, the next bit costs 1 + 1 = 2, the next bit costs 2 + 1 = 3, and so on. What is the amortized cost per operation for a sequence of n increments, starting from zero?\n\t> - **Solution**\n\t> <img src=\"binary_counter.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n3. We have argued in the lecture that if the table size is doubled when it’s full, then the amortized cost per insert is acceptable. Fred Hacker claims that this consumes too much space. He wants to try to increase the size with every insert by just two over the previous size. What is the amortized cost per insertion in Fred’s table?\n\t> - **Solution**\n\n4. This table supports inserts as well as deletions. The protocol is the following: If an array is full, we double its size on insertion; if an array is 1/4 full, we halve the array size on deletion. Show that the amortized cost of insert and delete is 5.\n\t> - **Solution**\n\n5. Suppose we perform a sequence of n operations on a data structure in which the i-th operation costs i if i is an exact power of 2 and 1 otherwise. Use aggregate analysis to determine the amortized cost per operation.\n\t> - **Solution**\n\t> Assume $n = 2^k$ operations, and these operation can be split into two parts.\n\t> 1. if *i* is an exact power of 2, $cost(i) = 2^i$, which $i \\in k$. <br>\n\t>> part 1 cost = $\\Sigma^{k}_{i=0} 2^i$\n\t> 2. if not, the remaining operations will cost 1.  <br>\n\t>> part 2 cost = $n - k - 1$\n\n\t> So all cost is:<br>\n\t> $Cost = \\Sigma^{k}_{i=0} 2^i + n - k - 1$ <br>\n\t> $\\quad \\quad = 2^{k + 1} - 1 + n - k - 1$ <br>\n\t> $\\quad \\quad = 2 \\cdot n + n - k - 2$ <br>\n\t> $\\quad \\quad = 3 \\cdot n - k - 2$ <br>\n\t> $\\quad \\quad = 3 \\cdot n - 2 - log_2 n$ <br>\n\nSo cost per operation = $\\frac{3 \\cdot n - 2 - log_2 n}{n} = O(3)$\n\n6. Suppose we perform a sequence of n operations on a data structure in which the i-th operation costs i if i is an exact power of 4 and 1 otherwise. Use aggregate analysis to determine the amortized cost per operation.\n\t> - **Solution**\n\n7. A MultiStack data structure has the usual POP and PUSH operations, and the cost of each operation is one unit. Additionally, it has MULTIPOP(k) operation that removes k recently pushed items. If k is bigger than the stack size, it removes all items. We wish to analyze the running time for a sequence of n PUSH, POP, and MULTIPOP operations, starting with an empty stack. What is the worst-case complexity for a sequence of n operations? What is the amortized cost per operation? Use the accounting method.\n\t> - **Solution**\n\n8. Consider a singly linked list as a dictionary that we always insert at the beginning of the list. Now assume that you may perform any number of insert operations but will only ever perform at most one lookup operation. What is the amortized cost per operation?\n\t> - **Solution**\n\t","source":"_posts/AIA-ch2-Q-A.md","raw":"---\ntitle: $$[Algorithms \\, In \\, Action]-CH2\\,Amortized \\,\\, Analysis$$\ncatalog: true\nmathjax: true\ndate: 2021-01-24 11:09:23\nsubtitle:\nheader-img: cruves.png\ntags:\n- Review\n- Amortized Analysis\n- Q&A\ncategories:\n- CSCI 570\n---\n\n### Amortized Analysis\nIn a sequence of operations, the worst-case time does not occur often in each oper ation; some operations may be cheap, some may be expensive. Therefore, a traditional worst-case per operation analysis **Big O** can give an overly pessimistic bound. \n> That why we need Amortized analysis.\n\nThere are generally three methods for performing amortized analysis:\n1. The aggregate method computes the upper bound **T(n)** on the total cost of **n** operations. The amortized cost is given by **T(n)/n**. In this method each operation will get the same amortized cost, even if there are several types of operations in the sequence.\n2. The accounting method (or the banker’s method) computes the individual cost of each operation. We assign different charges to each operation; some operations may charge more or less than they actually cost. The amount we charge an operation is called its amortized cost.\n3. The potential method (or the physicist’s method). We won’t use a potential method in this course\n\n#### Unbounded Array\n\n#### Binary Counter\n\n### Topological Sort\n  - **T(n)** counts the \\# of steps, where *n* is the input size.\n  - **O** big O, $$\\exists \\, c $$ which *c* > 0 and real number $${n_0}$$, has $$f(n) \t\\leqslant c \\cdot g(n)$$, for all  $$n \\geqslant {n_0}$$.\n  - **Ω** big Omega, $$\\exists \\, c $$ which *c* > 0 and real number $${n_0}$$, has $$f(n) \t\\geqslant c \\cdot g(n)$$, for all  $$n \\geqslant {n_0}$$.\n  - **Θ** big Theta, $$\\exists \\, {c_1} \\, and \\, {c_2} $$ which $${c_1}$$ > 0 and $${c_2}$$ > 0 and real number $${n_0}$$, has $${c_1} \\cdot g(n) \\leqslant f(n)\t\\leqslant {c_2} \\cdot g(n)$$, for all  $$n \\geqslant {n_0}$$.\n\n### Hamiltonian Path\n - finding the **longest path** in a directed acyclic graph (DAG)\n\n###Strongly Connected Graph\n - how to prove a graph is a strongly connected graph\n <img src=\"s_c_graph.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n\n### Review Q&A\n1. What is the definition of the amortized cost using the aggregate method? <img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\">\n\t> - **Solution**\n\t> - The aggregate method computes the upper bound **T(n)** on the total cost of **n** operations. The amortized cost is given by **T(n)/n**. In this method each operation will get the same amortized cost, even if there are several types of operations in the sequence.\n\n2. **(T/F)** Amortized analysis is used to determine the average runtime complexity of an algorithm.\n\t> - **False**\n\t> - what is \"average complexity\"? that is ask you to compute the runtime complexity of a single operation when given **n** random input.(focus on this operation and compute all best case, bad case and so on. )\n\t> - \"Amortized analysis\" is another concept, actually this analysis is looking at the worst-case run time per operation, rather than per input, that's the difference. (focus on a sequene of operation and in worst-case.)\n\n3. **(T/F)** Compared to the worst-case analysis, amortized analysis provides a more accurate upper bound on the performance of an algorithm.\n\t> - **True**\n\t> - that's what the definition says.\n\n4. **(T/F)** The total amortized cost of a sequence of **n** operations gives a lower bound on the total actual cost of the sequence.\n\t> - **False**\n\t> - The aggregate method computes the upper bound **T(n)** on the total cost of n operations.\n\n5. **(T/F)** Amortized constant time for a dynamic array is still guaranteed if we increase the array size by 5%.\n\t> - **True**\n\t> - In practice, programming languages, like JAVA and Python extend array capacity by multiple 1.6, which means increasing the array size by 60%. And ithey still can remain the constant runtime complexity. So if only increase 5%, it will work as well.\n\n6. **(T/F)** If an operation takes O(1) expected time, then it takes O(1) amortized time.\n\t> - **False**\n\t> - \"expected time\" equals to \"avgerage time\". \n\n7. Suppose you have a data structure such that a sequence of n operations has an amortized cost of **O(n * log n)**. What could be the highest actual time of a single operation?\n\t> - **Solution**\n\t> - less than **O(n * log n)**\n8. What is the worst-case runtime complexity of searching in an amortized dictionary?\n\t> - **Solution**\n\n### Exercise Q&A\n1. You have a stack data type, and you need to implement a FIFO queue. The stack has the usual POP and PUSH operations, and the cost of each operation is 1. The FIFO has two operations: ENQUEUE and DEQUEUE. We can implement a FIFO queue using two stacks. What is the amortized cost of ENQUEUE and DEQUEUE operations?\n\t> - **Solution**\n\t> <img src=\"dequeue.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n2. We are incrementing a binary counter, where flipping the i-th bit costs i + 1. Flipping the lowest-order bit costs 0 + 1 = 1, the next bit costs 1 + 1 = 2, the next bit costs 2 + 1 = 3, and so on. What is the amortized cost per operation for a sequence of n increments, starting from zero?\n\t> - **Solution**\n\t> <img src=\"binary_counter.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n3. We have argued in the lecture that if the table size is doubled when it’s full, then the amortized cost per insert is acceptable. Fred Hacker claims that this consumes too much space. He wants to try to increase the size with every insert by just two over the previous size. What is the amortized cost per insertion in Fred’s table?\n\t> - **Solution**\n\n4. This table supports inserts as well as deletions. The protocol is the following: If an array is full, we double its size on insertion; if an array is 1/4 full, we halve the array size on deletion. Show that the amortized cost of insert and delete is 5.\n\t> - **Solution**\n\n5. Suppose we perform a sequence of n operations on a data structure in which the i-th operation costs i if i is an exact power of 2 and 1 otherwise. Use aggregate analysis to determine the amortized cost per operation.\n\t> - **Solution**\n\t> Assume $n = 2^k$ operations, and these operation can be split into two parts.\n\t> 1. if *i* is an exact power of 2, $cost(i) = 2^i$, which $i \\in k$. <br>\n\t>> part 1 cost = $\\Sigma^{k}_{i=0} 2^i$\n\t> 2. if not, the remaining operations will cost 1.  <br>\n\t>> part 2 cost = $n - k - 1$\n\n\t> So all cost is:<br>\n\t> $Cost = \\Sigma^{k}_{i=0} 2^i + n - k - 1$ <br>\n\t> $\\quad \\quad = 2^{k + 1} - 1 + n - k - 1$ <br>\n\t> $\\quad \\quad = 2 \\cdot n + n - k - 2$ <br>\n\t> $\\quad \\quad = 3 \\cdot n - k - 2$ <br>\n\t> $\\quad \\quad = 3 \\cdot n - 2 - log_2 n$ <br>\n\nSo cost per operation = $\\frac{3 \\cdot n - 2 - log_2 n}{n} = O(3)$\n\n6. Suppose we perform a sequence of n operations on a data structure in which the i-th operation costs i if i is an exact power of 4 and 1 otherwise. Use aggregate analysis to determine the amortized cost per operation.\n\t> - **Solution**\n\n7. A MultiStack data structure has the usual POP and PUSH operations, and the cost of each operation is one unit. Additionally, it has MULTIPOP(k) operation that removes k recently pushed items. If k is bigger than the stack size, it removes all items. We wish to analyze the running time for a sequence of n PUSH, POP, and MULTIPOP operations, starting with an empty stack. What is the worst-case complexity for a sequence of n operations? What is the amortized cost per operation? Use the accounting method.\n\t> - **Solution**\n\n8. Consider a singly linked list as a dictionary that we always insert at the beginning of the list. Now assume that you may perform any number of insert operations but will only ever perform at most one lookup operation. What is the amortized cost per operation?\n\t> - **Solution**\n\t","slug":"AIA-ch2-Q-A","published":1,"updated":"2021-02-08T00:15:52.989Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cklbvizon0002xctt9ouzfbsd","content":"<h3 id=\"Amortized-Analysis\"><a href=\"#Amortized-Analysis\" class=\"headerlink\" title=\"Amortized Analysis\"></a>Amortized Analysis</h3><p>In a sequence of operations, the worst-case time does not occur often in each oper ation; some operations may be cheap, some may be expensive. Therefore, a traditional worst-case per operation analysis <strong>Big O</strong> can give an overly pessimistic bound. </p>\n<blockquote>\n<p>That why we need Amortized analysis.</p>\n</blockquote>\n<p>There are generally three methods for performing amortized analysis:</p>\n<ol>\n<li>The aggregate method computes the upper bound <strong>T(n)</strong> on the total cost of <strong>n</strong> operations. The amortized cost is given by <strong>T(n)/n</strong>. In this method each operation will get the same amortized cost, even if there are several types of operations in the sequence.</li>\n<li>The accounting method (or the banker’s method) computes the individual cost of each operation. We assign different charges to each operation; some operations may charge more or less than they actually cost. The amount we charge an operation is called its amortized cost.</li>\n<li>The potential method (or the physicist’s method). We won’t use a potential method in this course</li>\n</ol>\n<h4 id=\"Unbounded-Array\"><a href=\"#Unbounded-Array\" class=\"headerlink\" title=\"Unbounded Array\"></a>Unbounded Array</h4><h4 id=\"Binary-Counter\"><a href=\"#Binary-Counter\" class=\"headerlink\" title=\"Binary Counter\"></a>Binary Counter</h4><h3 id=\"Topological-Sort\"><a href=\"#Topological-Sort\" class=\"headerlink\" title=\"Topological Sort\"></a>Topological Sort</h3><ul>\n<li><strong>T(n)</strong> counts the # of steps, where <em>n</em> is the input size.</li>\n<li><strong>O</strong> big O, <script type=\"math/tex\">\\exists \\, c</script> which <em>c</em> &gt; 0 and real number <script type=\"math/tex\">{n_0}</script>, has <script type=\"math/tex\">f(n)     \\leqslant c \\cdot g(n)</script>, for all  <script type=\"math/tex\">n \\geqslant {n_0}</script>.</li>\n<li><strong>Ω</strong> big Omega, <script type=\"math/tex\">\\exists \\, c</script> which <em>c</em> &gt; 0 and real number <script type=\"math/tex\">{n_0}</script>, has <script type=\"math/tex\">f(n)     \\geqslant c \\cdot g(n)</script>, for all  <script type=\"math/tex\">n \\geqslant {n_0}</script>.</li>\n<li><strong>Θ</strong> big Theta, <script type=\"math/tex\">\\exists \\, {c_1} \\, and \\, {c_2}</script> which <script type=\"math/tex\">{c_1}</script> &gt; 0 and <script type=\"math/tex\">{c_2}</script> &gt; 0 and real number <script type=\"math/tex\">{n_0}</script>, has <script type=\"math/tex\">{c_1} \\cdot g(n) \\leqslant f(n)    \\leqslant {c_2} \\cdot g(n)</script>, for all  <script type=\"math/tex\">n \\geqslant {n_0}</script>.</li>\n</ul>\n<h3 id=\"Hamiltonian-Path\"><a href=\"#Hamiltonian-Path\" class=\"headerlink\" title=\"Hamiltonian Path\"></a>Hamiltonian Path</h3><ul>\n<li>finding the <strong>longest path</strong> in a directed acyclic graph (DAG)</li>\n</ul>\n<h3 id=\"Strongly-Connected-Graph\"><a href=\"#Strongly-Connected-Graph\" class=\"headerlink\" title=\"Strongly Connected Graph\"></a>Strongly Connected Graph</h3><ul>\n<li>how to prove a graph is a strongly connected graph<br><img src=\"s_c_graph.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n<h3 id=\"Review-Q-amp-A\"><a href=\"#Review-Q-amp-A\" class=\"headerlink\" title=\"Review Q&amp;A\"></a>Review Q&amp;A</h3><ol>\n<li><p>What is the definition of the amortized cost using the aggregate method? <img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\"></p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>The aggregate method computes the upper bound <strong>T(n)</strong> on the total cost of <strong>n</strong> operations. The amortized cost is given by <strong>T(n)/n</strong>. In this method each operation will get the same amortized cost, even if there are several types of operations in the sequence.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> Amortized analysis is used to determine the average runtime complexity of an algorithm.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>what is “average complexity”? that is ask you to compute the runtime complexity of a single operation when given <strong>n</strong> random input.(focus on this operation and compute all best case, bad case and so on. )</li>\n<li>“Amortized analysis” is another concept, actually this analysis is looking at the worst-case run time per operation, rather than per input, that’s the difference. (focus on a sequene of operation and in worst-case.)</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> Compared to the worst-case analysis, amortized analysis provides a more accurate upper bound on the performance of an algorithm.</p>\n<blockquote>\n<ul>\n<li><strong>True</strong></li>\n<li>that’s what the definition says.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> The total amortized cost of a sequence of <strong>n</strong> operations gives a lower bound on the total actual cost of the sequence.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>The aggregate method computes the upper bound <strong>T(n)</strong> on the total cost of n operations.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> Amortized constant time for a dynamic array is still guaranteed if we increase the array size by 5%.</p>\n<blockquote>\n<ul>\n<li><strong>True</strong></li>\n<li>In practice, programming languages, like JAVA and Python extend array capacity by multiple 1.6, which means increasing the array size by 60%. And ithey still can remain the constant runtime complexity. So if only increase 5%, it will work as well.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> If an operation takes O(1) expected time, then it takes O(1) amortized time.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>“expected time” equals to “avgerage time”. </li>\n</ul>\n</blockquote>\n</li>\n<li><p>Suppose you have a data structure such that a sequence of n operations has an amortized cost of <strong>O(n * log n)</strong>. What could be the highest actual time of a single operation?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>less than <strong>O(n * log n)</strong></li>\n</ul>\n</blockquote>\n</li>\n<li>What is the worst-case runtime complexity of searching in an amortized dictionary?<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n</ol>\n<h3 id=\"Exercise-Q-amp-A\"><a href=\"#Exercise-Q-amp-A\" class=\"headerlink\" title=\"Exercise Q&amp;A\"></a>Exercise Q&amp;A</h3><ol>\n<li><p>You have a stack data type, and you need to implement a FIFO queue. The stack has the usual POP and PUSH operations, and the cost of each operation is 1. The FIFO has two operations: ENQUEUE and DEQUEUE. We can implement a FIFO queue using two stacks. What is the amortized cost of ENQUEUE and DEQUEUE operations?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><br><img src=\"dequeue.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p>We are incrementing a binary counter, where flipping the i-th bit costs i + 1. Flipping the lowest-order bit costs 0 + 1 = 1, the next bit costs 1 + 1 = 2, the next bit costs 2 + 1 = 3, and so on. What is the amortized cost per operation for a sequence of n increments, starting from zero?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><br><img src=\"binary_counter.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p>We have argued in the lecture that if the table size is doubled when it’s full, then the amortized cost per insert is acceptable. Fred Hacker claims that this consumes too much space. He wants to try to increase the size with every insert by just two over the previous size. What is the amortized cost per insertion in Fred’s table?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>This table supports inserts as well as deletions. The protocol is the following: If an array is full, we double its size on insertion; if an array is 1/4 full, we halve the array size on deletion. Show that the amortized cost of insert and delete is 5.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Suppose we perform a sequence of n operations on a data structure in which the i-th operation costs i if i is an exact power of 2 and 1 otherwise. Use aggregate analysis to determine the amortized cost per operation.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><br>Assume $n = 2^k$ operations, and these operation can be split into two parts.</li>\n</ul>\n<ol>\n<li>if <em>i</em> is an exact power of 2, $cost(i) = 2^i$, which $i \\in k$. <br><blockquote>\n<p>part 1 cost = $\\Sigma^{k}_{i=0} 2^i$</p>\n</blockquote>\n</li>\n<li>if not, the remaining operations will cost 1.  <br><blockquote>\n<p>part 2 cost = $n - k - 1$</p>\n</blockquote>\n</li>\n</ol>\n<p>So all cost is:<br><br>$Cost = \\Sigma^{k}_{i=0} 2^i + n - k - 1$ <br><br>$\\quad \\quad = 2^{k + 1} - 1 + n - k - 1$ <br><br>$\\quad \\quad = 2 \\cdot n + n - k - 2$ <br><br>$\\quad \\quad = 3 \\cdot n - k - 2$ <br><br>$\\quad \\quad = 3 \\cdot n - 2 - log_2 n$ <br></p>\n</blockquote>\n</li>\n</ol>\n<p>So cost per operation = $\\frac{3 \\cdot n - 2 - log_2 n}{n} = O(3)$</p>\n<ol>\n<li><p>Suppose we perform a sequence of n operations on a data structure in which the i-th operation costs i if i is an exact power of 4 and 1 otherwise. Use aggregate analysis to determine the amortized cost per operation.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>A MultiStack data structure has the usual POP and PUSH operations, and the cost of each operation is one unit. Additionally, it has MULTIPOP(k) operation that removes k recently pushed items. If k is bigger than the stack size, it removes all items. We wish to analyze the running time for a sequence of n PUSH, POP, and MULTIPOP operations, starting with an empty stack. What is the worst-case complexity for a sequence of n operations? What is the amortized cost per operation? Use the accounting method.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Consider a singly linked list as a dictionary that we always insert at the beginning of the list. Now assume that you may perform any number of insert operations but will only ever perform at most one lookup operation. What is the amortized cost per operation?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Amortized-Analysis\"><a href=\"#Amortized-Analysis\" class=\"headerlink\" title=\"Amortized Analysis\"></a>Amortized Analysis</h3><p>In a sequence of operations, the worst-case time does not occur often in each oper ation; some operations may be cheap, some may be expensive. Therefore, a traditional worst-case per operation analysis <strong>Big O</strong> can give an overly pessimistic bound. </p>\n<blockquote>\n<p>That why we need Amortized analysis.</p>\n</blockquote>\n<p>There are generally three methods for performing amortized analysis:</p>\n<ol>\n<li>The aggregate method computes the upper bound <strong>T(n)</strong> on the total cost of <strong>n</strong> operations. The amortized cost is given by <strong>T(n)/n</strong>. In this method each operation will get the same amortized cost, even if there are several types of operations in the sequence.</li>\n<li>The accounting method (or the banker’s method) computes the individual cost of each operation. We assign different charges to each operation; some operations may charge more or less than they actually cost. The amount we charge an operation is called its amortized cost.</li>\n<li>The potential method (or the physicist’s method). We won’t use a potential method in this course</li>\n</ol>\n<h4 id=\"Unbounded-Array\"><a href=\"#Unbounded-Array\" class=\"headerlink\" title=\"Unbounded Array\"></a>Unbounded Array</h4><h4 id=\"Binary-Counter\"><a href=\"#Binary-Counter\" class=\"headerlink\" title=\"Binary Counter\"></a>Binary Counter</h4><h3 id=\"Topological-Sort\"><a href=\"#Topological-Sort\" class=\"headerlink\" title=\"Topological Sort\"></a>Topological Sort</h3><ul>\n<li><strong>T(n)</strong> counts the # of steps, where <em>n</em> is the input size.</li>\n<li><strong>O</strong> big O, <script type=\"math/tex\">\\exists \\, c</script> which <em>c</em> &gt; 0 and real number <script type=\"math/tex\">{n_0}</script>, has <script type=\"math/tex\">f(n)     \\leqslant c \\cdot g(n)</script>, for all  <script type=\"math/tex\">n \\geqslant {n_0}</script>.</li>\n<li><strong>Ω</strong> big Omega, <script type=\"math/tex\">\\exists \\, c</script> which <em>c</em> &gt; 0 and real number <script type=\"math/tex\">{n_0}</script>, has <script type=\"math/tex\">f(n)     \\geqslant c \\cdot g(n)</script>, for all  <script type=\"math/tex\">n \\geqslant {n_0}</script>.</li>\n<li><strong>Θ</strong> big Theta, <script type=\"math/tex\">\\exists \\, {c_1} \\, and \\, {c_2}</script> which <script type=\"math/tex\">{c_1}</script> &gt; 0 and <script type=\"math/tex\">{c_2}</script> &gt; 0 and real number <script type=\"math/tex\">{n_0}</script>, has <script type=\"math/tex\">{c_1} \\cdot g(n) \\leqslant f(n)    \\leqslant {c_2} \\cdot g(n)</script>, for all  <script type=\"math/tex\">n \\geqslant {n_0}</script>.</li>\n</ul>\n<h3 id=\"Hamiltonian-Path\"><a href=\"#Hamiltonian-Path\" class=\"headerlink\" title=\"Hamiltonian Path\"></a>Hamiltonian Path</h3><ul>\n<li>finding the <strong>longest path</strong> in a directed acyclic graph (DAG)</li>\n</ul>\n<h3 id=\"Strongly-Connected-Graph\"><a href=\"#Strongly-Connected-Graph\" class=\"headerlink\" title=\"Strongly Connected Graph\"></a>Strongly Connected Graph</h3><ul>\n<li>how to prove a graph is a strongly connected graph<br><img src=\"s_c_graph.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n<h3 id=\"Review-Q-amp-A\"><a href=\"#Review-Q-amp-A\" class=\"headerlink\" title=\"Review Q&amp;A\"></a>Review Q&amp;A</h3><ol>\n<li><p>What is the definition of the amortized cost using the aggregate method? <img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\"></p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>The aggregate method computes the upper bound <strong>T(n)</strong> on the total cost of <strong>n</strong> operations. The amortized cost is given by <strong>T(n)/n</strong>. In this method each operation will get the same amortized cost, even if there are several types of operations in the sequence.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> Amortized analysis is used to determine the average runtime complexity of an algorithm.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>what is “average complexity”? that is ask you to compute the runtime complexity of a single operation when given <strong>n</strong> random input.(focus on this operation and compute all best case, bad case and so on. )</li>\n<li>“Amortized analysis” is another concept, actually this analysis is looking at the worst-case run time per operation, rather than per input, that’s the difference. (focus on a sequene of operation and in worst-case.)</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> Compared to the worst-case analysis, amortized analysis provides a more accurate upper bound on the performance of an algorithm.</p>\n<blockquote>\n<ul>\n<li><strong>True</strong></li>\n<li>that’s what the definition says.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> The total amortized cost of a sequence of <strong>n</strong> operations gives a lower bound on the total actual cost of the sequence.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>The aggregate method computes the upper bound <strong>T(n)</strong> on the total cost of n operations.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> Amortized constant time for a dynamic array is still guaranteed if we increase the array size by 5%.</p>\n<blockquote>\n<ul>\n<li><strong>True</strong></li>\n<li>In practice, programming languages, like JAVA and Python extend array capacity by multiple 1.6, which means increasing the array size by 60%. And ithey still can remain the constant runtime complexity. So if only increase 5%, it will work as well.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> If an operation takes O(1) expected time, then it takes O(1) amortized time.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>“expected time” equals to “avgerage time”. </li>\n</ul>\n</blockquote>\n</li>\n<li><p>Suppose you have a data structure such that a sequence of n operations has an amortized cost of <strong>O(n * log n)</strong>. What could be the highest actual time of a single operation?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>less than <strong>O(n * log n)</strong></li>\n</ul>\n</blockquote>\n</li>\n<li>What is the worst-case runtime complexity of searching in an amortized dictionary?<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n</ol>\n<h3 id=\"Exercise-Q-amp-A\"><a href=\"#Exercise-Q-amp-A\" class=\"headerlink\" title=\"Exercise Q&amp;A\"></a>Exercise Q&amp;A</h3><ol>\n<li><p>You have a stack data type, and you need to implement a FIFO queue. The stack has the usual POP and PUSH operations, and the cost of each operation is 1. The FIFO has two operations: ENQUEUE and DEQUEUE. We can implement a FIFO queue using two stacks. What is the amortized cost of ENQUEUE and DEQUEUE operations?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><br><img src=\"dequeue.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p>We are incrementing a binary counter, where flipping the i-th bit costs i + 1. Flipping the lowest-order bit costs 0 + 1 = 1, the next bit costs 1 + 1 = 2, the next bit costs 2 + 1 = 3, and so on. What is the amortized cost per operation for a sequence of n increments, starting from zero?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><br><img src=\"binary_counter.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p>We have argued in the lecture that if the table size is doubled when it’s full, then the amortized cost per insert is acceptable. Fred Hacker claims that this consumes too much space. He wants to try to increase the size with every insert by just two over the previous size. What is the amortized cost per insertion in Fred’s table?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>This table supports inserts as well as deletions. The protocol is the following: If an array is full, we double its size on insertion; if an array is 1/4 full, we halve the array size on deletion. Show that the amortized cost of insert and delete is 5.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Suppose we perform a sequence of n operations on a data structure in which the i-th operation costs i if i is an exact power of 2 and 1 otherwise. Use aggregate analysis to determine the amortized cost per operation.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><br>Assume $n = 2^k$ operations, and these operation can be split into two parts.</li>\n</ul>\n<ol>\n<li>if <em>i</em> is an exact power of 2, $cost(i) = 2^i$, which $i \\in k$. <br><blockquote>\n<p>part 1 cost = $\\Sigma^{k}_{i=0} 2^i$</p>\n</blockquote>\n</li>\n<li>if not, the remaining operations will cost 1.  <br><blockquote>\n<p>part 2 cost = $n - k - 1$</p>\n</blockquote>\n</li>\n</ol>\n<p>So all cost is:<br><br>$Cost = \\Sigma^{k}_{i=0} 2^i + n - k - 1$ <br><br>$\\quad \\quad = 2^{k + 1} - 1 + n - k - 1$ <br><br>$\\quad \\quad = 2 \\cdot n + n - k - 2$ <br><br>$\\quad \\quad = 3 \\cdot n - k - 2$ <br><br>$\\quad \\quad = 3 \\cdot n - 2 - log_2 n$ <br></p>\n</blockquote>\n</li>\n</ol>\n<p>So cost per operation = $\\frac{3 \\cdot n - 2 - log_2 n}{n} = O(3)$</p>\n<ol>\n<li><p>Suppose we perform a sequence of n operations on a data structure in which the i-th operation costs i if i is an exact power of 4 and 1 otherwise. Use aggregate analysis to determine the amortized cost per operation.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>A MultiStack data structure has the usual POP and PUSH operations, and the cost of each operation is one unit. Additionally, it has MULTIPOP(k) operation that removes k recently pushed items. If k is bigger than the stack size, it removes all items. We wish to analyze the running time for a sequence of n PUSH, POP, and MULTIPOP operations, starting with an empty stack. What is the worst-case complexity for a sequence of n operations? What is the amortized cost per operation? Use the accounting method.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Consider a singly linked list as a dictionary that we always insert at the beginning of the list. Now assume that you may perform any number of insert operations but will only ever perform at most one lookup operation. What is the amortized cost per operation?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n</ul>\n</blockquote>\n</li>\n</ol>\n"},{"title":"$$[Algorithms \\, In \\, Action]-CH4\\, Greedy \\,\\, Algorithms$$","catalog":true,"mathjax":true,"date":"2021-02-16T06:01:43.000Z","subtitle":null,"header-img":"cruves.png","_content":"\n### Gneral Solution\n#### Shortest Path**\n> Dijkstra **(cannot has negative weight)**\n> BFS **(require a graph doesn't consider weight)**\n> Topological Sort **(require directed graph)**\n\n#### Minimum Cost\n> MST\n\n### Minimum Spanning Trees\n#### Kruskal's Algorithm\n> <img src=\"Kruskal.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n#### Prim's Algorithm\n> **Complexity**\n>> <img src=\"Prim.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n#### Feature\n> The smallest crossing edge must be in the MST.\n\n#### Dijkstra's Algorithm\n> does not work on graphs with negative weights.\n> <img src=\"dij1.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n#### Huffman Tree\n\n### Review Q&A\n1. **(T/F)** In the interval scheduling problem, if all intervals are of equal size, a greedy algorithm based on earliest start time will always select the maximum number of compatible intervals.\n\t> - **False**\n\t> - we need to sort by the finish time first and then find the compatible intervals.\n\n2. **(T/F)** Any weighted undirected graph with distinct edge weights has exactly one minimum spanning tree.\n\t> - **False**\n\t> - maybe differnt order.\n\t> <img src=\"r2.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n3. **(T/F)** Suppose we have a graph where each edge weight value appears at most twice. Then, there are at most two minimum spanning trees in this graph.\n\t> - **False**\n\t> - maybe some points are unreachable.\n\n4. **(T/F)** Kruskal’s algorithm can fail in the presence of negative cost edges.\n\t> - **False**\n\t> - it should work.\n\n5. **(T/F)** If a connected undirected graph $$G = (V, E)$$ has $n = |V|$ vertices and $n + 5$ edges, we can find the minimum spanning tree of $$G$$ in $O(n)$ runtime.\n\t> - **True**\n\t> - first, this graph has a circle at least.\n\t> the original time complexity of prim algorithm is $O((V + E) \\cdot log(V))$. but this complexity is for complete graph.<br>\n\t> about this issue, the heap size = 6, so we can say the $log(V)$ is a constant. So we can find the MST in a linear time.\n\t> <img src=\"r5.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n6. **(T/F)** The first edge added by Kruskal’s algorithm can be the last edge added by Prim’s algorithm.\n\t> - **True**\n\t> - possible\n\n7. **(T/F)** Suppose graph $$G$$ has a unique minimum spanning tree and graph $$G_1$$ is obtained by increasing the weight of every edge in $$G$$ by 1. The MST of $$G_1$$ must be different from the MST of $$G$$.\n\t> - **False**\n\t> - could be the same if the new added edge has a same weight of others.\n\n8. **(T/F)** Suppose graph $$G$$ has a unique minimum spanning tree and graph $$G_1$$ is obtained by squaring the weight of every edge in $$G$$. The MST of $$G_1$$ may be different from the MST of $$G$$.\n\t> - **True**\n\t> - square a negative num result in a positive integer.\n\n9. **(T/F)** If path $P$ is the shortest path from $u$ to $v$ and $w$ is a node on the path, then the part of path $P$ from $u$ to $w$ is also the shortest path.\n\t> - **False**\n\t> - maybe not\n\n10. **(T/F)** If all edges in a connected undirected graph have distinct positive weights, the shortest path between any two vertices is unique.\n\t> - **False**\n\t> <img src=\"r10.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n11. **(T/F)** Suppose we have calculated the shortest paths from a source to all other vertices. If we modify the original graph $$G$$ such that weights of all edges are doubled, then the shortest path tree of $$G$$ is also the shortest path tree of the modified graph.\n\t> - **True**\n\t> - $x + y + z < a + b$\n\t> - $2 \\cdot (x + y + z) <2 \\cdot (a + b)$ for sure.\n\n12. **(T/F)** Suppose we have calculated the shortest paths from a source to all other vertices. If we modify the original graph, $$G$$, such that weights of all edges are increased by 2, then the shortest path tree of $$G$$ is also the shortest path tree of the modified graph.\n\t> - **False**\n\t> - could be different.\n\t> - counter example.\n\t> <img src=\"r12.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n### Exercise Q&A\n1. At the Perfect Programming Company, the programmers are paired in order to ensure the highest quality of produced code. The productivity of each pair is the speed of the slowest programmer. Assuming an even number of programmers, devise an efficient algorithm for pairing them up so the total productivity of all programmers is maximized.\n\t> - **Solution**\n\t>> **A simple greedy algorithm works for this problem.** Sort the speeds of the programmers in decreasing order using an optimal sorting algorithm such as merge sort. Consecutive sorted programmers are then paired together starting with pairing the fastest programmer with the second fastest programmer. <br>\n\t>> Sorting takes $O(n \\cdot log(n))$ time while pairing the programmers takes $O(n)$ time giving a total running time of O(n lg n). <br>\n\t>> Correctness: Let $P$ be the set of programmers. The problem exhibits an optimal substructure. Assume the optimal pairing. Given any pair of programmers $(i, j)$ in the optimal pairing, the optimal sum of productivity is just the sum of the productivity of $(i, j)$ with the optimal sum of the productivity of the all pairs in $P − {i, j}$. <br>\n\t>>  We now show that the greedy choice works by showing that there exists an optimal pairing such that the two fastest programmers are paired together. Assume an optimal pairing where fastest programmer $i$ is not paired with the second faster programmer $j$. Instead let $i$ be paired with $k$ and $j$ be paired with $l$. Let $p_i$ , $p_j$ , $p_k$ and $p_l$ be the programming speeds of $i$, $j$, $k$ and $l$ respectively. We now change the pairings by pairing $i$ with $j$ and $k$ with $l$. The change in the sum of productivities is <center>$$(p_j + min(p_k, p_l)) − (p_k + p_l) ≥ 0$$</center> since $p_j$ is at least as large as the larger of $p_k$ and $p_l$ . We now have an optimal pairing where the fastest programmer is paired with the second fastest programmer. Hence to find the optimal solution, we can keep pairing the two fastest remaining programmers together.\n\n2. A new startup, FastRoute, wants to route information along a path in a communication network, represented as a graph. Each vertex represents a router and each edge a wire between routers. The wires are weighted by the maximum bandwidth they can support. FastRoute comes to you and asks you to develop an algorithm to find the path with maximum bandwidth from any source $s_1, \\, s_2, \\, …, \\, s_k$ to any destination $t_1, \\, t_2, \\, …, \\, t_n$. Devise an algorithm that has the same runtime complexity as Dijkstra’s algorithm.\n\t> - **Solution**\n\t>> Data structure change: we’ll use a max heap instead of a min heap used in Dijkstra Algorithm.<br>\n\t>> Initialization of the min heap. Initially all nodes will have a distance (bandwidth) of zero from $s$, except the starting point $s$ which will have a bandwidth of $\\infty$ to itself.<br>\n\t>> Change in relaxation step. Based on the definition of a path’s bandwidth, the bandwidth of a path from $s$ to $u$ through $u$’s neighbor $v$ will be $d(u) = min( d(v)$,  $weigth(v,u) )$, because the bandwidth of a path is equal to the bandwidth of its lowest bandwidth edge. Therefore, in the relaxation step, we will be replacing:<br>\n\t>> $d(u) = min (d(u), d(v) + weigth(v,u))$<br>\n\t>> with<br>\n\t>> $d(u) = max (d(u), min (d(v) , weigth(v,u))$<br>\n\n3. You are given a set $S$ of $n$ points, labeled $1$ to $n$, on a line. You are also given a set of $k$ finite intervals $I_1, \\, …, \\, I_k$, where each interval $I_i$, is of the form $[s_i, e_i]$, $I \\leq s_i \\leq e_i$. Present an efficient algorithm to find the smallest subset $X \\subseteq S$ of points such that each interval contains at least one point from $X$. Prove that your solution is optimal.\n\t> - **Solution**\n\t>> Sort the intervals in increasing order of $e_i$ . Select the first point as the right end-point of the first interval in this order. Remove all intervals which intersect with this point, and repeat. Proof of correctness is similar to the interval scheduling problem discussed in class. If the algorithm picks points $p_1 < p_2 < · · · < p_k$, and optimum solution picks points $q_1 < q_2 < · · · , q_s$, then prove by induction that $p_i ≥ q_i$ , and so $k ≤ s$.\n\n4. You are given a minimum spanning tree $T$ in a graph $G = (V, E)$. Suppose we remove an edge from $G$, creating a new graph, $G_1$. Assuming that $G_1$ is still connected, devise a linear time algorithm to find an MST in $G_1$.<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\">\n\t> - **Solution**\n\t>> Once we delete an edge from $T$, the tree becomes disconnected. We need to find the minimum weight edge that connects two componets, say $T_1$ and $T_2$. Pick any component say $T_2$ and find all edges going to $T_1$. Among them choose the one which has the smallest cost. Runtime: $O(E)$.\n\n5. You are given a minimum spanning tree $T$ in a graph $G = (V, E)$. Suppose we add a new edge (without introducing any new vertices) to $G$, creating a new graph, $G_1$. Assuming that $G_1$ is still connected, devise a linear time algorithm to find an MST in $G_1$.<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\">\n\t> - **Solution**\n\t> <img src=\"e5.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n6. Given graph $G = (V, E)$ with positive edge weights, we know that Dijkstra’s algorithm can be implemented in $O((E + V) \\cdot log(V))$ time using a binary heap. Suppose you have been told that the input graph $G$ is a dense graph in which $E = O(V^2)$. Find a way to implement Dijkstra’s algorithm in $O(V^2)$ time.\n\t> - **Solution**\n\t> - **O(n)**\n7. Given a graph, $G = (V, E)$, whose edge weights are integers in the range $[0, W]$, where $W$ is a relatively small integer number, we could run Dijkstra’s algorithm to find the shortest distances from the start vertex to all other vertices. Design a new algorithm that will run in linear time $O(V + E)$ and therefore outperform Dijkstra’s algorithm.\n\t> - **Solution**\n\t> <img src=\"e7.png\"  style=\"display:inline;box-shadow: none !important;\">\n8. Given a directed acyclic graph, $G = (V, E)$, with nonnegative edge weights and the source $s$, devise a linear time algorithm to find the shortest distances from $s$ to all other vertices.\n\t> - **Solution**\n\t> - **O(n)**\n9. You are given a graph, $G = (V, E)$, with nonnegative edge weights and the shortest path distances $d(s, u)$ from a source vertex $s$ to all other vertices in $G$. However, you are not given the shortest path tree. Devise a linear time algorithm to find a shortest path from $s$ to a given vertex $t$.\n\t> - **Solution**\n\t>> Reverse edges in the original graph. This could be done in linear time (for example, using matrix transform). For all vertices that are connected to a given vertex $t$, find ones such that $d(s, t) = d(s, u) + d(u, t)$. Next, set $u$ as $t$ and repeat this to find new $u$ until $s$ equals to $u$. Nodes saved in the sequence are the shortest path from $s$ to a given vertex $t$.\n\n10. Given a graph, $G = (V, E)$, with nonnegative edge weights and two vertices s and t, the goal is to find the shortest path from $s$ to $t$ with an odd number of edges. Devise an algorithm that has the same runtime complexity as Dijkstra’s algorithm.\n\t> - **Solution**\n\t> - **O(n)**\n11. Given a graph,$G = (V, E)$, with nonnegative edge weights and the shortest path distances $d(u, v)$ between any pair of vertices in $G$, suppose we add a new edge (without introducing any new vertices) to $G$, creating a new graph $G_1$. Devise an efficient algorithm (that outperforms Dijkstra’s algorithm in the worst case) to update the shortest path distances $d(u, v)$.\n\t> - **Solution**\n\t> - **O(n)**\n12. Given $n$ rods of lengths $L_1, L_2, …, L_n$, respectively, the goal is to connect all the rods to form a single rod. The length and the cost of connecting two rods are equal to the sum of their lengths. Devise an algorithm to minimize the cost of forming a single rod. \n\t> - **Solution**\n\t> - **O(n)**\n\n13. Given a sorted array of frequencies of size $n$, devise a linear time algorithm for building a Huffman tree.\n\t> - **Solution**\n\t> - **O(n)**","source":"_posts/AIA-ch4-Q-A.md","raw":"---\ntitle: $$[Algorithms \\, In \\, Action]-CH4\\, Greedy \\,\\, Algorithms$$\ncatalog: true\nmathjax: true\ndate: 2021-02-15 22:01:43\nsubtitle:\nheader-img: cruves.png\ntags:\n- Review\n- Greedy Algorithm\n- Q&A\ncategories:\n- CSCI 570\n---\n\n### Gneral Solution\n#### Shortest Path**\n> Dijkstra **(cannot has negative weight)**\n> BFS **(require a graph doesn't consider weight)**\n> Topological Sort **(require directed graph)**\n\n#### Minimum Cost\n> MST\n\n### Minimum Spanning Trees\n#### Kruskal's Algorithm\n> <img src=\"Kruskal.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n#### Prim's Algorithm\n> **Complexity**\n>> <img src=\"Prim.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n#### Feature\n> The smallest crossing edge must be in the MST.\n\n#### Dijkstra's Algorithm\n> does not work on graphs with negative weights.\n> <img src=\"dij1.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n#### Huffman Tree\n\n### Review Q&A\n1. **(T/F)** In the interval scheduling problem, if all intervals are of equal size, a greedy algorithm based on earliest start time will always select the maximum number of compatible intervals.\n\t> - **False**\n\t> - we need to sort by the finish time first and then find the compatible intervals.\n\n2. **(T/F)** Any weighted undirected graph with distinct edge weights has exactly one minimum spanning tree.\n\t> - **False**\n\t> - maybe differnt order.\n\t> <img src=\"r2.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n3. **(T/F)** Suppose we have a graph where each edge weight value appears at most twice. Then, there are at most two minimum spanning trees in this graph.\n\t> - **False**\n\t> - maybe some points are unreachable.\n\n4. **(T/F)** Kruskal’s algorithm can fail in the presence of negative cost edges.\n\t> - **False**\n\t> - it should work.\n\n5. **(T/F)** If a connected undirected graph $$G = (V, E)$$ has $n = |V|$ vertices and $n + 5$ edges, we can find the minimum spanning tree of $$G$$ in $O(n)$ runtime.\n\t> - **True**\n\t> - first, this graph has a circle at least.\n\t> the original time complexity of prim algorithm is $O((V + E) \\cdot log(V))$. but this complexity is for complete graph.<br>\n\t> about this issue, the heap size = 6, so we can say the $log(V)$ is a constant. So we can find the MST in a linear time.\n\t> <img src=\"r5.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n6. **(T/F)** The first edge added by Kruskal’s algorithm can be the last edge added by Prim’s algorithm.\n\t> - **True**\n\t> - possible\n\n7. **(T/F)** Suppose graph $$G$$ has a unique minimum spanning tree and graph $$G_1$$ is obtained by increasing the weight of every edge in $$G$$ by 1. The MST of $$G_1$$ must be different from the MST of $$G$$.\n\t> - **False**\n\t> - could be the same if the new added edge has a same weight of others.\n\n8. **(T/F)** Suppose graph $$G$$ has a unique minimum spanning tree and graph $$G_1$$ is obtained by squaring the weight of every edge in $$G$$. The MST of $$G_1$$ may be different from the MST of $$G$$.\n\t> - **True**\n\t> - square a negative num result in a positive integer.\n\n9. **(T/F)** If path $P$ is the shortest path from $u$ to $v$ and $w$ is a node on the path, then the part of path $P$ from $u$ to $w$ is also the shortest path.\n\t> - **False**\n\t> - maybe not\n\n10. **(T/F)** If all edges in a connected undirected graph have distinct positive weights, the shortest path between any two vertices is unique.\n\t> - **False**\n\t> <img src=\"r10.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n11. **(T/F)** Suppose we have calculated the shortest paths from a source to all other vertices. If we modify the original graph $$G$$ such that weights of all edges are doubled, then the shortest path tree of $$G$$ is also the shortest path tree of the modified graph.\n\t> - **True**\n\t> - $x + y + z < a + b$\n\t> - $2 \\cdot (x + y + z) <2 \\cdot (a + b)$ for sure.\n\n12. **(T/F)** Suppose we have calculated the shortest paths from a source to all other vertices. If we modify the original graph, $$G$$, such that weights of all edges are increased by 2, then the shortest path tree of $$G$$ is also the shortest path tree of the modified graph.\n\t> - **False**\n\t> - could be different.\n\t> - counter example.\n\t> <img src=\"r12.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n### Exercise Q&A\n1. At the Perfect Programming Company, the programmers are paired in order to ensure the highest quality of produced code. The productivity of each pair is the speed of the slowest programmer. Assuming an even number of programmers, devise an efficient algorithm for pairing them up so the total productivity of all programmers is maximized.\n\t> - **Solution**\n\t>> **A simple greedy algorithm works for this problem.** Sort the speeds of the programmers in decreasing order using an optimal sorting algorithm such as merge sort. Consecutive sorted programmers are then paired together starting with pairing the fastest programmer with the second fastest programmer. <br>\n\t>> Sorting takes $O(n \\cdot log(n))$ time while pairing the programmers takes $O(n)$ time giving a total running time of O(n lg n). <br>\n\t>> Correctness: Let $P$ be the set of programmers. The problem exhibits an optimal substructure. Assume the optimal pairing. Given any pair of programmers $(i, j)$ in the optimal pairing, the optimal sum of productivity is just the sum of the productivity of $(i, j)$ with the optimal sum of the productivity of the all pairs in $P − {i, j}$. <br>\n\t>>  We now show that the greedy choice works by showing that there exists an optimal pairing such that the two fastest programmers are paired together. Assume an optimal pairing where fastest programmer $i$ is not paired with the second faster programmer $j$. Instead let $i$ be paired with $k$ and $j$ be paired with $l$. Let $p_i$ , $p_j$ , $p_k$ and $p_l$ be the programming speeds of $i$, $j$, $k$ and $l$ respectively. We now change the pairings by pairing $i$ with $j$ and $k$ with $l$. The change in the sum of productivities is <center>$$(p_j + min(p_k, p_l)) − (p_k + p_l) ≥ 0$$</center> since $p_j$ is at least as large as the larger of $p_k$ and $p_l$ . We now have an optimal pairing where the fastest programmer is paired with the second fastest programmer. Hence to find the optimal solution, we can keep pairing the two fastest remaining programmers together.\n\n2. A new startup, FastRoute, wants to route information along a path in a communication network, represented as a graph. Each vertex represents a router and each edge a wire between routers. The wires are weighted by the maximum bandwidth they can support. FastRoute comes to you and asks you to develop an algorithm to find the path with maximum bandwidth from any source $s_1, \\, s_2, \\, …, \\, s_k$ to any destination $t_1, \\, t_2, \\, …, \\, t_n$. Devise an algorithm that has the same runtime complexity as Dijkstra’s algorithm.\n\t> - **Solution**\n\t>> Data structure change: we’ll use a max heap instead of a min heap used in Dijkstra Algorithm.<br>\n\t>> Initialization of the min heap. Initially all nodes will have a distance (bandwidth) of zero from $s$, except the starting point $s$ which will have a bandwidth of $\\infty$ to itself.<br>\n\t>> Change in relaxation step. Based on the definition of a path’s bandwidth, the bandwidth of a path from $s$ to $u$ through $u$’s neighbor $v$ will be $d(u) = min( d(v)$,  $weigth(v,u) )$, because the bandwidth of a path is equal to the bandwidth of its lowest bandwidth edge. Therefore, in the relaxation step, we will be replacing:<br>\n\t>> $d(u) = min (d(u), d(v) + weigth(v,u))$<br>\n\t>> with<br>\n\t>> $d(u) = max (d(u), min (d(v) , weigth(v,u))$<br>\n\n3. You are given a set $S$ of $n$ points, labeled $1$ to $n$, on a line. You are also given a set of $k$ finite intervals $I_1, \\, …, \\, I_k$, where each interval $I_i$, is of the form $[s_i, e_i]$, $I \\leq s_i \\leq e_i$. Present an efficient algorithm to find the smallest subset $X \\subseteq S$ of points such that each interval contains at least one point from $X$. Prove that your solution is optimal.\n\t> - **Solution**\n\t>> Sort the intervals in increasing order of $e_i$ . Select the first point as the right end-point of the first interval in this order. Remove all intervals which intersect with this point, and repeat. Proof of correctness is similar to the interval scheduling problem discussed in class. If the algorithm picks points $p_1 < p_2 < · · · < p_k$, and optimum solution picks points $q_1 < q_2 < · · · , q_s$, then prove by induction that $p_i ≥ q_i$ , and so $k ≤ s$.\n\n4. You are given a minimum spanning tree $T$ in a graph $G = (V, E)$. Suppose we remove an edge from $G$, creating a new graph, $G_1$. Assuming that $G_1$ is still connected, devise a linear time algorithm to find an MST in $G_1$.<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\">\n\t> - **Solution**\n\t>> Once we delete an edge from $T$, the tree becomes disconnected. We need to find the minimum weight edge that connects two componets, say $T_1$ and $T_2$. Pick any component say $T_2$ and find all edges going to $T_1$. Among them choose the one which has the smallest cost. Runtime: $O(E)$.\n\n5. You are given a minimum spanning tree $T$ in a graph $G = (V, E)$. Suppose we add a new edge (without introducing any new vertices) to $G$, creating a new graph, $G_1$. Assuming that $G_1$ is still connected, devise a linear time algorithm to find an MST in $G_1$.<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\">\n\t> - **Solution**\n\t> <img src=\"e5.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n6. Given graph $G = (V, E)$ with positive edge weights, we know that Dijkstra’s algorithm can be implemented in $O((E + V) \\cdot log(V))$ time using a binary heap. Suppose you have been told that the input graph $G$ is a dense graph in which $E = O(V^2)$. Find a way to implement Dijkstra’s algorithm in $O(V^2)$ time.\n\t> - **Solution**\n\t> - **O(n)**\n7. Given a graph, $G = (V, E)$, whose edge weights are integers in the range $[0, W]$, where $W$ is a relatively small integer number, we could run Dijkstra’s algorithm to find the shortest distances from the start vertex to all other vertices. Design a new algorithm that will run in linear time $O(V + E)$ and therefore outperform Dijkstra’s algorithm.\n\t> - **Solution**\n\t> <img src=\"e7.png\"  style=\"display:inline;box-shadow: none !important;\">\n8. Given a directed acyclic graph, $G = (V, E)$, with nonnegative edge weights and the source $s$, devise a linear time algorithm to find the shortest distances from $s$ to all other vertices.\n\t> - **Solution**\n\t> - **O(n)**\n9. You are given a graph, $G = (V, E)$, with nonnegative edge weights and the shortest path distances $d(s, u)$ from a source vertex $s$ to all other vertices in $G$. However, you are not given the shortest path tree. Devise a linear time algorithm to find a shortest path from $s$ to a given vertex $t$.\n\t> - **Solution**\n\t>> Reverse edges in the original graph. This could be done in linear time (for example, using matrix transform). For all vertices that are connected to a given vertex $t$, find ones such that $d(s, t) = d(s, u) + d(u, t)$. Next, set $u$ as $t$ and repeat this to find new $u$ until $s$ equals to $u$. Nodes saved in the sequence are the shortest path from $s$ to a given vertex $t$.\n\n10. Given a graph, $G = (V, E)$, with nonnegative edge weights and two vertices s and t, the goal is to find the shortest path from $s$ to $t$ with an odd number of edges. Devise an algorithm that has the same runtime complexity as Dijkstra’s algorithm.\n\t> - **Solution**\n\t> - **O(n)**\n11. Given a graph,$G = (V, E)$, with nonnegative edge weights and the shortest path distances $d(u, v)$ between any pair of vertices in $G$, suppose we add a new edge (without introducing any new vertices) to $G$, creating a new graph $G_1$. Devise an efficient algorithm (that outperforms Dijkstra’s algorithm in the worst case) to update the shortest path distances $d(u, v)$.\n\t> - **Solution**\n\t> - **O(n)**\n12. Given $n$ rods of lengths $L_1, L_2, …, L_n$, respectively, the goal is to connect all the rods to form a single rod. The length and the cost of connecting two rods are equal to the sum of their lengths. Devise an algorithm to minimize the cost of forming a single rod. \n\t> - **Solution**\n\t> - **O(n)**\n\n13. Given a sorted array of frequencies of size $n$, devise a linear time algorithm for building a Huffman tree.\n\t> - **Solution**\n\t> - **O(n)**","slug":"AIA-ch4-Q-A","published":1,"updated":"2021-02-19T04:15:10.029Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cklbvizoq0005xcttggaudmbo","content":"<h3 id=\"Gneral-Solution\"><a href=\"#Gneral-Solution\" class=\"headerlink\" title=\"Gneral Solution\"></a>Gneral Solution</h3><h4 id=\"Shortest-Path\"><a href=\"#Shortest-Path\" class=\"headerlink\" title=\"Shortest Path**\"></a>Shortest Path**</h4><blockquote>\n<p>Dijkstra <strong>(cannot has negative weight)</strong><br>BFS <strong>(require a graph doesn’t consider weight)</strong><br>Topological Sort <strong>(require directed graph)</strong></p>\n</blockquote>\n<h4 id=\"Minimum-Cost\"><a href=\"#Minimum-Cost\" class=\"headerlink\" title=\"Minimum Cost\"></a>Minimum Cost</h4><blockquote>\n<p>MST</p>\n</blockquote>\n<h3 id=\"Minimum-Spanning-Trees\"><a href=\"#Minimum-Spanning-Trees\" class=\"headerlink\" title=\"Minimum Spanning Trees\"></a>Minimum Spanning Trees</h3><h4 id=\"Kruskal’s-Algorithm\"><a href=\"#Kruskal’s-Algorithm\" class=\"headerlink\" title=\"Kruskal’s Algorithm\"></a>Kruskal’s Algorithm</h4><blockquote>\n<p><img src=\"Kruskal.png\"  style=\"display:inline;box-shadow: none !important;\"></p>\n</blockquote>\n<h4 id=\"Prim’s-Algorithm\"><a href=\"#Prim’s-Algorithm\" class=\"headerlink\" title=\"Prim’s Algorithm\"></a>Prim’s Algorithm</h4><blockquote>\n<p><strong>Complexity</strong></p>\n<blockquote>\n<p><img src=\"Prim.png\"  style=\"display:inline;box-shadow: none !important;\"></p>\n</blockquote>\n</blockquote>\n<h4 id=\"Feature\"><a href=\"#Feature\" class=\"headerlink\" title=\"Feature\"></a>Feature</h4><blockquote>\n<p>The smallest crossing edge must be in the MST.</p>\n</blockquote>\n<h4 id=\"Dijkstra’s-Algorithm\"><a href=\"#Dijkstra’s-Algorithm\" class=\"headerlink\" title=\"Dijkstra’s Algorithm\"></a>Dijkstra’s Algorithm</h4><blockquote>\n<p>does not work on graphs with negative weights.<br><img src=\"dij1.png\"  style=\"display:inline;box-shadow: none !important;\"></p>\n</blockquote>\n<h4 id=\"Huffman-Tree\"><a href=\"#Huffman-Tree\" class=\"headerlink\" title=\"Huffman Tree\"></a>Huffman Tree</h4><h3 id=\"Review-Q-amp-A\"><a href=\"#Review-Q-amp-A\" class=\"headerlink\" title=\"Review Q&amp;A\"></a>Review Q&amp;A</h3><ol>\n<li><p><strong>(T/F)</strong> In the interval scheduling problem, if all intervals are of equal size, a greedy algorithm based on earliest start time will always select the maximum number of compatible intervals.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>we need to sort by the finish time first and then find the compatible intervals.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> Any weighted undirected graph with distinct edge weights has exactly one minimum spanning tree.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>maybe differnt order.<br><img src=\"r2.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> Suppose we have a graph where each edge weight value appears at most twice. Then, there are at most two minimum spanning trees in this graph.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>maybe some points are unreachable.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> Kruskal’s algorithm can fail in the presence of negative cost edges.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>it should work.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> If a connected undirected graph <script type=\"math/tex\">G = (V, E)</script> has $n = |V|$ vertices and $n + 5$ edges, we can find the minimum spanning tree of <script type=\"math/tex\">G</script> in $O(n)$ runtime.</p>\n<blockquote>\n<ul>\n<li><strong>True</strong></li>\n<li>first, this graph has a circle at least.<br>the original time complexity of prim algorithm is $O((V + E) \\cdot log(V))$. but this complexity is for complete graph.<br><br>about this issue, the heap size = 6, so we can say the $log(V)$ is a constant. So we can find the MST in a linear time.<br><img src=\"r5.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> The first edge added by Kruskal’s algorithm can be the last edge added by Prim’s algorithm.</p>\n<blockquote>\n<ul>\n<li><strong>True</strong></li>\n<li>possible</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> Suppose graph <script type=\"math/tex\">G</script> has a unique minimum spanning tree and graph <script type=\"math/tex\">G_1</script> is obtained by increasing the weight of every edge in <script type=\"math/tex\">G</script> by 1. The MST of <script type=\"math/tex\">G_1</script> must be different from the MST of <script type=\"math/tex\">G</script>.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>could be the same if the new added edge has a same weight of others.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> Suppose graph <script type=\"math/tex\">G</script> has a unique minimum spanning tree and graph <script type=\"math/tex\">G_1</script> is obtained by squaring the weight of every edge in <script type=\"math/tex\">G</script>. The MST of <script type=\"math/tex\">G_1</script> may be different from the MST of <script type=\"math/tex\">G</script>.</p>\n<blockquote>\n<ul>\n<li><strong>True</strong></li>\n<li>square a negative num result in a positive integer.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> If path $P$ is the shortest path from $u$ to $v$ and $w$ is a node on the path, then the part of path $P$ from $u$ to $w$ is also the shortest path.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>maybe not</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> If all edges in a connected undirected graph have distinct positive weights, the shortest path between any two vertices is unique.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong><br><img src=\"r10.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> Suppose we have calculated the shortest paths from a source to all other vertices. If we modify the original graph <script type=\"math/tex\">G</script> such that weights of all edges are doubled, then the shortest path tree of <script type=\"math/tex\">G</script> is also the shortest path tree of the modified graph.</p>\n<blockquote>\n<ul>\n<li><strong>True</strong></li>\n<li>$x + y + z &lt; a + b$</li>\n<li>$2 \\cdot (x + y + z) &lt;2 \\cdot (a + b)$ for sure.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> Suppose we have calculated the shortest paths from a source to all other vertices. If we modify the original graph, <script type=\"math/tex\">G</script>, such that weights of all edges are increased by 2, then the shortest path tree of <script type=\"math/tex\">G</script> is also the shortest path tree of the modified graph.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>could be different.</li>\n<li>counter example.<br><img src=\"r12.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n</ol>\n<h3 id=\"Exercise-Q-amp-A\"><a href=\"#Exercise-Q-amp-A\" class=\"headerlink\" title=\"Exercise Q&amp;A\"></a>Exercise Q&amp;A</h3><ol>\n<li><p>At the Perfect Programming Company, the programmers are paired in order to ensure the highest quality of produced code. The productivity of each pair is the speed of the slowest programmer. Assuming an even number of programmers, devise an efficient algorithm for pairing them up so the total productivity of all programmers is maximized.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><blockquote>\n<p><strong>A simple greedy algorithm works for this problem.</strong> Sort the speeds of the programmers in decreasing order using an optimal sorting algorithm such as merge sort. Consecutive sorted programmers are then paired together starting with pairing the fastest programmer with the second fastest programmer. <br><br>Sorting takes $O(n \\cdot log(n))$ time while pairing the programmers takes $O(n)$ time giving a total running time of O(n lg n). <br><br>Correctness: Let $P$ be the set of programmers. The problem exhibits an optimal substructure. Assume the optimal pairing. Given any pair of programmers $(i, j)$ in the optimal pairing, the optimal sum of productivity is just the sum of the productivity of $(i, j)$ with the optimal sum of the productivity of the all pairs in $P − {i, j}$. <br><br> We now show that the greedy choice works by showing that there exists an optimal pairing such that the two fastest programmers are paired together. Assume an optimal pairing where fastest programmer $i$ is not paired with the second faster programmer $j$. Instead let $i$ be paired with $k$ and $j$ be paired with $l$. Let $p_i$ , $p_j$ , $p_k$ and $p_l$ be the programming speeds of $i$, $j$, $k$ and $l$ respectively. We now change the pairings by pairing $i$ with $j$ and $k$ with $l$. The change in the sum of productivities is <center>$$(p_j + min(p_k, p_l)) − (p_k + p_l) ≥ 0$$</center> since $p_j$ is at least as large as the larger of $p_k$ and $p_l$ . We now have an optimal pairing where the fastest programmer is paired with the second fastest programmer. Hence to find the optimal solution, we can keep pairing the two fastest remaining programmers together.</p>\n</blockquote>\n</li>\n</ul>\n</blockquote>\n</li>\n<li><p>A new startup, FastRoute, wants to route information along a path in a communication network, represented as a graph. Each vertex represents a router and each edge a wire between routers. The wires are weighted by the maximum bandwidth they can support. FastRoute comes to you and asks you to develop an algorithm to find the path with maximum bandwidth from any source $s_1, \\, s_2, \\, …, \\, s_k$ to any destination $t_1, \\, t_2, \\, …, \\, t_n$. Devise an algorithm that has the same runtime complexity as Dijkstra’s algorithm.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><blockquote>\n<p>Data structure change: we’ll use a max heap instead of a min heap used in Dijkstra Algorithm.<br><br>Initialization of the min heap. Initially all nodes will have a distance (bandwidth) of zero from $s$, except the starting point $s$ which will have a bandwidth of $\\infty$ to itself.<br><br>Change in relaxation step. Based on the definition of a path’s bandwidth, the bandwidth of a path from $s$ to $u$ through $u$’s neighbor $v$ will be $d(u) = min( d(v)$,  $weigth(v,u) )$, because the bandwidth of a path is equal to the bandwidth of its lowest bandwidth edge. Therefore, in the relaxation step, we will be replacing:<br><br>$d(u) = min (d(u), d(v) + weigth(v,u))$<br><br>with<br><br>$d(u) = max (d(u), min (d(v) , weigth(v,u))$<br></p>\n</blockquote>\n</li>\n</ul>\n</blockquote>\n</li>\n<li><p>You are given a set $S$ of $n$ points, labeled $1$ to $n$, on a line. You are also given a set of $k$ finite intervals $I_1, \\, …, \\, I_k$, where each interval $I_i$, is of the form $[s_i, e_i]$, $I \\leq s_i \\leq e_i$. Present an efficient algorithm to find the smallest subset $X \\subseteq S$ of points such that each interval contains at least one point from $X$. Prove that your solution is optimal.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><blockquote>\n<p>Sort the intervals in increasing order of $e_i$ . Select the first point as the right end-point of the first interval in this order. Remove all intervals which intersect with this point, and repeat. Proof of correctness is similar to the interval scheduling problem discussed in class. If the algorithm picks points $p_1 &lt; p_2 &lt; · · · &lt; p_k$, and optimum solution picks points $q_1 &lt; q_2 &lt; · · · , q_s$, then prove by induction that $p_i ≥ q_i$ , and so $k ≤ s$.</p>\n</blockquote>\n</li>\n</ul>\n</blockquote>\n</li>\n<li><p>You are given a minimum spanning tree $T$ in a graph $G = (V, E)$. Suppose we remove an edge from $G$, creating a new graph, $G_1$. Assuming that $G_1$ is still connected, devise a linear time algorithm to find an MST in $G_1$.<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\"></p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><blockquote>\n<p>Once we delete an edge from $T$, the tree becomes disconnected. We need to find the minimum weight edge that connects two componets, say $T_1$ and $T_2$. Pick any component say $T_2$ and find all edges going to $T_1$. Among them choose the one which has the smallest cost. Runtime: $O(E)$.</p>\n</blockquote>\n</li>\n</ul>\n</blockquote>\n</li>\n<li><p>You are given a minimum spanning tree $T$ in a graph $G = (V, E)$. Suppose we add a new edge (without introducing any new vertices) to $G$, creating a new graph, $G_1$. Assuming that $G_1$ is still connected, devise a linear time algorithm to find an MST in $G_1$.<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\"></p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><br><img src=\"e5.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Given graph $G = (V, E)$ with positive edge weights, we know that Dijkstra’s algorithm can be implemented in $O((E + V) \\cdot log(V))$ time using a binary heap. Suppose you have been told that the input graph $G$ is a dense graph in which $E = O(V^2)$. Find a way to implement Dijkstra’s algorithm in $O(V^2)$ time.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li><strong>O(n)</strong></li>\n</ul>\n</blockquote>\n</li>\n<li>Given a graph, $G = (V, E)$, whose edge weights are integers in the range $[0, W]$, where $W$ is a relatively small integer number, we could run Dijkstra’s algorithm to find the shortest distances from the start vertex to all other vertices. Design a new algorithm that will run in linear time $O(V + E)$ and therefore outperform Dijkstra’s algorithm.<blockquote>\n<ul>\n<li><strong>Solution</strong><br><img src=\"e7.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li>Given a directed acyclic graph, $G = (V, E)$, with nonnegative edge weights and the source $s$, devise a linear time algorithm to find the shortest distances from $s$ to all other vertices.<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li><strong>O(n)</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>You are given a graph, $G = (V, E)$, with nonnegative edge weights and the shortest path distances $d(s, u)$ from a source vertex $s$ to all other vertices in $G$. However, you are not given the shortest path tree. Devise a linear time algorithm to find a shortest path from $s$ to a given vertex $t$.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><blockquote>\n<p>Reverse edges in the original graph. This could be done in linear time (for example, using matrix transform). For all vertices that are connected to a given vertex $t$, find ones such that $d(s, t) = d(s, u) + d(u, t)$. Next, set $u$ as $t$ and repeat this to find new $u$ until $s$ equals to $u$. Nodes saved in the sequence are the shortest path from $s$ to a given vertex $t$.</p>\n</blockquote>\n</li>\n</ul>\n</blockquote>\n</li>\n<li><p>Given a graph, $G = (V, E)$, with nonnegative edge weights and two vertices s and t, the goal is to find the shortest path from $s$ to $t$ with an odd number of edges. Devise an algorithm that has the same runtime complexity as Dijkstra’s algorithm.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li><strong>O(n)</strong></li>\n</ul>\n</blockquote>\n</li>\n<li>Given a graph,$G = (V, E)$, with nonnegative edge weights and the shortest path distances $d(u, v)$ between any pair of vertices in $G$, suppose we add a new edge (without introducing any new vertices) to $G$, creating a new graph $G_1$. Devise an efficient algorithm (that outperforms Dijkstra’s algorithm in the worst case) to update the shortest path distances $d(u, v)$.<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li><strong>O(n)</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Given $n$ rods of lengths $L_1, L_2, …, L_n$, respectively, the goal is to connect all the rods to form a single rod. The length and the cost of connecting two rods are equal to the sum of their lengths. Devise an algorithm to minimize the cost of forming a single rod. </p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li><strong>O(n)</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Given a sorted array of frequencies of size $n$, devise a linear time algorithm for building a Huffman tree.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li><strong>O(n)</strong></li>\n</ul>\n</blockquote>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Gneral-Solution\"><a href=\"#Gneral-Solution\" class=\"headerlink\" title=\"Gneral Solution\"></a>Gneral Solution</h3><h4 id=\"Shortest-Path\"><a href=\"#Shortest-Path\" class=\"headerlink\" title=\"Shortest Path**\"></a>Shortest Path**</h4><blockquote>\n<p>Dijkstra <strong>(cannot has negative weight)</strong><br>BFS <strong>(require a graph doesn’t consider weight)</strong><br>Topological Sort <strong>(require directed graph)</strong></p>\n</blockquote>\n<h4 id=\"Minimum-Cost\"><a href=\"#Minimum-Cost\" class=\"headerlink\" title=\"Minimum Cost\"></a>Minimum Cost</h4><blockquote>\n<p>MST</p>\n</blockquote>\n<h3 id=\"Minimum-Spanning-Trees\"><a href=\"#Minimum-Spanning-Trees\" class=\"headerlink\" title=\"Minimum Spanning Trees\"></a>Minimum Spanning Trees</h3><h4 id=\"Kruskal’s-Algorithm\"><a href=\"#Kruskal’s-Algorithm\" class=\"headerlink\" title=\"Kruskal’s Algorithm\"></a>Kruskal’s Algorithm</h4><blockquote>\n<p><img src=\"Kruskal.png\"  style=\"display:inline;box-shadow: none !important;\"></p>\n</blockquote>\n<h4 id=\"Prim’s-Algorithm\"><a href=\"#Prim’s-Algorithm\" class=\"headerlink\" title=\"Prim’s Algorithm\"></a>Prim’s Algorithm</h4><blockquote>\n<p><strong>Complexity</strong></p>\n<blockquote>\n<p><img src=\"Prim.png\"  style=\"display:inline;box-shadow: none !important;\"></p>\n</blockquote>\n</blockquote>\n<h4 id=\"Feature\"><a href=\"#Feature\" class=\"headerlink\" title=\"Feature\"></a>Feature</h4><blockquote>\n<p>The smallest crossing edge must be in the MST.</p>\n</blockquote>\n<h4 id=\"Dijkstra’s-Algorithm\"><a href=\"#Dijkstra’s-Algorithm\" class=\"headerlink\" title=\"Dijkstra’s Algorithm\"></a>Dijkstra’s Algorithm</h4><blockquote>\n<p>does not work on graphs with negative weights.<br><img src=\"dij1.png\"  style=\"display:inline;box-shadow: none !important;\"></p>\n</blockquote>\n<h4 id=\"Huffman-Tree\"><a href=\"#Huffman-Tree\" class=\"headerlink\" title=\"Huffman Tree\"></a>Huffman Tree</h4><h3 id=\"Review-Q-amp-A\"><a href=\"#Review-Q-amp-A\" class=\"headerlink\" title=\"Review Q&amp;A\"></a>Review Q&amp;A</h3><ol>\n<li><p><strong>(T/F)</strong> In the interval scheduling problem, if all intervals are of equal size, a greedy algorithm based on earliest start time will always select the maximum number of compatible intervals.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>we need to sort by the finish time first and then find the compatible intervals.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> Any weighted undirected graph with distinct edge weights has exactly one minimum spanning tree.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>maybe differnt order.<br><img src=\"r2.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> Suppose we have a graph where each edge weight value appears at most twice. Then, there are at most two minimum spanning trees in this graph.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>maybe some points are unreachable.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> Kruskal’s algorithm can fail in the presence of negative cost edges.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>it should work.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> If a connected undirected graph <script type=\"math/tex\">G = (V, E)</script> has $n = |V|$ vertices and $n + 5$ edges, we can find the minimum spanning tree of <script type=\"math/tex\">G</script> in $O(n)$ runtime.</p>\n<blockquote>\n<ul>\n<li><strong>True</strong></li>\n<li>first, this graph has a circle at least.<br>the original time complexity of prim algorithm is $O((V + E) \\cdot log(V))$. but this complexity is for complete graph.<br><br>about this issue, the heap size = 6, so we can say the $log(V)$ is a constant. So we can find the MST in a linear time.<br><img src=\"r5.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> The first edge added by Kruskal’s algorithm can be the last edge added by Prim’s algorithm.</p>\n<blockquote>\n<ul>\n<li><strong>True</strong></li>\n<li>possible</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> Suppose graph <script type=\"math/tex\">G</script> has a unique minimum spanning tree and graph <script type=\"math/tex\">G_1</script> is obtained by increasing the weight of every edge in <script type=\"math/tex\">G</script> by 1. The MST of <script type=\"math/tex\">G_1</script> must be different from the MST of <script type=\"math/tex\">G</script>.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>could be the same if the new added edge has a same weight of others.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> Suppose graph <script type=\"math/tex\">G</script> has a unique minimum spanning tree and graph <script type=\"math/tex\">G_1</script> is obtained by squaring the weight of every edge in <script type=\"math/tex\">G</script>. The MST of <script type=\"math/tex\">G_1</script> may be different from the MST of <script type=\"math/tex\">G</script>.</p>\n<blockquote>\n<ul>\n<li><strong>True</strong></li>\n<li>square a negative num result in a positive integer.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> If path $P$ is the shortest path from $u$ to $v$ and $w$ is a node on the path, then the part of path $P$ from $u$ to $w$ is also the shortest path.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>maybe not</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> If all edges in a connected undirected graph have distinct positive weights, the shortest path between any two vertices is unique.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong><br><img src=\"r10.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> Suppose we have calculated the shortest paths from a source to all other vertices. If we modify the original graph <script type=\"math/tex\">G</script> such that weights of all edges are doubled, then the shortest path tree of <script type=\"math/tex\">G</script> is also the shortest path tree of the modified graph.</p>\n<blockquote>\n<ul>\n<li><strong>True</strong></li>\n<li>$x + y + z &lt; a + b$</li>\n<li>$2 \\cdot (x + y + z) &lt;2 \\cdot (a + b)$ for sure.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> Suppose we have calculated the shortest paths from a source to all other vertices. If we modify the original graph, <script type=\"math/tex\">G</script>, such that weights of all edges are increased by 2, then the shortest path tree of <script type=\"math/tex\">G</script> is also the shortest path tree of the modified graph.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>could be different.</li>\n<li>counter example.<br><img src=\"r12.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n</ol>\n<h3 id=\"Exercise-Q-amp-A\"><a href=\"#Exercise-Q-amp-A\" class=\"headerlink\" title=\"Exercise Q&amp;A\"></a>Exercise Q&amp;A</h3><ol>\n<li><p>At the Perfect Programming Company, the programmers are paired in order to ensure the highest quality of produced code. The productivity of each pair is the speed of the slowest programmer. Assuming an even number of programmers, devise an efficient algorithm for pairing them up so the total productivity of all programmers is maximized.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><blockquote>\n<p><strong>A simple greedy algorithm works for this problem.</strong> Sort the speeds of the programmers in decreasing order using an optimal sorting algorithm such as merge sort. Consecutive sorted programmers are then paired together starting with pairing the fastest programmer with the second fastest programmer. <br><br>Sorting takes $O(n \\cdot log(n))$ time while pairing the programmers takes $O(n)$ time giving a total running time of O(n lg n). <br><br>Correctness: Let $P$ be the set of programmers. The problem exhibits an optimal substructure. Assume the optimal pairing. Given any pair of programmers $(i, j)$ in the optimal pairing, the optimal sum of productivity is just the sum of the productivity of $(i, j)$ with the optimal sum of the productivity of the all pairs in $P − {i, j}$. <br><br> We now show that the greedy choice works by showing that there exists an optimal pairing such that the two fastest programmers are paired together. Assume an optimal pairing where fastest programmer $i$ is not paired with the second faster programmer $j$. Instead let $i$ be paired with $k$ and $j$ be paired with $l$. Let $p_i$ , $p_j$ , $p_k$ and $p_l$ be the programming speeds of $i$, $j$, $k$ and $l$ respectively. We now change the pairings by pairing $i$ with $j$ and $k$ with $l$. The change in the sum of productivities is <center>$$(p_j + min(p_k, p_l)) − (p_k + p_l) ≥ 0$$</center> since $p_j$ is at least as large as the larger of $p_k$ and $p_l$ . We now have an optimal pairing where the fastest programmer is paired with the second fastest programmer. Hence to find the optimal solution, we can keep pairing the two fastest remaining programmers together.</p>\n</blockquote>\n</li>\n</ul>\n</blockquote>\n</li>\n<li><p>A new startup, FastRoute, wants to route information along a path in a communication network, represented as a graph. Each vertex represents a router and each edge a wire between routers. The wires are weighted by the maximum bandwidth they can support. FastRoute comes to you and asks you to develop an algorithm to find the path with maximum bandwidth from any source $s_1, \\, s_2, \\, …, \\, s_k$ to any destination $t_1, \\, t_2, \\, …, \\, t_n$. Devise an algorithm that has the same runtime complexity as Dijkstra’s algorithm.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><blockquote>\n<p>Data structure change: we’ll use a max heap instead of a min heap used in Dijkstra Algorithm.<br><br>Initialization of the min heap. Initially all nodes will have a distance (bandwidth) of zero from $s$, except the starting point $s$ which will have a bandwidth of $\\infty$ to itself.<br><br>Change in relaxation step. Based on the definition of a path’s bandwidth, the bandwidth of a path from $s$ to $u$ through $u$’s neighbor $v$ will be $d(u) = min( d(v)$,  $weigth(v,u) )$, because the bandwidth of a path is equal to the bandwidth of its lowest bandwidth edge. Therefore, in the relaxation step, we will be replacing:<br><br>$d(u) = min (d(u), d(v) + weigth(v,u))$<br><br>with<br><br>$d(u) = max (d(u), min (d(v) , weigth(v,u))$<br></p>\n</blockquote>\n</li>\n</ul>\n</blockquote>\n</li>\n<li><p>You are given a set $S$ of $n$ points, labeled $1$ to $n$, on a line. You are also given a set of $k$ finite intervals $I_1, \\, …, \\, I_k$, where each interval $I_i$, is of the form $[s_i, e_i]$, $I \\leq s_i \\leq e_i$. Present an efficient algorithm to find the smallest subset $X \\subseteq S$ of points such that each interval contains at least one point from $X$. Prove that your solution is optimal.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><blockquote>\n<p>Sort the intervals in increasing order of $e_i$ . Select the first point as the right end-point of the first interval in this order. Remove all intervals which intersect with this point, and repeat. Proof of correctness is similar to the interval scheduling problem discussed in class. If the algorithm picks points $p_1 &lt; p_2 &lt; · · · &lt; p_k$, and optimum solution picks points $q_1 &lt; q_2 &lt; · · · , q_s$, then prove by induction that $p_i ≥ q_i$ , and so $k ≤ s$.</p>\n</blockquote>\n</li>\n</ul>\n</blockquote>\n</li>\n<li><p>You are given a minimum spanning tree $T$ in a graph $G = (V, E)$. Suppose we remove an edge from $G$, creating a new graph, $G_1$. Assuming that $G_1$ is still connected, devise a linear time algorithm to find an MST in $G_1$.<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\"></p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><blockquote>\n<p>Once we delete an edge from $T$, the tree becomes disconnected. We need to find the minimum weight edge that connects two componets, say $T_1$ and $T_2$. Pick any component say $T_2$ and find all edges going to $T_1$. Among them choose the one which has the smallest cost. Runtime: $O(E)$.</p>\n</blockquote>\n</li>\n</ul>\n</blockquote>\n</li>\n<li><p>You are given a minimum spanning tree $T$ in a graph $G = (V, E)$. Suppose we add a new edge (without introducing any new vertices) to $G$, creating a new graph, $G_1$. Assuming that $G_1$ is still connected, devise a linear time algorithm to find an MST in $G_1$.<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\"></p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><br><img src=\"e5.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Given graph $G = (V, E)$ with positive edge weights, we know that Dijkstra’s algorithm can be implemented in $O((E + V) \\cdot log(V))$ time using a binary heap. Suppose you have been told that the input graph $G$ is a dense graph in which $E = O(V^2)$. Find a way to implement Dijkstra’s algorithm in $O(V^2)$ time.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li><strong>O(n)</strong></li>\n</ul>\n</blockquote>\n</li>\n<li>Given a graph, $G = (V, E)$, whose edge weights are integers in the range $[0, W]$, where $W$ is a relatively small integer number, we could run Dijkstra’s algorithm to find the shortest distances from the start vertex to all other vertices. Design a new algorithm that will run in linear time $O(V + E)$ and therefore outperform Dijkstra’s algorithm.<blockquote>\n<ul>\n<li><strong>Solution</strong><br><img src=\"e7.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li>Given a directed acyclic graph, $G = (V, E)$, with nonnegative edge weights and the source $s$, devise a linear time algorithm to find the shortest distances from $s$ to all other vertices.<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li><strong>O(n)</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>You are given a graph, $G = (V, E)$, with nonnegative edge weights and the shortest path distances $d(s, u)$ from a source vertex $s$ to all other vertices in $G$. However, you are not given the shortest path tree. Devise a linear time algorithm to find a shortest path from $s$ to a given vertex $t$.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><blockquote>\n<p>Reverse edges in the original graph. This could be done in linear time (for example, using matrix transform). For all vertices that are connected to a given vertex $t$, find ones such that $d(s, t) = d(s, u) + d(u, t)$. Next, set $u$ as $t$ and repeat this to find new $u$ until $s$ equals to $u$. Nodes saved in the sequence are the shortest path from $s$ to a given vertex $t$.</p>\n</blockquote>\n</li>\n</ul>\n</blockquote>\n</li>\n<li><p>Given a graph, $G = (V, E)$, with nonnegative edge weights and two vertices s and t, the goal is to find the shortest path from $s$ to $t$ with an odd number of edges. Devise an algorithm that has the same runtime complexity as Dijkstra’s algorithm.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li><strong>O(n)</strong></li>\n</ul>\n</blockquote>\n</li>\n<li>Given a graph,$G = (V, E)$, with nonnegative edge weights and the shortest path distances $d(u, v)$ between any pair of vertices in $G$, suppose we add a new edge (without introducing any new vertices) to $G$, creating a new graph $G_1$. Devise an efficient algorithm (that outperforms Dijkstra’s algorithm in the worst case) to update the shortest path distances $d(u, v)$.<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li><strong>O(n)</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Given $n$ rods of lengths $L_1, L_2, …, L_n$, respectively, the goal is to connect all the rods to form a single rod. The length and the cost of connecting two rods are equal to the sum of their lengths. Devise an algorithm to minimize the cost of forming a single rod. </p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li><strong>O(n)</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Given a sorted array of frequencies of size $n$, devise a linear time algorithm for building a Huffman tree.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li><strong>O(n)</strong></li>\n</ul>\n</blockquote>\n</li>\n</ol>\n"},{"title":"$$[Algorithms \\, In \\, Action]-CH3\\, Heap$$","catalog":true,"mathjax":true,"date":"2021-02-07T07:08:15.000Z","subtitle":null,"header-img":"cruves.png","_content":"\n### Heap\n- Three types of heap\n\t> **Binary Heap**\n\t\t>> asdasda\n\n\t> **Binomial Heap**\n\t\t>> **Definition**: <br>A binomial heap is a collection (a linked list) of at most Celling(log(n)) binomial trees (<u>**of unique rank**</u>) in increasing order of size where each tree has a heap ordering property.<br>\n\t\t>> **Binomial Trees**\n\t\t>>> The binomial tree $$B_k$$ is defined as \n\t\t>>> 1. $$B_0$$ is a single node\n\t\t>>> 2. $$B_k$$ is formed by joining two $$B_{k - 1}$$ trees\n\t\t>>> <img src=\"BT.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n\t> **Fibonacci Heap**\n\t\t>> <u>general idea</u> is to have a more relaxed structure (compared to binomial heaps) that will improve *decreaseKey* complexity to constant amortized time\n\n\n\n\n### Review Q&A\n1. What is the worst-case runtime complexity of finding the smallest item in a binary min-heap?<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\">\n\t> - **Solution**\n\t> - **O(1)**\n\n2. What is the worst-case runtime complexity of finding the largest item in a binary min-heap?\n\t> - **Solution**\n\t> - **O(n)**\n\n3. How many binomial trees does a binomial heap with 31 elements contain?\n\t> - **Solution**\n\t> - \"Having this in mind, we always will assume in the worst-case analysis that there are $O(log(n))$ binomial trees in a binomial heap with n nodes.\" --Chpater 3 [3.2.0]\n\t> $O(log(31)) = 6$\n\n4. How many binomial trees are in a binomial heap of size n?\n\t> - **Solution**\n\t> - $O(log(n))$\n\n5. What is the worst-case runtime complexity of inserting into a binomial heap?\n\t> - **Solution** => $O(1)$\n\t> <img src=\"heap_table.png\"  style=\"display:inline;box-shadow: none !important;\">\n6. What is the worst-case runtime complexity of searching in a binomial heap?\n\t> - **Solution** => $O(n)$\n\n7. What is the amortized cost of inserting into a binomial heap?\n\t> - **Solution** => $O(1)$\n\n8. What is the worst-case runtime complexity of deleteMin() from a binomial heap?\n\t> - **Solution** => $O(log(n))$\n\n9. **(T/F)** The following array is a max heap: [10, 3, 5, 1, 4, 2].\n\t> - **False**\n\t\n10. **(T/F)** In a binary max-heap with **n** elements, the worst-case runtime complexity of finding the second largest element is $O(1)$.\n\t> - **True**\n\n11. **(T/F)** If item A is an ancestor of item B in a heap then it must be the case that the insert(A) operation occurred before insert(B).\n\t> - **False**\n\t> - It could be any order, but the final result will be the same.\n\n12. **(T/F)** Using a binary heap we can sort any array of size n in $O(n)$ time.\n\t> - **False**\n\t> - dont know\n\n13. **(T/F)** In a binomial min-heap with **n** elements, the worst-case runtime complexity of finding the smallest element is $O(1)$.\n\t> - **True**\n\t> - this is min-heap, the smallest element will be placed in the top.\n\n14. **(T/F)** In a binomial min-heap with **n** elements, the worst-case runtime complexity of finding the second smallest element is $O(1)$.\n\t> - **True**\n\t> - same reason I think.\n\n15. **(T/F)** By using a binomial heap we can sort data of size n in $O(n)$ time.\n\t> - **False**\n\t> - could sort **n** elements in $O(nlog(n))$ time.\n\n16. **(T/F)** Given a Fibonacci heap of size **n**, the maximum number of trees is that heap is **n**.\n\t> - **False**\n\t> - dont know\n\n### Exercise Q&A\n1. Given a sequence of numbers, 3, 5, 2, 8, 1, 5, 2,\n\t- a. draw a binary min-heap (in an array form) by inserting these numbers, reading them from left to right; and\n\t- b. show an array that would be the result after the call to deleteMi() on this heap\n\n  > - **Solution**\n\t> <img src=\"heap.gif\"  style=\"display:inline;box-shadow: none !important;\">\n\t\n2. Devise an algorithm of merging two binary heaps. What is its runtime complexity?\n\t> - **Solution**\n\t> <img src=\"e2.png\"  style=\"display:inline;box-shadow: none !important;\">\n3. Suppose you have two binary min-heaps, A and B, with a total of **n** elements between them. You want to discover if A and B have a key in common. Devise an algorithm to this problem that takes $O(n \\cdot log(n))$ time.\n\t> - **Solution**\n\t> - abcd\n4. The values 1, 2, 3, …, 63 are all inserted (in any order) into an initially empty minheap. What is the smallest number that could be a leaf node?\n\t> - **Solution**\n\t> <img src=\"e4.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n5. Prove that it is impossible construct a min-heap (not necessarily binary) in a comparison-based model with both the following properties:\n\t- a. deleteMin() runs in $O(1)$\n\t- b. buildHeap() runs in $O(n)$, where n is the input size.\n\n  > - **Solution**\n  > - abcd\n\n6. Given an unsorted array of size **n**, devise a heap-based algorithm that finds the k-th largest element in the array. What is its runtime complexity?\n\t> - **Solution**\n\t> - abcd\n7. Recall that two sorted arrays of size n can be merged into a single sorted list in linear time O(n). Suppose there are k > 2 sorted arrays, each of size n. Devise a heap-based algorithm that merges k arrays and requires at most O(k) extra space.\n\t> - **Solution**\n\t> - abcd\n8. Given a stream of data (its size is unknown in advance), devise a heap-based algorithm that finds the k-th largest element in the array. Your algorithm must take at most $O(k)$ extra space. What is its runtime complexity?\n\t> - **Solution**\n\t> <img src=\"e8.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n9. Given a stream of data (its size is unknown in advance), devise a heap-based algorithm that finds the median of elements read so far. What is its runtime complexity?\n\t> - **Solution**\n\t> - use *Exercise 8*'s Online Algorithm\n\t\n10. Given a sequence of numbers, 3, 5, 2, 8, 1, 5, 2, 7,\n\t- a. draw a binomial heap by inserting these numbers, reading them from left to right; and\n\t- b. show a heap that would be the result after the call to deleteMin() on this heap.\n\n\t> - **Solution**\n\t> - abcd\n\n11. Discuss the relationship between inserting into a binomial heap and binary increment.\n\t> - **Solution**\n\t> - abcd\n12. Discuss the relationship between merging two binomial heaps and adding two binary numbers.\n\t> - **Solution**\n\t> - abcd\n13. Discuss the relationship between inserting into a binomial heap and a Fibonacci heap.\n\t> - **Solution**\n\t> - abcd\n14. Devise an algorithm of deleting any item from a binomial heap. What is its runtime complexity?\n\t> - **Solution**\n\t> - abcd\n15. Devise an algorithm to find all nodes less than some given value X in a binomial heap. Analyze its complexity.\n\t> - **Solution**\n\t> - abcd","source":"_posts/AIA-ch3-Q-A.md","raw":"---\ntitle: $$[Algorithms \\, In \\, Action]-CH3\\, Heap$$\ncatalog: true\nmathjax: true\ndate: 2021-02-06 23:08:15\nsubtitle:\nheader-img: cruves.png\ntags:\n- Review\n- Heap\n- Q&A\ncategories:\n- CSCI 570\n---\n\n### Heap\n- Three types of heap\n\t> **Binary Heap**\n\t\t>> asdasda\n\n\t> **Binomial Heap**\n\t\t>> **Definition**: <br>A binomial heap is a collection (a linked list) of at most Celling(log(n)) binomial trees (<u>**of unique rank**</u>) in increasing order of size where each tree has a heap ordering property.<br>\n\t\t>> **Binomial Trees**\n\t\t>>> The binomial tree $$B_k$$ is defined as \n\t\t>>> 1. $$B_0$$ is a single node\n\t\t>>> 2. $$B_k$$ is formed by joining two $$B_{k - 1}$$ trees\n\t\t>>> <img src=\"BT.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n\t> **Fibonacci Heap**\n\t\t>> <u>general idea</u> is to have a more relaxed structure (compared to binomial heaps) that will improve *decreaseKey* complexity to constant amortized time\n\n\n\n\n### Review Q&A\n1. What is the worst-case runtime complexity of finding the smallest item in a binary min-heap?<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\">\n\t> - **Solution**\n\t> - **O(1)**\n\n2. What is the worst-case runtime complexity of finding the largest item in a binary min-heap?\n\t> - **Solution**\n\t> - **O(n)**\n\n3. How many binomial trees does a binomial heap with 31 elements contain?\n\t> - **Solution**\n\t> - \"Having this in mind, we always will assume in the worst-case analysis that there are $O(log(n))$ binomial trees in a binomial heap with n nodes.\" --Chpater 3 [3.2.0]\n\t> $O(log(31)) = 6$\n\n4. How many binomial trees are in a binomial heap of size n?\n\t> - **Solution**\n\t> - $O(log(n))$\n\n5. What is the worst-case runtime complexity of inserting into a binomial heap?\n\t> - **Solution** => $O(1)$\n\t> <img src=\"heap_table.png\"  style=\"display:inline;box-shadow: none !important;\">\n6. What is the worst-case runtime complexity of searching in a binomial heap?\n\t> - **Solution** => $O(n)$\n\n7. What is the amortized cost of inserting into a binomial heap?\n\t> - **Solution** => $O(1)$\n\n8. What is the worst-case runtime complexity of deleteMin() from a binomial heap?\n\t> - **Solution** => $O(log(n))$\n\n9. **(T/F)** The following array is a max heap: [10, 3, 5, 1, 4, 2].\n\t> - **False**\n\t\n10. **(T/F)** In a binary max-heap with **n** elements, the worst-case runtime complexity of finding the second largest element is $O(1)$.\n\t> - **True**\n\n11. **(T/F)** If item A is an ancestor of item B in a heap then it must be the case that the insert(A) operation occurred before insert(B).\n\t> - **False**\n\t> - It could be any order, but the final result will be the same.\n\n12. **(T/F)** Using a binary heap we can sort any array of size n in $O(n)$ time.\n\t> - **False**\n\t> - dont know\n\n13. **(T/F)** In a binomial min-heap with **n** elements, the worst-case runtime complexity of finding the smallest element is $O(1)$.\n\t> - **True**\n\t> - this is min-heap, the smallest element will be placed in the top.\n\n14. **(T/F)** In a binomial min-heap with **n** elements, the worst-case runtime complexity of finding the second smallest element is $O(1)$.\n\t> - **True**\n\t> - same reason I think.\n\n15. **(T/F)** By using a binomial heap we can sort data of size n in $O(n)$ time.\n\t> - **False**\n\t> - could sort **n** elements in $O(nlog(n))$ time.\n\n16. **(T/F)** Given a Fibonacci heap of size **n**, the maximum number of trees is that heap is **n**.\n\t> - **False**\n\t> - dont know\n\n### Exercise Q&A\n1. Given a sequence of numbers, 3, 5, 2, 8, 1, 5, 2,\n\t- a. draw a binary min-heap (in an array form) by inserting these numbers, reading them from left to right; and\n\t- b. show an array that would be the result after the call to deleteMi() on this heap\n\n  > - **Solution**\n\t> <img src=\"heap.gif\"  style=\"display:inline;box-shadow: none !important;\">\n\t\n2. Devise an algorithm of merging two binary heaps. What is its runtime complexity?\n\t> - **Solution**\n\t> <img src=\"e2.png\"  style=\"display:inline;box-shadow: none !important;\">\n3. Suppose you have two binary min-heaps, A and B, with a total of **n** elements between them. You want to discover if A and B have a key in common. Devise an algorithm to this problem that takes $O(n \\cdot log(n))$ time.\n\t> - **Solution**\n\t> - abcd\n4. The values 1, 2, 3, …, 63 are all inserted (in any order) into an initially empty minheap. What is the smallest number that could be a leaf node?\n\t> - **Solution**\n\t> <img src=\"e4.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n5. Prove that it is impossible construct a min-heap (not necessarily binary) in a comparison-based model with both the following properties:\n\t- a. deleteMin() runs in $O(1)$\n\t- b. buildHeap() runs in $O(n)$, where n is the input size.\n\n  > - **Solution**\n  > - abcd\n\n6. Given an unsorted array of size **n**, devise a heap-based algorithm that finds the k-th largest element in the array. What is its runtime complexity?\n\t> - **Solution**\n\t> - abcd\n7. Recall that two sorted arrays of size n can be merged into a single sorted list in linear time O(n). Suppose there are k > 2 sorted arrays, each of size n. Devise a heap-based algorithm that merges k arrays and requires at most O(k) extra space.\n\t> - **Solution**\n\t> - abcd\n8. Given a stream of data (its size is unknown in advance), devise a heap-based algorithm that finds the k-th largest element in the array. Your algorithm must take at most $O(k)$ extra space. What is its runtime complexity?\n\t> - **Solution**\n\t> <img src=\"e8.png\"  style=\"display:inline;box-shadow: none !important;\">\n\n9. Given a stream of data (its size is unknown in advance), devise a heap-based algorithm that finds the median of elements read so far. What is its runtime complexity?\n\t> - **Solution**\n\t> - use *Exercise 8*'s Online Algorithm\n\t\n10. Given a sequence of numbers, 3, 5, 2, 8, 1, 5, 2, 7,\n\t- a. draw a binomial heap by inserting these numbers, reading them from left to right; and\n\t- b. show a heap that would be the result after the call to deleteMin() on this heap.\n\n\t> - **Solution**\n\t> - abcd\n\n11. Discuss the relationship between inserting into a binomial heap and binary increment.\n\t> - **Solution**\n\t> - abcd\n12. Discuss the relationship between merging two binomial heaps and adding two binary numbers.\n\t> - **Solution**\n\t> - abcd\n13. Discuss the relationship between inserting into a binomial heap and a Fibonacci heap.\n\t> - **Solution**\n\t> - abcd\n14. Devise an algorithm of deleting any item from a binomial heap. What is its runtime complexity?\n\t> - **Solution**\n\t> - abcd\n15. Devise an algorithm to find all nodes less than some given value X in a binomial heap. Analyze its complexity.\n\t> - **Solution**\n\t> - abcd","slug":"AIA-ch3-Q-A","published":1,"updated":"2021-02-16T06:04:42.896Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cklbvizpa000sxctt62op7v23","content":"<h3 id=\"Heap\"><a href=\"#Heap\" class=\"headerlink\" title=\"Heap\"></a>Heap</h3><ul>\n<li><p>Three types of heap</p>\n<blockquote>\n<p><strong>Binary Heap</strong></p>\n<blockquote>\n<p>asdasda</p>\n</blockquote>\n<p><strong>Binomial Heap</strong></p>\n<blockquote>\n<p><strong>Definition</strong>: <br>A binomial heap is a collection (a linked list) of at most Celling(log(n)) binomial trees (<u><strong>of unique rank</strong></u>) in increasing order of size where each tree has a heap ordering property.<br><br><strong>Binomial Trees</strong></p>\n<blockquote>\n<p>The binomial tree <script type=\"math/tex\">B_k</script> is defined as </p>\n<ol>\n<li><script type=\"math/tex\">B_0</script> is a single node</li>\n<li><script type=\"math/tex\">B_k</script> is formed by joining two <script type=\"math/tex\">B_{k - 1}</script> trees<br><img src=\"BT.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ol>\n</blockquote>\n</blockquote>\n<p><strong>Fibonacci Heap</strong></p>\n<blockquote>\n<p><u>general idea</u> is to have a more relaxed structure (compared to binomial heaps) that will improve <em>decreaseKey</em> complexity to constant amortized time</p>\n</blockquote>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"Review-Q-amp-A\"><a href=\"#Review-Q-amp-A\" class=\"headerlink\" title=\"Review Q&amp;A\"></a>Review Q&amp;A</h3><ol>\n<li><p>What is the worst-case runtime complexity of finding the smallest item in a binary min-heap?<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\"></p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li><strong>O(1)</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>What is the worst-case runtime complexity of finding the largest item in a binary min-heap?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li><strong>O(n)</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>How many binomial trees does a binomial heap with 31 elements contain?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>“Having this in mind, we always will assume in the worst-case analysis that there are $O(log(n))$ binomial trees in a binomial heap with n nodes.” —Chpater 3 [3.2.0]<br>$O(log(31)) = 6$</li>\n</ul>\n</blockquote>\n</li>\n<li><p>How many binomial trees are in a binomial heap of size n?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>$O(log(n))$</li>\n</ul>\n</blockquote>\n</li>\n<li><p>What is the worst-case runtime complexity of inserting into a binomial heap?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong> =&gt; $O(1)$<br><img src=\"heap_table.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p>What is the worst-case runtime complexity of searching in a binomial heap?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong> =&gt; $O(n)$</li>\n</ul>\n</blockquote>\n</li>\n<li><p>What is the amortized cost of inserting into a binomial heap?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong> =&gt; $O(1)$</li>\n</ul>\n</blockquote>\n</li>\n<li><p>What is the worst-case runtime complexity of deleteMin() from a binomial heap?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong> =&gt; $O(log(n))$</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> The following array is a max heap: [10, 3, 5, 1, 4, 2].</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> In a binary max-heap with <strong>n</strong> elements, the worst-case runtime complexity of finding the second largest element is $O(1)$.</p>\n<blockquote>\n<ul>\n<li><strong>True</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> If item A is an ancestor of item B in a heap then it must be the case that the insert(A) operation occurred before insert(B).</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>It could be any order, but the final result will be the same.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> Using a binary heap we can sort any array of size n in $O(n)$ time.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>dont know</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> In a binomial min-heap with <strong>n</strong> elements, the worst-case runtime complexity of finding the smallest element is $O(1)$.</p>\n<blockquote>\n<ul>\n<li><strong>True</strong></li>\n<li>this is min-heap, the smallest element will be placed in the top.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> In a binomial min-heap with <strong>n</strong> elements, the worst-case runtime complexity of finding the second smallest element is $O(1)$.</p>\n<blockquote>\n<ul>\n<li><strong>True</strong></li>\n<li>same reason I think.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> By using a binomial heap we can sort data of size n in $O(n)$ time.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>could sort <strong>n</strong> elements in $O(nlog(n))$ time.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> Given a Fibonacci heap of size <strong>n</strong>, the maximum number of trees is that heap is <strong>n</strong>.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>dont know</li>\n</ul>\n</blockquote>\n</li>\n</ol>\n<h3 id=\"Exercise-Q-amp-A\"><a href=\"#Exercise-Q-amp-A\" class=\"headerlink\" title=\"Exercise Q&amp;A\"></a>Exercise Q&amp;A</h3><ol>\n<li><p>Given a sequence of numbers, 3, 5, 2, 8, 1, 5, 2,</p>\n<ul>\n<li>a. draw a binary min-heap (in an array form) by inserting these numbers, reading them from left to right; and</li>\n<li>b. show an array that would be the result after the call to deleteMi() on this heap</li>\n</ul>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><br><img src=\"heap.gif\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Devise an algorithm of merging two binary heaps. What is its runtime complexity?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><br><img src=\"e2.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li>Suppose you have two binary min-heaps, A and B, with a total of <strong>n</strong> elements between them. You want to discover if A and B have a key in common. Devise an algorithm to this problem that takes $O(n \\cdot log(n))$ time.<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>abcd</li>\n</ul>\n</blockquote>\n</li>\n<li><p>The values 1, 2, 3, …, 63 are all inserted (in any order) into an initially empty minheap. What is the smallest number that could be a leaf node?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><br><img src=\"e4.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Prove that it is impossible construct a min-heap (not necessarily binary) in a comparison-based model with both the following properties:</p>\n<ul>\n<li>a. deleteMin() runs in $O(1)$</li>\n<li>b. buildHeap() runs in $O(n)$, where n is the input size.</li>\n</ul>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>abcd</li>\n</ul>\n</blockquote>\n</li>\n<li><p>Given an unsorted array of size <strong>n</strong>, devise a heap-based algorithm that finds the k-th largest element in the array. What is its runtime complexity?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>abcd</li>\n</ul>\n</blockquote>\n</li>\n<li>Recall that two sorted arrays of size n can be merged into a single sorted list in linear time O(n). Suppose there are k &gt; 2 sorted arrays, each of size n. Devise a heap-based algorithm that merges k arrays and requires at most O(k) extra space.<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>abcd</li>\n</ul>\n</blockquote>\n</li>\n<li><p>Given a stream of data (its size is unknown in advance), devise a heap-based algorithm that finds the k-th largest element in the array. Your algorithm must take at most $O(k)$ extra space. What is its runtime complexity?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><br><img src=\"e8.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Given a stream of data (its size is unknown in advance), devise a heap-based algorithm that finds the median of elements read so far. What is its runtime complexity?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>use <em>Exercise 8</em>‘s Online Algorithm</li>\n</ul>\n</blockquote>\n</li>\n<li><p>Given a sequence of numbers, 3, 5, 2, 8, 1, 5, 2, 7,</p>\n<ul>\n<li>a. draw a binomial heap by inserting these numbers, reading them from left to right; and</li>\n<li>b. show a heap that would be the result after the call to deleteMin() on this heap.</li>\n</ul>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>abcd</li>\n</ul>\n</blockquote>\n</li>\n<li><p>Discuss the relationship between inserting into a binomial heap and binary increment.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>abcd</li>\n</ul>\n</blockquote>\n</li>\n<li>Discuss the relationship between merging two binomial heaps and adding two binary numbers.<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>abcd</li>\n</ul>\n</blockquote>\n</li>\n<li>Discuss the relationship between inserting into a binomial heap and a Fibonacci heap.<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>abcd</li>\n</ul>\n</blockquote>\n</li>\n<li>Devise an algorithm of deleting any item from a binomial heap. What is its runtime complexity?<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>abcd</li>\n</ul>\n</blockquote>\n</li>\n<li>Devise an algorithm to find all nodes less than some given value X in a binomial heap. Analyze its complexity.<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>abcd</li>\n</ul>\n</blockquote>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Heap\"><a href=\"#Heap\" class=\"headerlink\" title=\"Heap\"></a>Heap</h3><ul>\n<li><p>Three types of heap</p>\n<blockquote>\n<p><strong>Binary Heap</strong></p>\n<blockquote>\n<p>asdasda</p>\n</blockquote>\n<p><strong>Binomial Heap</strong></p>\n<blockquote>\n<p><strong>Definition</strong>: <br>A binomial heap is a collection (a linked list) of at most Celling(log(n)) binomial trees (<u><strong>of unique rank</strong></u>) in increasing order of size where each tree has a heap ordering property.<br><br><strong>Binomial Trees</strong></p>\n<blockquote>\n<p>The binomial tree <script type=\"math/tex\">B_k</script> is defined as </p>\n<ol>\n<li><script type=\"math/tex\">B_0</script> is a single node</li>\n<li><script type=\"math/tex\">B_k</script> is formed by joining two <script type=\"math/tex\">B_{k - 1}</script> trees<br><img src=\"BT.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ol>\n</blockquote>\n</blockquote>\n<p><strong>Fibonacci Heap</strong></p>\n<blockquote>\n<p><u>general idea</u> is to have a more relaxed structure (compared to binomial heaps) that will improve <em>decreaseKey</em> complexity to constant amortized time</p>\n</blockquote>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"Review-Q-amp-A\"><a href=\"#Review-Q-amp-A\" class=\"headerlink\" title=\"Review Q&amp;A\"></a>Review Q&amp;A</h3><ol>\n<li><p>What is the worst-case runtime complexity of finding the smallest item in a binary min-heap?<img src=\"lecture.png\"  style=\"width:30px;display:inline;box-shadow: none !important;\"></p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li><strong>O(1)</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>What is the worst-case runtime complexity of finding the largest item in a binary min-heap?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li><strong>O(n)</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p>How many binomial trees does a binomial heap with 31 elements contain?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>“Having this in mind, we always will assume in the worst-case analysis that there are $O(log(n))$ binomial trees in a binomial heap with n nodes.” —Chpater 3 [3.2.0]<br>$O(log(31)) = 6$</li>\n</ul>\n</blockquote>\n</li>\n<li><p>How many binomial trees are in a binomial heap of size n?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>$O(log(n))$</li>\n</ul>\n</blockquote>\n</li>\n<li><p>What is the worst-case runtime complexity of inserting into a binomial heap?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong> =&gt; $O(1)$<br><img src=\"heap_table.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p>What is the worst-case runtime complexity of searching in a binomial heap?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong> =&gt; $O(n)$</li>\n</ul>\n</blockquote>\n</li>\n<li><p>What is the amortized cost of inserting into a binomial heap?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong> =&gt; $O(1)$</li>\n</ul>\n</blockquote>\n</li>\n<li><p>What is the worst-case runtime complexity of deleteMin() from a binomial heap?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong> =&gt; $O(log(n))$</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> The following array is a max heap: [10, 3, 5, 1, 4, 2].</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> In a binary max-heap with <strong>n</strong> elements, the worst-case runtime complexity of finding the second largest element is $O(1)$.</p>\n<blockquote>\n<ul>\n<li><strong>True</strong></li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> If item A is an ancestor of item B in a heap then it must be the case that the insert(A) operation occurred before insert(B).</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>It could be any order, but the final result will be the same.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> Using a binary heap we can sort any array of size n in $O(n)$ time.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>dont know</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> In a binomial min-heap with <strong>n</strong> elements, the worst-case runtime complexity of finding the smallest element is $O(1)$.</p>\n<blockquote>\n<ul>\n<li><strong>True</strong></li>\n<li>this is min-heap, the smallest element will be placed in the top.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> In a binomial min-heap with <strong>n</strong> elements, the worst-case runtime complexity of finding the second smallest element is $O(1)$.</p>\n<blockquote>\n<ul>\n<li><strong>True</strong></li>\n<li>same reason I think.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> By using a binomial heap we can sort data of size n in $O(n)$ time.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>could sort <strong>n</strong> elements in $O(nlog(n))$ time.</li>\n</ul>\n</blockquote>\n</li>\n<li><p><strong>(T/F)</strong> Given a Fibonacci heap of size <strong>n</strong>, the maximum number of trees is that heap is <strong>n</strong>.</p>\n<blockquote>\n<ul>\n<li><strong>False</strong></li>\n<li>dont know</li>\n</ul>\n</blockquote>\n</li>\n</ol>\n<h3 id=\"Exercise-Q-amp-A\"><a href=\"#Exercise-Q-amp-A\" class=\"headerlink\" title=\"Exercise Q&amp;A\"></a>Exercise Q&amp;A</h3><ol>\n<li><p>Given a sequence of numbers, 3, 5, 2, 8, 1, 5, 2,</p>\n<ul>\n<li>a. draw a binary min-heap (in an array form) by inserting these numbers, reading them from left to right; and</li>\n<li>b. show an array that would be the result after the call to deleteMi() on this heap</li>\n</ul>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><br><img src=\"heap.gif\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Devise an algorithm of merging two binary heaps. What is its runtime complexity?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><br><img src=\"e2.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li>Suppose you have two binary min-heaps, A and B, with a total of <strong>n</strong> elements between them. You want to discover if A and B have a key in common. Devise an algorithm to this problem that takes $O(n \\cdot log(n))$ time.<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>abcd</li>\n</ul>\n</blockquote>\n</li>\n<li><p>The values 1, 2, 3, …, 63 are all inserted (in any order) into an initially empty minheap. What is the smallest number that could be a leaf node?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><br><img src=\"e4.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Prove that it is impossible construct a min-heap (not necessarily binary) in a comparison-based model with both the following properties:</p>\n<ul>\n<li>a. deleteMin() runs in $O(1)$</li>\n<li>b. buildHeap() runs in $O(n)$, where n is the input size.</li>\n</ul>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>abcd</li>\n</ul>\n</blockquote>\n</li>\n<li><p>Given an unsorted array of size <strong>n</strong>, devise a heap-based algorithm that finds the k-th largest element in the array. What is its runtime complexity?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>abcd</li>\n</ul>\n</blockquote>\n</li>\n<li>Recall that two sorted arrays of size n can be merged into a single sorted list in linear time O(n). Suppose there are k &gt; 2 sorted arrays, each of size n. Devise a heap-based algorithm that merges k arrays and requires at most O(k) extra space.<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>abcd</li>\n</ul>\n</blockquote>\n</li>\n<li><p>Given a stream of data (its size is unknown in advance), devise a heap-based algorithm that finds the k-th largest element in the array. Your algorithm must take at most $O(k)$ extra space. What is its runtime complexity?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong><br><img src=\"e8.png\"  style=\"display:inline;box-shadow: none !important;\"></li>\n</ul>\n</blockquote>\n</li>\n<li><p>Given a stream of data (its size is unknown in advance), devise a heap-based algorithm that finds the median of elements read so far. What is its runtime complexity?</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>use <em>Exercise 8</em>‘s Online Algorithm</li>\n</ul>\n</blockquote>\n</li>\n<li><p>Given a sequence of numbers, 3, 5, 2, 8, 1, 5, 2, 7,</p>\n<ul>\n<li>a. draw a binomial heap by inserting these numbers, reading them from left to right; and</li>\n<li>b. show a heap that would be the result after the call to deleteMin() on this heap.</li>\n</ul>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>abcd</li>\n</ul>\n</blockquote>\n</li>\n<li><p>Discuss the relationship between inserting into a binomial heap and binary increment.</p>\n<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>abcd</li>\n</ul>\n</blockquote>\n</li>\n<li>Discuss the relationship between merging two binomial heaps and adding two binary numbers.<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>abcd</li>\n</ul>\n</blockquote>\n</li>\n<li>Discuss the relationship between inserting into a binomial heap and a Fibonacci heap.<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>abcd</li>\n</ul>\n</blockquote>\n</li>\n<li>Devise an algorithm of deleting any item from a binomial heap. What is its runtime complexity?<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>abcd</li>\n</ul>\n</blockquote>\n</li>\n<li>Devise an algorithm to find all nodes less than some given value X in a binomial heap. Analyze its complexity.<blockquote>\n<ul>\n<li><strong>Solution</strong></li>\n<li>abcd</li>\n</ul>\n</blockquote>\n</li>\n</ol>\n"}],"PostAsset":[{"_id":"source/_posts/AIA-ch1-Q-A/ans_6.png","slug":"ans_6.png","post":"cklbvizok0001xctt3ijn03c1","modified":1,"renderable":0},{"_id":"source/_posts/AIA-ch1-Q-A/cruves.png","slug":"cruves.png","post":"cklbvizok0001xctt3ijn03c1","modified":1,"renderable":0},{"_id":"source/_posts/AIA-ch1-Q-A/ans_7.png","slug":"ans_7.png","post":"cklbvizok0001xctt3ijn03c1","modified":1,"renderable":0},{"_id":"source/_posts/AIA-ch4-Q-A/e7.png","slug":"e7.png","post":"cklbvizoq0005xcttggaudmbo","modified":1,"renderable":0},{"_id":"source/_posts/AIA-ch2-Q-A/s_c_graph.png","slug":"s_c_graph.png","post":"cklbvizon0002xctt9ouzfbsd","modified":1,"renderable":0},{"_id":"source/_posts/AIA-ch2-Q-A/dequeue.png","slug":"dequeue.png","post":"cklbvizon0002xctt9ouzfbsd","modified":1,"renderable":0},{"_id":"source/_posts/AIA-ch2-Q-A/binary_counter.png","slug":"binary_counter.png","post":"cklbvizon0002xctt9ouzfbsd","modified":1,"renderable":0},{"_id":"source/_posts/AIA-ch4-Q-A/e5.png","slug":"e5.png","post":"cklbvizoq0005xcttggaudmbo","modified":1,"renderable":0},{"_id":"source/_posts/AIA-ch2-Q-A/lecture.png","post":"cklbvizon0002xctt9ouzfbsd","slug":"lecture.png","modified":1,"renderable":1},{"_id":"source/_posts/AIA-ch1-Q-A/ans_5.png","post":"cklbvizok0001xctt3ijn03c1","slug":"ans_5.png","modified":1,"renderable":1},{"_id":"source/_posts/AIA-ch1-Q-A/fn_gn.png","post":"cklbvizok0001xctt3ijn03c1","slug":"fn_gn.png","modified":1,"renderable":1},{"_id":"source/_posts/AIA-ch1-Q-A/lecture.png","post":"cklbvizok0001xctt3ijn03c1","slug":"lecture.png","modified":1,"renderable":1},{"_id":"source/_posts/AIA-ch1-Q-A/v_e_f_2.png","post":"cklbvizok0001xctt3ijn03c1","slug":"v_e_f_2.png","modified":1,"renderable":1},{"_id":"source/_posts/AIA-ch4-Q-A/Kruskal.png","post":"cklbvizoq0005xcttggaudmbo","slug":"Kruskal.png","modified":1,"renderable":1},{"_id":"source/_posts/AIA-ch4-Q-A/Prim.png","post":"cklbvizoq0005xcttggaudmbo","slug":"Prim.png","modified":1,"renderable":1},{"_id":"source/_posts/AIA-ch4-Q-A/dij1.png","post":"cklbvizoq0005xcttggaudmbo","slug":"dij1.png","modified":1,"renderable":1},{"_id":"source/_posts/AIA-ch4-Q-A/lecture.png","post":"cklbvizoq0005xcttggaudmbo","slug":"lecture.png","modified":1,"renderable":1},{"_id":"source/_posts/AIA-ch4-Q-A/r10.png","post":"cklbvizoq0005xcttggaudmbo","slug":"r10.png","modified":1,"renderable":1},{"_id":"source/_posts/AIA-ch4-Q-A/r12.png","post":"cklbvizoq0005xcttggaudmbo","slug":"r12.png","modified":1,"renderable":1},{"_id":"source/_posts/AIA-ch4-Q-A/r2.png","post":"cklbvizoq0005xcttggaudmbo","slug":"r2.png","modified":1,"renderable":1},{"_id":"source/_posts/AIA-ch4-Q-A/r5.png","post":"cklbvizoq0005xcttggaudmbo","slug":"r5.png","modified":1,"renderable":1},{"_id":"source/_posts/AIA-ch3-Q-A/BT.png","post":"cklbvizpa000sxctt62op7v23","slug":"BT.png","modified":1,"renderable":1},{"_id":"source/_posts/AIA-ch3-Q-A/e2.png","post":"cklbvizpa000sxctt62op7v23","slug":"e2.png","modified":1,"renderable":1},{"_id":"source/_posts/AIA-ch3-Q-A/e4.png","post":"cklbvizpa000sxctt62op7v23","slug":"e4.png","modified":1,"renderable":1},{"_id":"source/_posts/AIA-ch3-Q-A/e8.png","post":"cklbvizpa000sxctt62op7v23","slug":"e8.png","modified":1,"renderable":1},{"_id":"source/_posts/AIA-ch3-Q-A/heap.gif","slug":"heap.gif","post":"cklbvizpa000sxctt62op7v23","modified":1,"renderable":0},{"_id":"source/_posts/AIA-ch3-Q-A/heap_table.png","post":"cklbvizpa000sxctt62op7v23","slug":"heap_table.png","modified":1,"renderable":1},{"_id":"source/_posts/AIA-ch3-Q-A/lecture.png","post":"cklbvizpa000sxctt62op7v23","slug":"lecture.png","modified":1,"renderable":1}],"PostCategory":[{"post_id":"cklbvizok0001xctt3ijn03c1","category_id":"cklbvizoo0003xctt04n4ckk3","_id":"cklbvizou0009xcttg8lc47kk"},{"post_id":"cklbvizon0002xctt9ouzfbsd","category_id":"cklbvizoo0003xctt04n4ckk3","_id":"cklbvizoy000bxcttb1dshxgx"},{"post_id":"cklbvizoq0005xcttggaudmbo","category_id":"cklbvizoo0003xctt04n4ckk3","_id":"cklbvizp1000exctt6dw0aeuc"},{"post_id":"cklbvizpa000sxctt62op7v23","category_id":"cklbvizoo0003xctt04n4ckk3","_id":"cklbvizpc000wxcttf2y9cdse"}],"PostTag":[{"post_id":"cklbvizok0001xctt3ijn03c1","tag_id":"cklbvizoq0004xctt6e7t8faq","_id":"cklbvizp0000dxcttfbwv4vd7"},{"post_id":"cklbvizok0001xctt3ijn03c1","tag_id":"cklbvizos0007xctt26uta985","_id":"cklbvizp1000fxctt5vuj7l4m"},{"post_id":"cklbvizok0001xctt3ijn03c1","tag_id":"cklbvizov000axcttbge571kc","_id":"cklbvizp2000hxctt5k4x7t49"},{"post_id":"cklbvizon0002xctt9ouzfbsd","tag_id":"cklbvizoq0004xctt6e7t8faq","_id":"cklbvizp3000kxctthaf931vc"},{"post_id":"cklbvizon0002xctt9ouzfbsd","tag_id":"cklbvizp1000gxctth9en94r6","_id":"cklbvizp3000lxctt248yebmi"},{"post_id":"cklbvizon0002xctt9ouzfbsd","tag_id":"cklbvizov000axcttbge571kc","_id":"cklbvizp3000nxctta79d7kec"},{"post_id":"cklbvizoq0005xcttggaudmbo","tag_id":"cklbvizoq0004xctt6e7t8faq","_id":"cklbvizp4000pxctt6l21hzjq"},{"post_id":"cklbvizoq0005xcttggaudmbo","tag_id":"cklbvizp3000mxctt11y11q6t","_id":"cklbvizp4000qxctt90o70ulu"},{"post_id":"cklbvizoq0005xcttggaudmbo","tag_id":"cklbvizov000axcttbge571kc","_id":"cklbvizp4000rxctth5aq17um"},{"post_id":"cklbvizpa000sxctt62op7v23","tag_id":"cklbvizoq0004xctt6e7t8faq","_id":"cklbvizpd000xxctt5wel3wk1"},{"post_id":"cklbvizpa000sxctt62op7v23","tag_id":"cklbvizpc000vxcttfu7ueyla","_id":"cklbvizpd000yxcttcapzfchs"},{"post_id":"cklbvizpa000sxctt62op7v23","tag_id":"cklbvizov000axcttbge571kc","_id":"cklbvizpd000zxctt8jmv7qkh"}],"Tag":[{"name":"Review","_id":"cklbvizoq0004xctt6e7t8faq"},{"name":"Graph","_id":"cklbvizos0007xctt26uta985"},{"name":"Q&A","_id":"cklbvizov000axcttbge571kc"},{"name":"Amortized Analysis","_id":"cklbvizp1000gxctth9en94r6"},{"name":"Greedy Algorithm","_id":"cklbvizp3000mxctt11y11q6t"},{"name":"Heap","_id":"cklbvizpc000vxcttfu7ueyla"}]}}